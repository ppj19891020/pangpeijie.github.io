<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[分库分表方案对比]]></title>
    <url>%2F2018%2F04%2F26%2F%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8%E6%96%B9%E6%A1%88%E5%AF%B9%E6%AF%94%2F</url>
    <content type="text"><![CDATA[背景目前公司业务高速发展，各种业务数据呈井喷的态势，单表数据量急剧膨胀，随之而来是单表读写性能和吞吐量呈下降趋势而且无法应对业务高速增长产生的数据。因此需要使用分库分表机制保证高性能同时支撑和驱动业务发展，选择一款功能强大支持分库分表的中间件就成为当务之急。开源的数据库中间件众多，需要从中挑选一个适合的，并能作为映客长期演进的中间件，因此需要从多个维度对中间件进行相关测试 解决方案针对数据量过大出现的性能问题，通过分库分表将数据量保持在阀值以下，可以有效分散高并发量和缓解大数据量。分库分表一般分垂直拆分和水平拆分，根据业务将单库（表）拆分为多库（表），常用的字段和不常用的字段拆分至不同的库（表）中，可适当缓解并发量和数据量，但不能根治；垂直拆分之后依然超过单节点所能承载的阈值，则需要水平拆分来进一步处理。 水平拆分则是根据分片算法将一个库（表）拆分为多个库（表）。 分表虽然可以解决海量数据导致的性能问题，但无法解决过多请求访问同一数据库，导致其响应变慢的问题。所以水平拆分通常要采取分库的方式(合理的配合使用分库+分表)，一并解决数据量和访问量巨大的问题。 产品调研调研分析后Mycat和Sharding-jdbc功能上比较稳定成熟，支持分库分表、读写分离、分布式主键、柔性事务等。 Sharding-jdbc：类似TDDL，基于JDBC协议的数据库中间件产品，使用客户端直连数据库，以jar包形式提供服务，兼容JDBC和各种ORM框架，使系统在数据访问层直接具有分片化和分布式治理的能力。 轻量级框架， 直接封装的jdbc协议，jar包形式提供服务，旧代码迁移、新代码开发成本低 无需额外部署和依赖，客户端直连数据库，无需二次转发，性能高 运维层面不改动，无需关注中间件本身的 HA mycat基于阿里开源的Cobar研发，对代码进行了彻底重构，使用NIO重构了网络模块，并优化了Buffer内核，增强了聚合，Join等基本特性.主要原理是拦截用户发送过来的SQL语句，对SQL语句做了特定的分析：如分片分析、路由分析、读写分离分析、缓存分析等，然后将此SQL发往后端的真实数据库，并将返回的结果做适当的处理，最后返回给用户。 可以负责更多的内容，将数据迁移，分布式事务等纳入 Proxy 的范畴 针对mycat和mysql有较全性能监控项统计支持 可结合Storm等分布式实时流引擎，实现数据分析和数据聚合 比较本次对比不是对MySQL数据库进行极限或压力性能测试，而是在同等软硬件环境下对选取的数据库中间件在软件/物理架构、功能特性、扩展性、SQL支持程度、容灾/容错、可用性、可维护性、接入成本等进行综合衡量。 对比点 mycat sharding-jdbc Tidb-分布式数据库 分库分表 支持 支持 支持 分布式事物 弱XA 弱XA 完全ACID 复杂聚合查询 较弱（支持单库内部任意join，支持跨库2表join） 支持（聚合，分组，排序，分页，OR，关联查询） 支持 主键 时间戳、数据库、zk 雪花算法 区间分段（可能出现重复主键） 分片规则 已支持较多分片，可自定义 已支持较多分片，可自定义 内部实现机制，无需业务制定 支持数据库 mysql、nosql(monogdb) mysql 本身就是数据库 HA haproxy+keeplive 无 水平扩展+高可用 语言 java java go 可维护性 较高（提供管控台） 较高 低（虽然提供管控台，但是由于开发语言限制与团队技术栈不一致） 接入成本 低 较高(业务方需配合) 高(业务数据需要全部迁移tidb) 优点 有效解决了数据库链接数多的问题，因为各工程应用只连接中间件，中间件代理了真实的物理链接，并且与后端mysql物理链接是复用型的所有的分库分表等规则集中配置在中间件上，更可控 性能高 产品较新 缺点 计算过程只能单节点计算，单机扩展只能调优，但是集群可以做负载均衡；相对sharding-jdbc来说，由于增加一层中间代理，性能稍微降低；需要保证中间件的可用性，会增加运维成本及复杂度； 业务工程里各自配置多数据源（主、从），不能做到统一数据库连接管理，分片规则需要hard code到业务代码中 业务数据需要全部迁移，并且生产环境配置要求较高，不建议使用 分库分表后不支持的sql语法 SELECT不支持的语法 不支持跨分片的交叉查询 跨节点的联合查询，不支持union all，union sharding-jdbc不支持DISTINCT聚合,但是mycat支持 mycat支持跨库2张表的join（可通过Catlet实现多表join），sharding-jdbc支持多表join，由于内部实现复杂度和性能，不推荐使用join，最好由业务改造简单查询 mycat join支持 INSERT不支持的语法 插入的字段不包含分片字段 插入的分片字段找不到对应分片 复制插入 insert into…select… 多行插入 insert into tab_a(c1,c2) values(v1,v2),(v11,v21)… UPDATE不支持的语法 更新的列包含分片列 多表更新 update a, b set a.nation=’China’, b.pwd=’123456’ where a.id=b.id 复杂多表关联更新 update a, b set a.nation=’China’ where a.id=b.id; 但支持子查询方式 update a set a.nation=’China’ where id in (select id from b); DELETE不支持语法 复杂删除sql delete a from a join b on a.id=b.id; 支持子查询方式 delete from a where a.id in (select id from b), 但表不能起别名 其他 Call procedure() MyCat未支持存储过程定义, 因而不允许调用存储过程，但可通过注解来调用各个分片上的存储过程 Select func(); 不支持这种方式直接调用自定义函数， 但支持 select id, func() from employee 只需employee所在的所有分片上存在这个函数。MySql自带函数可随意使用。 mycat 使用教程mycat分库分表规则主要是修改server.xml、schema.xml和rule.xml。 server.xml：是Mycat服务器参数调整和用户授权的配置文件。 schema.xml：是逻辑库定义和表以及分片定义的配置文件。 rule.xml：是分片规则的配置文件，分片规则的具体一些参数信息单独存放为文件，也在这个目录下，配置文件修改需要重启MyCAT。 mycat服务端server.xml配置 1234567891011121314151617181920212223242526272829303132333435363738394041424344&lt;mycat:server xmlns:mycat="http://io.mycat/"&gt; &lt;system&gt; &lt;!-- 0为需要密码登陆、1为不需要密码登陆 ,默认为0，设置为1则需要指定默认账户--&gt; &lt;property name="nonePasswordLogin"&gt;0&lt;/property&gt; &lt;!-- 1为开启实时统计、0为关闭 --&gt; &lt;property name="useSqlStat"&gt;0&lt;/property&gt; &lt;!-- 1为开启全加班一致性检测、0为关闭 --&gt; &lt;property name="useGlobleTableCheck"&gt;0&lt;/property&gt; &lt;!-- 用来指定Mycat全局序列类型，0为本地文件，1为数据库方式，2为时间戳列方式，默认使用本地文件方式，文件方式主要用于测试--&gt; &lt;property name="sequnceHandlerType"&gt;2&lt;/property&gt; &lt;!--默认为type 0: DirectByteBufferPool | type 1 ByteBufferArena--&gt; &lt;property name="processorBufferPoolType"&gt;0&lt;/property&gt; &lt;!--分布式事务开关，0为不过滤分布式事务，1为过滤分布式事务（如果分布式事务内只涉及全局表，则不过滤），2为不过滤分布式事务,但是记录分布式事务日志--&gt; &lt;property name="handleDistributedTransactions"&gt;0&lt;/property&gt; &lt;!-- 配置是否启用非堆内存跨分片结果集，1为开启，0为关闭，mycat1.6开始支持该属性--&gt; &lt;property name="useOffHeapForMerge"&gt;1&lt;/property&gt; &lt;!--单位为m--&gt; &lt;property name="memoryPageSize"&gt;64k&lt;/property&gt; &lt;!--单位为k--&gt; &lt;property name="spillsFileBufferSize"&gt;1k&lt;/property&gt; &lt;property name="useStreamOutput"&gt;0&lt;/property&gt; &lt;!--单位为m--&gt; &lt;property name="systemReserveMemorySize"&gt;384m&lt;/property&gt; &lt;!--是否采用zookeeper协调切换 --&gt; &lt;property name="useZKSwitch"&gt;false&lt;/property&gt; &lt;!-- 定义mycat使用的端口，默认值为8066 --&gt; &lt;property name="serverPort"&gt;3307&lt;/property&gt; &lt;!-- 定义mycat管理的端口，默认值为9066 --&gt; &lt;property name="managerPort"&gt;9066&lt;/property&gt; &lt;/system&gt; &lt;!-- 定义登录mycat对的用户权限 --&gt; &lt;user name="root" defaultAccount="true"&gt; &lt;property name="password"&gt;123456&lt;/property&gt; &lt;!-- 若要访问TESTDB 必须现在server.xml 中定义，否则无法访问TESTDB--&gt; &lt;property name="schemas"&gt;dbtest&lt;/property&gt; &lt;!-- 配置是否允许只读 --&gt; &lt;property name="readOnly"&gt;true&lt;/property&gt; &lt;!-- 定义限制前端整体的连接数，如果其值为0，或者不设置，则表示不限制连接数量 --&gt; &lt;property name="benchmark"&gt;11111&lt;/property&gt; &lt;!-- 设置是否开启密码加密功能，默认为0不开启加密，为1则表示开启加密 --&gt; &lt;property name="usingDecrypt"&gt;1&lt;/property&gt; &lt;/user&gt;&lt;/mycat:server&gt; 分库分表schema.xml配置 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061&lt;mycat:schema xmlns:mycat="http://io.mycat/"&gt; &lt;!-- schema 定义mycat中的逻辑库，可以有多个逻辑库, 1）dataNode属性：绑定逻辑库到具体的Database上面， 2）checkSQLschema：如果为true，则会替换掉schema，如果为false则不会； 3）sqlMaxLimit：如果带了该属性，则每次执行sql的时候如果sql没有limit则会带上这个limit，如果schema为非拆分库，则该属性不会生效。--&gt; &lt;schema name="dbtest" checkSQLschema="true" sqlMaxLimit="100"&gt; &lt;!-- table标签定义了MyCat中的逻辑表，所有拆分的表都需要在table标签中定义。 --&gt; &lt;!-- 1）name属性：定义逻辑表的名称--&gt; &lt;!-- 2）dataNode属性：定义逻辑表所属的dataNode，如果需要引用多个dataNode,则可以用dataNode="dn$0-99" 来代表dn0到dn99的数据库--&gt; &lt;!-- 3）rule属性：用来指定逻辑表使用的规则名字，规则名字在rule.xml中定义。--&gt; &lt;!-- 4）ruleRequired属性：该属性用于指定表是否绑定分片规则，如果配置为true,但是没有具体的分片规则，则会报错。--&gt; &lt;!-- 5）type属性：定义逻辑表的类型，分为"全局表（global）"和"普通表"两种类型,不设置该值的时候未global的所有表。--&gt; &lt;!-- 6）autoIncrement属性：使用该值的时候需要定义auto_increment，使用的时候最好配合数据库模式的全局序列。--&gt; &lt;!-- 7）subTables属性：dataNode在分表的条件下只能配置一个，不支持各种条件的Join关联查询。--&gt; &lt;!-- 8）primaryKey属性:逻辑表对应真实表的主键。--&gt; &lt;!-- 9）needAddLimit属性：指定表是否需要字段再每个语句的后面加上limit限制。--&gt; &lt;table name="travelrecord" dataNode="dn1,dn2" primaryKey="id" rule="rule1"&gt; &lt;!--childTable标签用于定义E-R分片的子表，通过标签上的属性与浮表进行关联--&gt; &lt;!-- 1)name属性：定义子表的名称--&gt; &lt;!-- 2）joinKey属性：插入子表时，回使用这个值查找浮表存贮的数据节点--&gt; &lt;!-- 3）parentKey属性：与父表建立关联关系的列名，程序首先获取joinKey的值，然后通过parentKey属性指定的列名产生查询语句，通过执行语句得知父表存储在哪个分片上，从而确定子表存贮的位置。--&gt; &lt;!-- 4）primaryKey：和table标签一样--&gt; &lt;!-- 5）needAddLimit：和table标签一样--&gt; &lt;/table&gt; &lt;/schema&gt; &lt;!-- dataNode标签定义了mycat中的数据节点，这也就是我们通常所说的数据分片，一个单独的dataNode就是一个独立的数据分片--&gt; &lt;!--1）name属性：定义数据节点的唯一名字--&gt; &lt;!--2）dataHost属性：定义该分片所属的数据库实例，属性引用自dataHost标签上定义的name属性--&gt; &lt;!--3）database属性：定义该分片所属的数据库实例上的具体数据库。--&gt; &lt;dataNode name="dn1" dataHost="localhost1" database="db01"/&gt; &lt;dataNode name="dn2" dataHost="localhost1" database="db02" /&gt; &lt;!-- 定义数据库实例，读写分离和心跳语句--&gt; &lt;!--1)那么属性：标识唯一的dataHost,--&gt; &lt;!-- 2)maxCon属性：指定每个读写实例连接池的最大连接数。内嵌writeHost、readHost标签会使用这个属性的值来实例化连接池的最大连接数--&gt; &lt;!--3)minCon属性：指定每个读写实例连接池的最小连接数。初始化连接池的大小的属性。--&gt; &lt;!--4）balance属性：负债均衡类型，有四种--&gt; &lt;!-- balance="0" : 不开启读写分离机制，所有的读操作都发送到当前可以用的writeHost上--&gt; &lt;!-- balance="1" : 全部的readHost与stand by writeHost（双主从模式下的master） 都参与select语句的负债均衡--&gt; &lt;!-- balance="2" : 所有的读操作都随机的往writeHost和readHost上分发--&gt; &lt;!-- balance="3" : 所有的读分发到readHost上，writeHost负责写--&gt; &lt;!--5）writeType属性：负载均衡目前的取值有两种：--&gt; &lt;!-- writeType="0"：所有的写操作都发送到第一个writeHost,writeHost1挂了，则切换到writeHost2上，重新恢复writeHost1后，还是以writeHost2为准--&gt; &lt;!-- writeType="1"：所有的写操作都随机的发送到配置的writeHost上，1.5版本以后不推荐使用该值。--&gt; &lt;!--6）dbType属性：制定后端后端数据的类型：mysql，oracle、mongoDB--&gt; &lt;!--7）dbDriver属性：制定后端数据库使用的Driver.目前可选的值为native和JDBC。--&gt; &lt;!--8）switchType属性：默认值为1，自动切换。--&gt; &lt;!-- -1表示不自动切换--&gt; &lt;!-- 2表示基于mysql主从同步的状态决定是否切换。--&gt; &lt;!-- 3表示基于mysql galaxy cluster 的切换机制--&gt; &lt;!--9）tempReadHostAvailable属性：如果配置了writeHost属性，下面的readHost依旧可以使用，默认为0--&gt; &lt;dataHost name="localhost1" maxCon="1000" minCon="10" balance="0" writeType="0" dbType="mysql" dbDriver="native" switchType="1" slaveThreshold="100"&gt; &lt;heartbeat&gt;select user()&lt;/heartbeat&gt; &lt;writeHost host="hostM1" url="127.0.0.1:3306" user="root" password="123456"&gt; &lt;!-- url、user、password 设置成你的数据库 --&gt; &lt;/writeHost&gt; &lt;/dataHost&gt;&lt;/mycat:schema&gt; 分库分表规则rule.xml配置 1234567891011121314151617181920212223&lt;mycat:rule xmlns:mycat="http://io.mycat/"&gt; &lt;!--name 属性指定唯一的名字，用于标识不同的表规则 1）内嵌的 rule 标签则指定对物理表中的哪一列进行拆分和使用什么路由算法。 2）columns 内指定要拆分的列名字。 3)algorithm 使用 function 标签中的 name 属性。连接表规则和具体路由算法。当然，多个表规则可以连接到同一个路由算法上。 table 标签内使用。让逻辑表使用这个规则进行分片。 --&gt; &lt;tableRule name="rule1"&gt; &lt;rule&gt; &lt;columns&gt;id&lt;/columns&gt; &lt;algorithm&gt;func1&lt;/algorithm&gt; &lt;/rule&gt; &lt;/tableRule&gt; &lt;!--name 指定算法的名字。 1)class 制定路由算法具体的类名字。 2)property 为具体算法需要用到的一些属性。 --&gt; &lt;function name="func1" class="io.mycat.route.function.PartitionByLong"&gt; &lt;property name="partitionCount"&gt;2&lt;/property&gt; &lt;property name="partitionLength"&gt;512&lt;/property&gt; &lt;/function&gt;&lt;/mycat:rule&gt; sharding-jdbc 使用教程 maven依赖包 12345678910&lt;dependency&gt; &lt;groupId&gt;io.shardingsphere&lt;/groupId&gt; &lt;artifactId&gt;sharding-jdbc&lt;/artifactId&gt; &lt;version&gt;$&#123;sharding-sphere.version&#125;&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;io.shardingsphere&lt;/groupId&gt; &lt;artifactId&gt;sharding-jdbc-spring-namespace&lt;/artifactId&gt; &lt;version&gt;$&#123;sharding-sphere.version&#125;&lt;/version&gt;&lt;/dependency&gt; 分库分表设置 123456789101112131415161718192021222324252627282930&lt;!-- 按照 2库+2表分片 --&gt;&lt;!-- 分库规则-按照user_id取模 --&gt;&lt;!-- inline-strategy 行表达式分片策略 对应InlineShardingStrategy。使用Groovy的表达式，提供对SQL语句中的=和IN的分片操作支持，只支持单分片键。 对于简单的分片算法，可以通过简单的配置使用，从而避免繁琐的Java代码开发， 如: t_user$&#123;u_id % 8&#125; 表示t_user表按照u_id按8取模分成8个表，表名称为t_user0到t_user7。 1) sharding-column 分片列名称 2) algorithm-expression 分片算法行表达式，需符合groovy语法--&gt;&lt;sharding:inline-strategy id="databaseStrategy" sharding-column="user_id" algorithm-expression="sharding_$-&gt;&#123;user_id % 2&#125;" /&gt;&lt;sharding:inline-strategy id="userTableStrategy" sharding-column="age" algorithm-expression="t_user_$-&gt;&#123;age % 2&#125;" /&gt;&lt;!-- data-source 分片数据源 1）sharding-rule data-source-names 原始数据源 2）table-rules 数据表分片规则列表 3）table-rule 数据表分片规则 4）logic-table 逻辑表 5）generate-key-column-name 分布式主键指定，默认使用雪花算法计算id 6）actual-data-nodes 由数据源名 + 表名组成，以小数点分隔。多个表以逗号分隔，支持inline表达式。缺省表示使用已知数据源与逻辑表名称生成数据节点。用于广播表（即每个库中都需要一个同样的表用于关联查询，多为字典表）或只分库不分表且所有库的表结构完全一致的情况 7）database-strategy-ref 默认数据库分片策略，对应&lt;sharding:xxx-strategy&gt;中的策略Id，缺省表示不分库 8）table-strategy-ref 表分片策略，对应&lt;sharding:xxx-strategy&gt;中的策略Id，缺省表示使用&lt;sharding:sharding-rule /&gt;配置的默认表分片策略 --&gt;&lt;sharding:data-source id="shardingDataSource"&gt; &lt;sharding:sharding-rule data-source-names="sharding_0,sharding_1"&gt; &lt;sharding:table-rules&gt; &lt;sharding:table-rule logic-table="t_user" generate-key-column-name="id" actual-data-nodes="sharding_$-&gt;&#123;0..1&#125;.t_user_$-&gt;&#123;0..1&#125;" database-strategy-ref="databaseStrategy" table-strategy-ref="userTableStrategy" /&gt; &lt;/sharding:table-rules&gt; &lt;/sharding:sharding-rule&gt;&lt;/sharding:data-source&gt;]]></content>
      <categories>
        <category>分库分表</category>
      </categories>
      <tags>
        <tag>分库分表</tag>
        <tag>mycat</tag>
        <tag>sharding-jdbc</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[otter]]></title>
    <url>%2F2018%2F04%2F24%2Fotter%E5%9F%BA%E7%A1%80%E4%BB%8B%E7%BB%8D%2F</url>
    <content type="text"><![CDATA[背景 ***公司系统间的数据同步通过http接口通信，这种方式会导致数据同步高峰期间nginx的负载流量增加，从而影响业务流量。其二就是http方式的不稳定性，会导致一些数据不一致的问题。针对这个现象，目前提出2中解决方式，第一种可以通过高可用消息队列来进行解耦，第二种通过数据库底层binlog来监听数据变化。 otter介绍 otter为阿里的一款增量数据同步工具，基于数据库增量日志解析，准实时同步到本机房或异地机房的mysql/oracle数据库.一个分布式数据库同步系统。 otter工作原理 原理描述： 基于Canal开源产品，获取数据库增量日志数据。 典型管理系统架构，manager(web管理)+node(工作节点).manager运行时推送同步配置到node节点.node节点将同步状态反馈到manager上. 基于zookeeper，解决分布式状态调度的，允许多node节点之间协同工作. Otter目前支持了什么 单向同步， mysql/oracle互相同步 双向同步，无冲突变更 文件同步，本地/aranda文件 双A同步，冲突检测&amp;冲突补救 数据迁移，中间表/行记录同步 典型的场景是账户信息表和账户交易明细表，更新账户余额后需要登记一条账户明细，并且保证在一个事务里，用户可以通过交易明细表查看交易记录，但是交易明细表的数据量是逐步递增的，用户量多的系统，几个月下来的数据超过千万了，表数据量一多就导致查询和插入变慢，而一开始就对账户明细做分表处理就难于保证强一致性事务，通过otter可以将记录同步导历史表，并且进行分表处理，用户往年的交易记录就可以查询历史表了，而原交易明细表就可以删除一个月甚至几天前的数据； 环境准备 otter manager依赖于mysql进行配置信息的存储，所以需要预先安装mysql，并初始化otter manager的系统表结构。 整个otter架构依赖了zookeeper进行多节点调度，所以需要预先安装zookeeper，不需要初始化节点，otter程序启动后会自检. 安装jdk1.6+ 官方文档：https://github.com/alibaba/otter/wiki/Manager_Quickstarthttps://github.com/alibaba/otter/wiki/Node_Quickstart 名词解释 Channel：同步通道，单向同步中一个Pipeline组成，在双向同步中有两个Pipeline组成；Pipeline：从源端到目标端的整个过程描述，主要由一些同步映射过程组成； DataMediaPair：根据业务表定义映射关系，比如源表和目标表，字段映射，字段组等； DataMedia:抽象的数据介质概念，可以理解为数据表/mq队列定义； DataMediaSource: 抽象的数据介质源信息，补充描述DateMedia； ColumnPair: 定义字段映射关系； ColumnGroup: 定义字段映射组； Node: 处理同步过程的工作节点，对应一个jvm； 采坑问题 mysql需要开启binlog,并且binlog的模式一定要Row。 mysql5.6版本需要binlog_checksum设置为none，默认开始crc校验。 mysql mater节点需要设置server-id，server-id需要和manager上配置的node的id一致。错误内容如下：12345pid:1 nid:1 exception:canal:源数据库cancal:java.io.IOException: Received error packet: errno = 1236, sqlstate = HY000 errmsg = Misconfigured master - server_id was not set at com.alibaba.otter.canal.parse.inbound.mysql.dbsync.DirectLogFetcher.fetch(DirectLogFetcher.java:105) at com.alibaba.otter.canal.parse.inbound.mysql.MysqlConnection.dump(MysqlConnection.java:146) at com.alibaba.otter.canal.parse.inbound.AbstractEventParser$3.run(AbstractEventParser.java:227) at java.lang.Thread.run(Thread.java:745) 参考资料 https://github.com/alibaba/otter/wiki https://github.com/alibaba/otter/wiki/Faq https://blog.csdn.net/wudufeng/article/details/78688240 https://yq.aliyun.com/articles/223077?utm_content=m_32233 https://my.oschina.net/u/860872/blog/1609715 https://www.cnblogs.com/findumars/p/6294542.html mysql binlog优化https://www.cnblogs.com/doseoer/p/6132454.html binlog采坑 https://www.cnblogs.com/276815076/p/7993712.html https://yq.aliyun.com/articles/223077?utm_content=m_32233 https://blog.csdn.net/wudufeng/article/details/78688240]]></content>
      <categories>
        <category>中间件</category>
      </categories>
      <tags>
        <tag>otter</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker 基础命令]]></title>
    <url>%2F2018%2F04%2F23%2Fdocker%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[拉取镜像 docker pull daocloud.io/library/mysql:5.6 创建容器 docker run -p 3306:3306 –name mysql -v /Users/peijiepang/Documents/docker/mysql/conf:/etc/mysql -v /Users/peijiepang/Documents/docker/mysql/data:/var/lib/mysql -e MYSQL_ROOT_PASSWORD=123456 -d daocloud.io/library/mysql:5.6 获取所有的容器id docker ps -a 启动容器 docker start 578fcc293e25 查看当前启动的容器 docker ps 进去容器内部系统 sudo docker exec -it 578fcc293e25 /bin/bash 退出容器 exit/ctrl+c 容器重启 docker restart 容器id 查看容器启动日志 docker logs 容器id docker容器安装vim apt-get update，这个命令的作用是：同步 /etc/apt/sources.list 和 /etc/apt/sources.list.d 中列出的源的索引，这样才能获取到最新的软件包。等更新完毕以后再敲命令：apt-get install vim命令即可。 容器拷贝文件 12将主机/www/runoob目录拷贝到容器96f7f14e99ab的/www目录下:docker cp /www/runoob 96f7f14e99ab:/www/ 12docker cp /www/runoob 96f7f14e99ab:/www将容器96f7f14e99ab的/www目录拷贝到主机的/tmp目录中 容器设置时区12345678进入到/usr/share/zoneinfo/Asia目录，查看目录信息/usr/share/zoneinfo/Asia# ls -hllrwxrwxrwx 1 root root 6 Jul 6 02:15 Shanghai -&gt; ../PRClrwxrwxrwx 1 root root 12 Jul 6 02:15 Singapore -&gt; ../Singapore从查询结果可以知道，上海的时区文件实际上是个软连接文件。连接到了目录 /usr/share/zoneinfo/ 下的PRC文件。 直接进行拷贝：cp /usr/share/zoneinfo/PRC /etc/localtime然后这样就可以了。]]></content>
      <categories>
        <category>docker</category>
      </categories>
      <tags>
        <tag>命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java应用CPU百分百解决方案]]></title>
    <url>%2F2018%2F04%2F22%2Fjava%E5%BA%94%E7%94%A8CPU%E7%99%BE%E5%88%86%E7%99%BE%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88%2F</url>
    <content type="text"><![CDATA[利用top命令查找异常进程 top 输入top命令后，可以按P(shift+p)根据cpu占用排序、按M根据内存占用排序、按T根据运行时间排序。 这里先按P根据cpu排序查找异常的线程：]]></content>
      <categories>
        <category>问题及解决</category>
      </categories>
      <tags>
        <tag>服务器问题</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java应用OOM快速定位与解决方法]]></title>
    <url>%2F2018%2F04%2F21%2FOOM%E5%BF%AB%E9%80%9F%E5%AE%9A%E4%BD%8D%E4%B8%8E%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[背景最近项目老是出现OOM问题，常见有以下错误： java.lang.OutOfMemoryError: PermGen space java.lang.OutOfMemoryError: Java heap space OOM的常见原因 内存分配确实过小 频繁创建对象，没有及时释放 频繁申请系统资源，导致系统资源耗尽（例如：不断创建线程，不断发起网络连接） Java代码导致OutOfMemoryError错误的解决 检查代码中是否有死循环或递归调用。 检查是否有大循环重复产生新对象实体。 检查对数据库查询中，是否有一次获得全部数据的查询。一般来说，如果一次取十万条记录到内存，就可能引起内存溢出。这个问题比较隐蔽，在上线前，数据库中数据较少，不容易出问题，上线后，数据库中数据多了，一次查询就有可能引起内存溢出。因此对于数据库查询尽量采用分页的方式查询。 检查List、MAP等集合对象是否有使用完后，未清除的问题。List、MAP等集合对象会始终存有对对象的引用，使得这些对象不能被GC回收。 定位代码解决需要先找到出问题的进程，使用top命令定位： top 输入top命令后，可以按P(shift+p)根据cpu占用排序、按M根据内存占用排序、按T根据运行时间排序。（可以先按c显示具体的command） 这里先按M根据内存排序查找异常的进程：这里假设出现异常的进程pid为10410 注意定位问题前请先尝试输入jps命令，确定是否能够显示出现问题的pid.如果jps没有相应的显示，可能是你当前用户的权限不够，请使用启用相应进程的用户或者拥有更高权限的用户排查问题！不然以下的一些命令（例如jmap）将无法使用. 判断是否是由于“内存分配确实过小”输入以下命令： jmap -heap 10410 Attaching to process ID 10410, please wait... Debugger attached successfully. Server compiler detected. JVM version is 25.91-b14 using thread-local object allocation. Parallel GC with 4 thread(s) Heap Configuration: MinHeapFreeRatio = 0 MaxHeapFreeRatio = 100 MaxHeapSize = 2147483648 (2048.0MB) NewSize = 44564480 (42.5MB) MaxNewSize = 715653120 (682.5MB) OldSize = 89653248 (85.5MB) NewRatio = 2 SurvivorRatio = 8 MetaspaceSize = 21807104 (20.796875MB) CompressedClassSpaceSize = 1073741824 (1024.0MB) MaxMetaspaceSize = 17592186044415 MB G1HeapRegionSize = 0 (0.0MB) Heap Usage: PS Young Generation Eden Space: capacity = 343408640 (327.5MB) used = 63192336 (60.26490783691406MB) free = 280216304 (267.23509216308594MB) 18.401498576156964% used From Space: capacity = 18350080 (17.5MB) used = 12886976 (12.28997802734375MB) free = 5463104 (5.21002197265625MB) 70.22844587053571% used To Space: capacity = 18874368 (18.0MB) used = 0 (0.0MB) free = 18874368 (18.0MB) 0.0% used PS Old Generation capacity = 80216064 (76.5MB) used = 24040136 (22.92646026611328MB) free = 56175928 (53.57353973388672MB) 29.969229106030433% used 23018 interned Strings occupying 2885744 bytes. 判断是否是由于“频繁创建对象，没有及时回收”输入以下命令，找出最耗内存的对象： jmap -histo:live 10410 | more num #instances #bytes class name ---------------------------------------------- 1: 59259 8998824 [C 2: 21537 1895256 java.lang.reflect.Method 3: 57709 1385016 java.lang.String 4: 2683 1063512 [B 5: 9175 1021368 java.lang.Class 6: 18681 747240 java.util.LinkedHashMap$Entry 7: 21370 683840 java.util.concurrent.ConcurrentHashMap$Node 8: 8166 574544 [Ljava.util.HashMap$Node; 9: 9977 558712 java.util.LinkedHashMap 10: 9548 518480 [Ljava.lang.Object; 11: 21735 472376 [Ljava.lang.Class; 12: 13345 427040 java.util.HashMap$Node 13: 5570 401040 java.lang.reflect.Field 14: 259 258400 [Ljava.util.concurrent.ConcurrentHashMap$Node; 15: 14774 236384 java.lang.Object 16: 2692 215360 java.lang.reflect.Constructor 17: 3413 198216 [Ljava.lang.reflect.Method; 18: 4133 160288 [Ljava.lang.String; 19: 3695 147800 java.lang.ref.SoftReference 20: 1537 147552 org.springframework.beans.GenericTypeAwarePropertyDescriptor 21: 2378 133168 java.lang.Class$ReflectionData 22: 2861 132256 [I 23: 4050 129600 java.util.LinkedList 24: 3749 119968 java.lang.ref.WeakReference 25: 2435 116880 java.util.HashMap 26: 4509 108216 java.util.ArrayList 27: 4080 97920 java.beans.MethodRef 28: 2154 86160 java.util.TreeMap$Entry 29: 1188 85536 org.springframework.core.annotation.AnnotationAttributes 30: 1126 72064 org.springframework.core.MethodParameter 31: 2858 68592 java.util.LinkedList$Node 32: 3928 62848 java.util.LinkedHashSet 33: 370 62160 org.springframework.context.annotation.ConfigurationClassBeanDefinitionReader$ConfigurationClassBeanDefinition 34: 2185 52440 sun.reflect.generics.tree.SimpleClassTypeSignature 35: 2016 48384 sun.reflect.annotation.AnnotationInvocationHandler 36: 961 46128 org.springframework.core.ResolvableType 37: 901 43248 org.apache.tomcat.util.modeler.AttributeInfo 38: 2023 43200 [Ljava.lang.reflect.Type; 39: 2570 41120 java.util.LinkedHashMap$LinkedKeySet 40: 2185 41096 [Lsun.reflect.generics.tree.TypeArgument; 41: 1282 41024 java.util.concurrent.locks.ReentrantLock$NonfairSync 42: 2472 39552 java.util.LinkedHashMap$LinkedEntrySet 43: 2374 37984 org.springframework.core.annotation.AnnotationUtils$DefaultValueHolder 44: 1593 37008 [Ljava.lang.reflect.Constructor; 输入命令后，会以表格的形式显示存活对象的信息，并按照所占内存大小排序。 instances: 对象实例数量 bytes: 占用内存大小 class name: 类名 可以看到目前最耗内存的对象也才占用内存8m，所以属于正常范畴 如果发现某个对象的占用大量内存（例如：1G以上），就需要review代码，审查下该对象是否没有及时回收 PS：其中输出的奇怪的class name请查看最后的附录。 判断是否是由于“频繁申请系统资源”输入以下命令，查看进程的线程数 ll /proc/{PID}/task | wc -l 输入以下命令，查看进程的句柄数 ll /proc/{PID}/fd | wc -l jmap 附加说明 BaseType Character Type Interpretation B byte signed byte C char Unicode character D double double-precision floating-point value F float single-precision floating-point value I int integer J long long integer L reference an instance of class S short signed short Z boolean true or false [ reference one array dimension]]></content>
      <categories>
        <category>问题及解决</category>
      </categories>
      <tags>
        <tag>OutOfMemoryError</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[druid数据源无可用连接问题]]></title>
    <url>%2F2018%2F04%2F20%2Fdruid%E6%95%B0%E6%8D%AE%E6%BA%90%E6%97%A0%E5%8F%AF%E7%94%A8%E8%BF%9E%E6%8E%A5%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[背景在工程中使用了druid连接池，运行一段时间后系统出现异常,但是使用客户端能正常连接，连接数被未被占满,报错如下： Caused by: org.springframework.jdbc.CannotGetJdbcConnectionException: Could not get JDBC Connection; nested exception is com.alibaba.druid.pool.GetConnectionTimeoutException: wait millis 60009, active 50 at org.springframework.jdbc.datasource.DataSourceUtils.getConnection(DataSourceUtils.java:80) at org.springframework.jdbc.support.JdbcUtils.extractDatabaseMetaData(JdbcUtils.java:280) … 64 more 原因及解决方案应该是程序中有地方连接未关闭造成的。那如何来定呢？使用druid连接池的超时回收机制，在配置中增加以下内容： &lt;!– 超过时间限制是否回收 –&gt; &lt;property name=“removeAbandoned” value=“true” /&gt; &lt;!– 超时时间；单位为秒。180秒=3分钟 –&gt; &lt;property name=“removeAbandonedTimeout” value=“180” /&gt; &lt;!– 关闭abanded连接时输出错误日志 –&gt; &lt;property name=“logAbandoned” value=“true” /&gt; 但是加了logAbandoned配置之后，可能经常会强制释放连接报错，错误如下： [com.alibaba.druid.pool.DruidDataSource] – &lt;abandon connection, open stackTrace at java.lang.Thread.getStackTrace(Thread.java:1567) at com.alibaba.druid.pool.DruidDataSource.getConnectionDirect(DruidDataSource.java:995) at com.alibaba.druid.filter.FilterChainImpl.dataSource_connect(FilterChainImpl.java:4544) 备注：该堆栈是之前使用该连接是new出来的，故可以凭此确认此链接使用没有很好的回收。 但理论上使用了mybatis，mybatis会负责好连接池申请回放回]]></content>
      <categories>
        <category>问题及解决</category>
      </categories>
      <tags>
        <tag>连接池</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[解决OutOfMemoryError: unable to create new native thread问题]]></title>
    <url>%2F2018%2F04%2F19%2F%E8%A7%A3%E5%86%B3OutOfMemoryError-unable-to-create-new-native-thread%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[背景java.lang.OutOfMemoryError共有8种类型，其中java.lang.OutOfMemoryError: unable to create new native thread是很常见的一种，这类错误通常发生在应用试图创建新线程时。最近测试环境经常出现错误如下： Caused by: java.lang.OutOfMemoryError: unable to create new native thread at java.lang.Thread.start0(Native Method) at java.lang.Thread.start(Thread.java:714) at java.util.concurrent.ThreadPoolExecutor.addWorker(ThreadPoolExecutor.java:950) at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1368) at com.alibaba.dubbo.remoting.transport.dispatcher.all.AllChannelHandler.caught(AllChannelHandler.java:65) 可能原因 系统内存耗尽，无法为新线程分配内存 创建线程数超过了操作系统的限制 解决方案 排查应用是否创建了过多的线程 通过jstack确定应用创建了多少线程？超量创建的线程的堆栈信息是怎样的？谁创建了这些线程？一旦明确了这些问题，便很容易解决。步骤如下： 该进程内最耗费CPU的线程pid top -Hp pid 将pid装换成十六进制 printf “%x\n” 21742 最后用jstack查找线程堆栈信息 jstack 21711 | grep 54ee 调整操作系统线程数阈值 操作系统会限制进程允许创建的线程数，使用ulimit -u命令查看限制。某些服务器上此阈值设置的过小，比如1024。一旦应用创建超过1024个线程，就会遇到java.lang.OutOfMemoryError: unable to create new native thread问题。如果是这种情况，可以调大操作系统线程数阈值。 用当前用户登录，然后用ulimit -a查看配置项，将max user processes项调整大一点，可以参考top -H 信息中的 Threads: 853 total线程数 增加机器内存 如果上述两项未能排除问题，可能是正常增长的业务确实需要更多内存来创建更多线程。如果是这种情况，增加机器内存。 减小堆内存 一个老司机也经常忽略的非常重要的知识点：线程不在堆内存上创建，线程在堆内存之外的内存上创建。所以如果分配了堆内存之后只剩下很少的可用内存，依然可能遇到java.lang.OutOfMemoryError: unable to create new native thread。考虑如下场景：系统总内存6G，堆内存分配了5G，永久代512M。在这种情况下，JVM占用了5.5G内存，系统进程、其他用户进程和线程将共用剩下的0.5G内存，很有可能没有足够的可用内存创建新的线程。如果是这种情况，考虑减小堆内存。 减少进程数 这和减小堆内存原理相似。考虑如下场景：系统总内存32G，java进程数5个，每个进程的堆内存6G。在这种情况下，java进程总共占用30G内存，仅剩下2G内存用于系统进程、其他用户进程和线程，很有可能没有足够的可用内存创建新的线程。如果是这种情况，考虑减少每台机器上的进程数。 减小线程栈大小 线程会占用内存，如果每个线程都占用更多内存，整体上将消耗更多的内存。每个线程默认占用内存大小取决于JVM实现。可以利用-Xss参数限制线程内存大小，降低总内存消耗。例如，JVM默认每个线程占用1M内存，应用有500个线程，那么将消耗500M内存空间。如果实际上256K内存足够线程正常运行，配置-Xss256k，那么500个线程将只需要消耗125M内存。（注意，如果-Xss设置的过低，将会产生java.lang.StackOverflowError错误）]]></content>
      <categories>
        <category>问题及解决</category>
      </categories>
      <tags>
        <tag>OutOfMemoryError</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hello Hexo]]></title>
    <url>%2F2018%2F04%2F12%2Fhello-hexo%2F</url>
    <content type="text"><![CDATA[以前一直用wordpress维护博客，最近看到hexo博客的样例，觉得挺炫的，今天就准备将wordpress版本的博客迁移到hexo，然后重新梳理以前的博文。 Hexo Quick StartCreate a new post1$ hexo new "My New Post" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment]]></content>
      <categories>
        <category>感悟</category>
      </categories>
      <tags>
        <tag>感悟</tag>
      </tags>
  </entry>
</search>
