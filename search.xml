<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[使用JMH做Java微基准测试]]></title>
    <url>%2F2018%2F12%2F09%2F%E4%BD%BF%E7%94%A8JMH%E5%81%9AJava%E5%BE%AE%E5%9F%BA%E5%87%86%E6%B5%8B%E8%AF%95%2F</url>
    <content type="text"><![CDATA[背景在使用Java编程过程中，我们对于一些代码调用的细节有多种编写方式，但是不确定它们性能时，往往采用重复多次计数的方式来解决。但是随着JVM不断的进化，随着代码执行次数的增加，JVM会不断的进行编译优化，使得重复多少次才能够得到一个稳定的测试结果变得让人疑惑，这时候有经验的同学就会在测试执行前先循环上万次并注释为预热。 没错！这样做确实可以获得一个偏向正确的测试结果，但是我们试想如果每到需要斟酌性能的时候，都要根据场景写一段预热的逻辑吗？当预热完成后，需要多少次迭代来进行正式内容的测量呢？每次测试结果的输出报告是不是都需要用System.out来输出呢？ 其实这些工作都可以交给 JMH (the Java Microbenchmark Harness) ，它被作为Java9的一部分来发布，但是我们完全不需要等待Java9，而可以方便的使用它来简化我们测试，它能够照看好JVM的预热、代码优化，让你的测试过程变得更加简单。 使用 首先在项目中新增依赖，jmh-core以及jmh-generator-annprocess的依赖可以在maven仓库中找寻最新版本。 12345678910&lt;dependency&gt; &lt;groupId&gt;org.openjdk.jmh&lt;/groupId&gt; &lt;artifactId&gt;jmh-core&lt;/artifactId&gt; &lt;version&gt;1.19&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.openjdk.jmh&lt;/groupId&gt; &lt;artifactId&gt;jmh-generator-annprocess&lt;/artifactId&gt; &lt;version&gt;1.19&lt;/version&gt;&lt;/dependency&gt; 编写基准测试 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394package com.dxy.keygen.core;import com.dxy.keygen.utils.KeyGeneratorUtils;import com.dxy.keygen.utils.OrderNoGeneratorUtils;import org.junit.Test;import org.openjdk.jmh.annotations.*;import org.openjdk.jmh.runner.Runner;import org.openjdk.jmh.runner.RunnerException;import org.openjdk.jmh.runner.options.Options;import org.openjdk.jmh.runner.options.OptionsBuilder;/** * 基准测试 * @author: peijiepang * @date 2018-12-07 * @Description: */public class BenchmarkTest &#123; /** * 基准测试类 * @throws RunnerException */ @Test public void benchmarkTest() throws RunnerException &#123; Options opt = new OptionsBuilder() .include("defaultKeyGeneratorBenchmarkTest") .include("DefaultGeneratorOrderNoBenchmarkTest") .include("TimestampGeneratorOrderNoBenchmarkTest") .warmupIterations(5)//预热做5轮 .measurementIterations(10)//正式计量测试做10轮 .forks(3)//做3轮测试 .build(); new Runner(opt).run(); &#125; /** * 分布式主键生成基准测试 */ @Benchmark @BenchmarkMode(&#123;Mode.Throughput,Mode.AverageTime&#125;) public void defaultKeyGeneratorBenchmarkTest() &#123; KeyGeneratorUtils.generateKey(); &#125; /** * 默认订单号生成基准测试 */ @State(Scope.Benchmark) public static class DefaultGeneratorOrderNoBenchmarkTest&#123; /** * 订单号生成init */ @Setup public void init() &#123; OrderNoGeneratorUtils.init(OrderNoGeneratorUtils.OrderNoGeneratorEnum.DEFAULT); System.out.println("init"); &#125; /** * 分布式主键生成基准测试 */ @Benchmark @BenchmarkMode(&#123;Mode.Throughput,Mode.AverageTime&#125;) public void orderNoGeneratorBenchmarkTest() &#123; OrderNoGeneratorUtils.generateOrderNo(); &#125; &#125; /** * 时间戳订单号生成基准测试 */ @State(Scope.Benchmark) public static class TimestampGeneratorOrderNoBenchmarkTest&#123; /** * 订单号生成init */ @Setup public void init() &#123; OrderNoGeneratorUtils.init(OrderNoGeneratorUtils.OrderNoGeneratorEnum.TIMESTAMP); System.out.println("init"); &#125; /** * 分布式主键生成基准测试 */ @Benchmark @BenchmarkMode(&#123;Mode.Throughput,Mode.AverageTime&#125;) public void orderNoGeneratorBenchmarkTest() &#123; OrderNoGeneratorUtils.generateOrderNo(); &#125; &#125;&#125; 基准测试结果如下 123456789# Run complete. Total time: 00:06:32Benchmark Mode Cnt Score Error UnitsBenchmarkTest.DefaultGeneratorOrderNoBenchmarkTest.orderNoGeneratorBenchmarkTest thrpt 30 8612.597 ± 1864.319 ops/sBenchmarkTest.TimestampGeneratorOrderNoBenchmarkTest.orderNoGeneratorBenchmarkTest thrpt 30 8899.778 ± 2066.678 ops/sBenchmarkTest.defaultKeyGeneratorBenchmarkTest thrpt 30 1024568.969 ± 146.663 ops/sBenchmarkTest.DefaultGeneratorOrderNoBenchmarkTest.orderNoGeneratorBenchmarkTest avgt 30 ≈ 10⁻⁴ s/opBenchmarkTest.TimestampGeneratorOrderNoBenchmarkTest.orderNoGeneratorBenchmarkTest avgt 30 ≈ 10⁻⁴ s/opBenchmarkTest.defaultKeyGeneratorBenchmarkTest avgt 30 ≈ 10⁻⁶ s/op 注解介绍好了，当你对JMH有了一个基本认识后，现在来详细解释一下前面代码中的各个注解含义。 @BenchmarkMode基准测试类型。这里选择的是Throughput也就是吞吐量。根据源码点进去，每种类型后面都有对应的解释，比较好理解，吞吐量会得到单位时间内可以进行的操作数。 Throughput: 整体吞吐量，例如“1秒内可以执行多少次调用”。 AverageTime: 调用的平均时间，例如“每次调用平均耗时xxx毫秒”。 SampleTime: 随机取样，最后输出取样结果的分布，例如“99%的调用在xxx毫秒以内，99.99%的调用在xxx毫秒以内” SingleShotTime: 以上模式都是默认一次 iteration 是 1s，唯有 SingleShotTime 是只运行一次。往往同时把 warmup 次数设为0，用于测试冷启动时的性能。 All(“all”, “All benchmark modes”); @Warmup上面我们提到了，进行基准测试前需要进行预热。一般我们前几次进行程序测试的时候都会比较慢， 所以要让程序进行几轮预热，保证测试的准确性。其中的参数iterations也就非常好理解了，就是预热轮数。 为什么需要预热？因为 JVM 的 JIT 机制的存在，如果某个函数被调用多次之后，JVM 会尝试将其编译成为机器码从而提高执行速度。所以为了让 benchmark 的结果更加接近真实情况就需要进行预热。 @Measurement度量，其实就是一些基本的测试参数。 iterations 进行测试的轮次 time 每轮进行的时长 timeUnit 时长单位 都是一些基本的参数，可以根据具体情况调整。一般比较重的东西可以进行大量的测试，放到服务器上运行。 @Threads每个进程中的测试线程，这个非常好理解，根据具体情况选择，一般为cpu乘以2。 @Fork进行 fork 的次数。如果 fork 数是2的话，则 JMH 会 fork 出两个进程来进行测试。 @OutputTimeUnit这个比较简单了，基准测试结果的时间类型。一般选择秒、毫秒、微秒。 @Benchmark方法级注解，表示该方法是需要进行 benchmark 的对象，用法和 JUnit 的 @Test 类似。 @Param属性级注解，@Param 可以用来指定某项参数的多种情况。特别适合用来测试一个函数在不同的参数输入的情况下的性能。 @Setup方法级注解，这个注解的作用就是我们需要在测试之前进行一些准备工作，比如对一些数据的初始化之类的。 @TearDown方法级注解，这个注解的作用就是我们需要在测试之后进行一些结束工作，比如关闭线程池，数据库连接等的，主要用于资源的回收等。 @State当使用@Setup参数的时候，必须在类上加这个参数，不然会提示无法运行。 State 用于声明某个类是一个“状态”，然后接受一个 Scope 参数用来表示该状态的共享范围。 因为很多 benchmark 会需要一些表示状态的类，JMH 允许你把这些类以依赖注入的方式注入到 benchmark 函数里。Scope 主要分为三种。 Thread: 该状态为每个线程独享。 Group: 该状态为同一个组里面所有线程共享。 Benchmark: 该状态在所有线程间共享。]]></content>
      <tags>
        <tag>jmh</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java线程池ScheduledThreadPoolExecutor分析2]]></title>
    <url>%2F2018%2F12%2F04%2FJava%E7%BA%BF%E7%A8%8B%E6%B1%A0ScheduledThreadPoolExecutor%E5%88%86%E6%9E%902%2F</url>
    <content type="text"><![CDATA[简介DelayedWorkQueue是一个基于堆的数据结构，类似于DelayQueue和PriorityQueue。在执行定时任务的时候，每个任务的执行时间都不同，所以DelayedWorkQueue的工作就是按照执行时间的升序来排列，执行时间距离当前时间越近的任务在队列的前面。 堆结构如下图所示： 为什么要使用DelayedWorkQueue呢？定时任务执行时需要取出最近要执行的任务，所以任务在队列中每次出队时一定要是当前队列中执行时间最靠前的，所以自然要使用优先级队列。 DelayedWorkQueue是一个优先级队列，它可以保证每次出队的任务都是当前队列中执行时间最靠前的，由于它是基于堆结构的队列，堆结构在执行插入和删除操作时的最坏时间复杂度是 O(logN)。 排序规则 执行时间距离当前时间越近，越靠前 如果执行时间相同，则先执行插入时间靠前的任务。 新增/获取任务DelayedWorkQueue通过put或者add来新增一条任务，但其底层都是调用offer来新增任务的。对于获取任务，我们知道在ThreadPoolExecutor中线程根据getTask来获取任务队列中的任务，而在getTask中任务队列通过poll或者take函数来获取任务队列中的任务，由于ScheduleThreadPoolExecutor继承自ThreadPoolExecutor，因此其底层获取任务方式相同，只需要DelayedWorkQueue提供take及pool方法即可。 DelayWorkQueue底层是用最小堆数据结构实现的，需要最先执行的任务在堆的顶部，因此在每次插入或者删除任务时需要调整二叉树节点的顺序，但不同于最小堆的地方在于DelayWorkQueue不关心兄弟节点之间的顺序，只要父节点的任务先于子节点执行即可。 在一个最小堆的队列中，假如索引从0开始，子节点索引值为k，父节点索引值为p，则存在如下规律： 一个节点的左子节点的索引为：k = p * 2 + 1 一个节点的右子节点的索引为：k = (p + 1) * 2 一个节点的父节点的索引为：p = (k - 1) / 2 源码分析DelayedWorkQueue的属性1234567891011// 队列初始容量private static final int INITIAL_CAPACITY = 16;// 根据初始容量创建RunnableScheduledFuture类型的数组private RunnableScheduledFuture&lt;?&gt;[] queue = new RunnableScheduledFuture&lt;?&gt;[INITIAL_CAPACITY];private final ReentrantLock lock = new ReentrantLock();private int size = 0;// leader线程private Thread leader = null;// 当较新的任务在队列的头部可用时，或者新线程可能需要成为leader，则通过该条件发出信号private final Condition available = lock.newCondition(); 注意这里的leader，它是Leader-Follower模式的变体，用于减少不必要的定时等待。什么意思呢？对于多线程的网络模型来说： 所有线程会有三种身份中的一种：leader和follower，以及一个干活中的状态：proccesser。它的基本原则就是，永远最多只有一个leader。而所有follower都在等待成为leader。线程池启动时会自动产生一个Leader负责等待网络IO事件，当有一个事件产生时，Leader线程首先通知一个Follower线程将其提拔为新的Leader，然后自己就去干活了，去处理这个网络事件，处理完毕后加入Follower线程等待队列，等待下次成为Leader。这种方法可以增强CPU高速缓存相似性，及消除动态内存分配和线程间的数据交换。 offer方法既然是阻塞队列，入队的操作如add和put方法都调用了offer方法，下面查看一下offer方法：123456789101112131415161718192021222324252627282930313233343536/** * 入队操作 * @param x * @return */public boolean offer(Runnable x) &#123; if (x == null) throw new NullPointerException(); RunnableScheduledFuture&lt;?&gt; e = (RunnableScheduledFuture&lt;?&gt;)x; final ReentrantLock lock = this.lock; lock.lock(); try &#123; int i = size; // queue是一个RunnableScheduledFuture类型的数组，如果容量不够需要扩容 if (i &gt;= queue.length) grow(); size = i + 1; if (i == 0) &#123; // i == 0 说明堆中还没有数据，设置索引 queue[0] = e; setIndex(e, 0); &#125; else &#123; // i != 0 时，需要对堆进行重新排序 siftUp(i, e); &#125; // 如果传入的任务已经是队列的第一个节点了，这时available需要发出信号 if (queue[0] == e) &#123; // leader设置为null为了使在take方法中的线程在通过available.signal();后会执行available.awaitNanos(delay); leader = null; available.signal(); &#125; &#125; finally &#123; lock.unlock(); &#125; return true;&#125; siftUp方法1234567891011121314151617/** * Sifts element added at bottom up to its heap-ordered spot. * Call only when holding lock. */private void siftUp(int k, RunnableScheduledFuture&lt;?&gt; key) &#123; while (k &gt; 0) &#123; int parent = (k - 1) &gt;&gt;&gt; 1; //查找到父节点 RunnableScheduledFuture&lt;?&gt; e = queue[parent]; //获取父节点任务 if (key.compareTo(e) &gt;= 0) //如果父节点先于该任务执行，则跳出循环 break; queue[k] = e; //与父节点交换位置 setIndex(e, k); k = parent; //重新向上追溯父节点 &#125; queue[k] = key; setIndex(key, k);&#125; 代码很好理解，就是循环的根据key节点与它的父节点来判断，如果key节点的执行时间小于父节点，则将两个节点交换，使执行时间靠前的节点排列在队列的前面。 假设新入队的节点的延迟时间（调用getDelay()方法获得）是5，执行过程如下： 先将新的节点添加到数组的尾部，这时新节点的索引k为7： 计算新父节点的索引：parent = (k - 1) &gt;&gt;&gt; 1，parent = 那么queue[3]的时间间隔值为8，因为 5 &lt; 8 ，将执行queue[7] = queue[3] 这时将k设置为3，继续循环，再次计算parent为1，queue[1]的时间间隔为3，因为 5 &gt; 3 ，这时退出循环，最终k为3： 可见，每次新增节点时，只是根据父节点来判断，而不会影响兄弟节点。 另外，setIndex方法只是设置了ScheduledFutureTask中的heapIndex属性：1234private void setIndex(RunnableScheduledFuture&lt;?&gt; f, int idx) &#123; if (f instanceof ScheduledFutureTask) ((ScheduledFutureTask)f).heapIndex = idx;&#125; take方法12345678910111213141516171819202122232425262728293031323334353637383940public RunnableScheduledFuture&lt;?&gt; take() throws InterruptedException &#123; final ReentrantLock lock = this.lock; lock.lockInterruptibly(); try &#123; for (;;) &#123; RunnableScheduledFuture&lt;?&gt; first = queue[0]; if (first == null) available.await(); else &#123; // 计算当前时间到执行时间的时间间隔 long delay = first.getDelay(NANOSECONDS); if (delay &lt;= 0) return finishPoll(first); first = null; // don't retain ref while waiting if (leader != null) // leader不为空，阻塞线程 available.await(); else &#123; // leader为空，则把leader设置为当前线程 Thread thisThread = Thread.currentThread(); leader = thisThread; try &#123; // 阻塞到执行时间 available.awaitNanos(delay); &#125; finally &#123; // 设置leader = null，让其他线程执行available.awaitNanos(delay); if (leader == thisThread) leader = null; &#125; &#125; &#125; &#125; &#125; finally &#123; // 如果leader不为空，则说明leader的线程正在执行available.awaitNanos(delay); // 如果queue[0] == null，说明队列为空 if (leader == null &amp;&amp; queue[0] != null) available.signal(); lock.unlock(); &#125;&#125; take方法是什么时候调用的呢，工作线程会循环地从workQueue中取任务。但定时任务却不同，因为如果一旦getTask方法取出了任务就开始执行了，而这时可能还没有到执行的时间，所以在take方法中，要保证只有在到指定的执行时间的时候任务才可以被取走。 再来说一下leader的作用，这里的leader是为了减少不必要的定时等待，当一个线程成为leader时，它只等待下一个节点的时间间隔，但其它线程无限期等待。 leader线程必须在从take（）或poll（）返回之前signal其它线程，除非其他线程成为了leader。 举例来说，如果没有leader，那么在执行take时，都要执行available.awaitNanos(delay)，假设当前线程执行了该段代码，这时还没有signal，第二个线程也执行了该段代码，则第二个线程也要被阻塞。多个这时执行该段代码是没有作用的，因为只能有一个线程会从take中返回queue[0]（因为有lock），其他线程这时再返回for循环执行时取的queue[0]，已经不是之前的queue[0]了，然后又要继续阻塞。 所以，为了不让多个线程频繁的做无用的定时等待，这里增加了leader，如果leader不为空，则说明队列中第一个节点已经在等待出队，这时其它的线程会一直阻塞，减少了无用的阻塞（注意，在finally中调用了signal()来唤醒一个线程，而不是signalAll()）。 poll方法与take类似，但这里要提供超时功能123456789101112131415161718192021222324252627282930313233343536373839404142434445464748public RunnableScheduledFuture&lt;?&gt; poll(long timeout, TimeUnit unit) throws InterruptedException &#123; long nanos = unit.toNanos(timeout); final ReentrantLock lock = this.lock; lock.lockInterruptibly(); try &#123; for (;;) &#123; RunnableScheduledFuture&lt;?&gt; first = queue[0]; if (first == null) &#123; if (nanos &lt;= 0) return null; else nanos = available.awaitNanos(nanos); &#125; else &#123; long delay = first.getDelay(NANOSECONDS); // 如果delay &lt;= 0，说明已经到了任务执行的时间，返回 if (delay &lt;= 0) return finishPoll(first); // 如果nanos &lt;= 0，说明已经超时，返回null if (nanos &lt;= 0) return null; first = null; // don't retain ref while waiting // nanos &lt; delay 说明需要等待的时间小于任务要执行的延迟时间 // leader != null 说明有其它线程正在对任务进行阻塞 // 这时阻塞当前线程nanos纳秒 if (nanos &lt; delay || leader != null) nanos = available.awaitNanos(nanos); else &#123; Thread thisThread = Thread.currentThread(); leader = thisThread; try &#123; // 这里的timeLeft表示delay减去实际的等待时间 long timeLeft = available.awaitNanos(delay); // 计算剩余的等待时间 nanos -= delay - timeLeft; &#125; finally &#123; if (leader == thisThread) leader = null; &#125; &#125; &#125; &#125; &#125; finally &#123; if (leader == null &amp;&amp; queue[0] != null) available.signal(); lock.unlock(); &#125;&#125; finishPoll方法当调用了take或者poll方法能够获取到任务时，会调用该方法进行返回：123456789101112131415161718/** * Performs common bookkeeping for poll and take: Replaces * first element with last and sifts it down. Call only when * holding lock. * @param f the task to remove and return */private RunnableScheduledFuture&lt;?&gt; finishPoll(RunnableScheduledFuture&lt;?&gt; f) &#123; // 数组长度-1 int s = --size; // 取出最后一个节点 RunnableScheduledFuture&lt;?&gt; x = queue[s]; queue[s] = null; // 长度不为0，则从第一个元素开始排序，目的是要把最后一个节点放到合适的位置上 if (s != 0) siftDown(0, x); setIndex(f, -1); return f;&#125; siftDown方法siftDown方法使堆从k开始向下调整1234567891011121314151617181920212223242526272829/** * Sifts element added at top down to its heap-ordered spot. * Call only when holding lock. */private void siftDown(int k, RunnableScheduledFuture&lt;?&gt; key) &#123; // 根据二叉树的特性，数组长度除以2，表示取有子节点的索引 int half = size &gt;&gt;&gt; 1; // 判断索引为k的节点是否有子节点 while (k &lt; half) &#123; // 左子节点的索引 int child = (k &lt;&lt; 1) + 1; RunnableScheduledFuture&lt;?&gt; c = queue[child]; // 右子节点的索引 int right = child + 1; // 如果有右子节点并且左子节点的时间间隔大于右子节点，取时间间隔最小的节点 if (right &lt; size &amp;&amp; c.compareTo(queue[right]) &gt; 0) c = queue[child = right]; // 如果key的时间间隔小于等于c的时间间隔，跳出循环 if (key.compareTo(c) &lt;= 0) break; queue[k] = c; // 设置要移除索引的节点为其子节点 setIndex(c, k); k = child; &#125; queue[k] = key; // 将key放入索引为k的位置 setIndex(key, k);&#125; siftDown方法执行时包含两种情况，一种是没有子节点，一种是有子节点（根据half判断）。例如： 没有子节点的情况： 假设初始的堆如下： 假设 k = 3 ，那么 k = half ，没有子节点，在执行siftDown方法时直接把索引为3的节点设置为数组的最后一个节点： 有子节点的情况： 假设 k = 0 ，那么执行以下步骤： 获取左子节点，child = 1 ，获取右子节点， right = 2 ： 由于 right &lt; size ，这时比较左子节点和右子节点时间间隔的大小，这里 3 &lt; 7 ，所以 c = queue[child] 比较key的时间间隔是否小于c的时间间隔，这里不满足，继续执行，把索引为k的节点设置为c，然后将k设置为child 因为 half = 3 ，k = 1 ，继续执行循环，这时的索引变为 这时再经过如上判断后，将k的值为3，最终的结果如下 最后，如果在finishPoll方法中调用的话，会把索引为0的节点的索引设置为-1，表示已经删除了该节点，并且size也减了1，最后的结果如下 可见，siftdown方法在执行完并不是有序的，但可以发现，子节点的下次执行时间一定比父节点的下次执行时间要大，由于每次都会取左子节点和右子节点中下次执行时间最小的节点，所以还是可以保证在take和poll时出队是有序的。 remove方法1234567891011121314151617181920212223242526public boolean remove(Object x) &#123; final ReentrantLock lock = this.lock; lock.lock(); try &#123; int i = indexOf(x); if (i &lt; 0) return false; setIndex(queue[i], -1); int s = --size; RunnableScheduledFuture&lt;?&gt; replacement = queue[s]; queue[s] = null; if (s != i) &#123; // 从i开始向下调整 siftDown(i, replacement); // 如果queue[i] == replacement，说明i是叶子节点 // 如果是这种情况，不能保证子节点的下次执行时间比父节点的大 // 这时需要进行一次向上调整 if (queue[i] == replacement) siftUp(i, replacement); &#125; return true; &#125; finally &#123; lock.unlock(); &#125;&#125; 假设初始的堆结构如下： 这时要删除8的节点，那么这时 k = 1，key为最后一个节点： 这时通过上文对siftDown方法的分析，siftDown方法执行后的结果如下： 这时会发现，最后一个节点的值比父节点还要小，所以这里要执行一次siftUp方法来保证子节点的下次执行时间要比父节点的大，所以最终结果如下： 总结本文详细分析了ScheduedThreadPoolExecutor的实现，主要介绍了以下方面： 与Timer执行定时任务的比较，相比Timer，ScheduedThreadPoolExecutor有什么优点； ScheduledThreadPoolExecutor继承自ThreadPoolExecutor，所以它也是一个线程池，也有coorPoolSize和workQueue，ScheduledThreadPoolExecutor特殊的地方在于，自己实现了优先工作队列DelayedWorkQueue； ScheduedThreadPoolExecutor实现了ScheduledExecutorService，所以就有了任务调度的方法，如schedule，scheduleAtFixedRate和scheduleWithFixedDelay，同时注意他们之间的区别； 内部类ScheduledFutureTask继承自FutureTask，实现了任务的异步执行并且可以获取返回结果。同时也实现了Delayed接口，可以通过getDelay方法获取将要执行的时间间隔； 周期任务的执行其实是调用了FutureTask类中的runAndReset方法，每次执行完不设置结果和状态。参考FutureTask源码解析； 详细分析了DelayedWorkQueue的数据结构，它是一个基于最小堆结构的优先队列，并且每次出队时能够保证取出的任务是当前队列中下次执行时间最小的任务。同时注意一下优先队列中堆的顺序，堆中的顺序并不是绝对的，但要保证子节点的值要比父节点的值要大，这样就不会影响出队的顺序。 总体来说，ScheduedThreadPoolExecutor的重点是要理解下次执行时间的计算，以及优先队列的出队、入队和删除的过程，这两个是理解ScheduedThreadPoolExecutor的关键。]]></content>
      <categories>
        <category>juc</category>
      </categories>
      <tags>
        <tag>ScheduledThreadPoolExecutor</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java线程池ScheduledThreadPoolExecutor分析1]]></title>
    <url>%2F2018%2F11%2F27%2FJava%E7%BA%BF%E7%A8%8B%E6%B1%A0ScheduledThreadPoolExecutor%E5%88%86%E6%9E%901%2F</url>
    <content type="text"><![CDATA[简介自JDK1.5开始，JDK提供了ScheduledThreadPoolExecutor类来支持周期性任务的调度。在这之前的实现需要依靠Timer和TimerTask或者其它第三方工具来完成。但Timer有不少的缺陷： Timer是单线程模式； 如果在执行任务期间某个TimerTask耗时较久，那么就会影响其它任务的调度； Timer的任务调度是基于绝对时间的，对系统时间敏感； Timer不会捕获执行TimerTask时所抛出的异常，由于Timer是单线程，所以一旦出现异常，则线程就会终止，其他任务也得不到执行。 ScheduledThreadPoolExecutor继承ThreadPoolExecutor来重用线程池的功能，它的实现方式如下： 将任务封装成ScheduledFutureTask对象，ScheduledFutureTask基于相对时间，不受系统时间的改变所影响； ScheduledFutureTask实现了java.lang.Comparable接口和java.util.concurrent.Delayed接口，所以有两个重要的方法：compareTo和getDelay。compareTo方法用于比较任务之间的优先级关系，如果距离下次执行的时间间隔较短，则优先级高；getDelay方法用于返回距离下次任务执行时间的时间间隔； ScheduledThreadPoolExecutor定义了一个DelayedWorkQueue，它是一个有序队列，会通过每个任务按照距离下次执行时间间隔的大小来排序； ScheduledFutureTask继承自FutureTask，可以通过返回Future对象来获取执行的结果。 类图 从ScheduledThreadPoolExecutor类声明可以看出： ScheduledThreadPoolExecutor是ThreadPoolExecutor的子类，并且实现了接口ScheduledExecutorService； Demo12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849package com.fly.learn.executor;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import java.util.concurrent.ExecutorService;import java.util.concurrent.Executors;import java.util.concurrent.ScheduledExecutorService;import java.util.concurrent.TimeUnit;import java.util.concurrent.atomic.AtomicInteger;/** * 线程池test * @author: peijiepang * @date 2018/11/23 * @Description: */public class ThreadPoolExecutorTest &#123; private final static Logger LOGGER = LoggerFactory.getLogger(ThreadPoolExecutorTest.class); //private static ThreadPoolExecutor executor = new ThreadPoolExecutor(5, 10, 30, TimeUnit.SECONDS, new ArrayBlockingQueue&lt;Runnable&gt;(10)); //private static Executor executor = Executors.newFixedThreadPool(5); //private static Executor executor = Executors.newSingleThreadExecutor(); //private static Executor executor = Executors.newCachedThreadPool(); private static ScheduledExecutorService executor = Executors.newScheduledThreadPool(5); private AtomicInteger i = new AtomicInteger(0); public void executeTask()&#123; Task1 task1 = new Task1();//构建任务// executor.execute(task1);//执行任务 executor.scheduleAtFixedRate(task1,0,1,TimeUnit.SECONDS); &#125; /* * 基本任务 */ class Task1 implements Runnable&#123; public void run() &#123; //具体任务的业务 LOGGER.info("&#123;&#125;...",i.incrementAndGet()); &#125; &#125; public static void main(String[] args) throws InterruptedException &#123; ThreadPoolExecutorTest test = new ThreadPoolExecutorTest(); test.executeTask(); &#125;&#125; 源码解析构造函数1234567891011121314151617181920212223public ScheduledThreadPoolExecutor(int corePoolSize) &#123; super(corePoolSize, Integer.MAX_VALUE, 0, NANOSECONDS, new DelayedWorkQueue());&#125;public ScheduledThreadPoolExecutor(int corePoolSize, ThreadFactory threadFactory) &#123; super(corePoolSize, Integer.MAX_VALUE, 0, NANOSECONDS, new DelayedWorkQueue(), threadFactory);&#125;public ScheduledThreadPoolExecutor(int corePoolSize, RejectedExecutionHandler handler) &#123; super(corePoolSize, Integer.MAX_VALUE, 0, NANOSECONDS, new DelayedWorkQueue(), handler);&#125;public ScheduledThreadPoolExecutor(int corePoolSize, ThreadFactory threadFactory, RejectedExecutionHandler handler) &#123; super(corePoolSize, Integer.MAX_VALUE, 0, NANOSECONDS, new DelayedWorkQueue(), threadFactory, handler);&#125; 从构造方法可以看出，ScheduledThreadPoolExecutor使用DelayQueue来作为线程池的工作队列，由于DelayQueue是无界队列，根据线程池的工作原理，核心参数maximumPoolSize在ScheduledThreadPoolExecutor中是没有什么意义的。总的来说，ScheduledThreadPoolExecutor为了实现周期性执行任务，对ThreadPoolExecutor做了以下改动： 工作队列使用DelayQueue； 任务提交之后统统都进工作队列； 获取任务的方式改变，执行了任务之后，也增加了额外的处理，具体的改变后文会一一给出详细的分析。 任务提交与调度12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485/** * @throws RejectedExecutionException &#123;@inheritDoc&#125; * @throws NullPointerException &#123;@inheritDoc&#125; */public ScheduledFuture&lt;?&gt; schedule(Runnable command, long delay, TimeUnit unit) &#123; if (command == null || unit == null) throw new NullPointerException(); RunnableScheduledFuture&lt;?&gt; t = decorateTask(command, new ScheduledFutureTask&lt;Void&gt;(command, null, triggerTime(delay, unit))); delayedExecute(t); return t;&#125;/** * @throws RejectedExecutionException &#123;@inheritDoc&#125; * @throws NullPointerException &#123;@inheritDoc&#125; */public &lt;V&gt; ScheduledFuture&lt;V&gt; schedule(Callable&lt;V&gt; callable, long delay, TimeUnit unit) &#123; if (callable == null || unit == null) throw new NullPointerException(); RunnableScheduledFuture&lt;V&gt; t = decorateTask(callable, new ScheduledFutureTask&lt;V&gt;(callable, triggerTime(delay, unit))); delayedExecute(t); return t;&#125; /** * 提交延时任务，下一次执行时间相当于是上一次的执行时间加上period，它是采用已固定的频率来执行任务 * @throws RejectedExecutionException &#123;@inheritDoc&#125; * @throws NullPointerException &#123;@inheritDoc&#125; * @throws IllegalArgumentException &#123;@inheritDoc&#125; */public ScheduledFuture&lt;?&gt; scheduleAtFixedRate(Runnable command, long initialDelay, long period, TimeUnit unit) &#123; if (command == null || unit == null) throw new NullPointerException(); if (period &lt;= 0) throw new IllegalArgumentException(); //构造ScheduledFutureTask ScheduledFutureTask&lt;Void&gt; sft = new ScheduledFutureTask&lt;Void&gt;(command, null, triggerTime(initialDelay, unit), unit.toNanos(period)); //提供可被子类重载或者修改的方法 RunnableScheduledFuture&lt;Void&gt; t = decorateTask(command, sft); sft.outerTask = t; //真正提交任务 delayedExecute(t); return t;&#125;/** * 与scheduleAtFixedRate方法不同的是，下一次执行时间是上一次任务执行完的系统时间加上period， * 因而具体执行时间不是固定的，但周期是固定的，是采用相对固定的延迟来执行任务 * @throws RejectedExecutionException &#123;@inheritDoc&#125; * @throws NullPointerException &#123;@inheritDoc&#125; * @throws IllegalArgumentException &#123;@inheritDoc&#125; */public ScheduledFuture&lt;?&gt; scheduleWithFixedDelay(Runnable command, long initialDelay, long delay, TimeUnit unit) &#123; if (command == null || unit == null) throw new NullPointerException(); if (delay &lt;= 0) throw new IllegalArgumentException(); ScheduledFutureTask&lt;Void&gt; sft = new ScheduledFutureTask&lt;Void&gt;(command, null, triggerTime(initialDelay, unit), unit.toNanos(-delay)); RunnableScheduledFuture&lt;Void&gt; t = decorateTask(command, sft); sft.outerTask = t; delayedExecute(t); return t;&#125; ScheduledFutureTask123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181// 任务被添加到ScheduledThreadPoolExecutor中的序号/** Sequence number to break ties FIFO */private final long sequenceNumber;// 任务将要被执行的具体时间/** The time the task is enabled to execute in nanoTime units */private long time;/** * 任务执行的间隔周期 * Period in nanoseconds for repeating tasks. A positive * value indicates fixed-rate execution. A negative value * indicates fixed-delay execution. A value of 0 indicates a * non-repeating task. */private final long period;/** * Creates a one-shot action with given nanoTime-based trigger time. */ScheduledFutureTask(Runnable r, V result, long ns) &#123; super(r, result); this.time = ns; this.period = 0; this.sequenceNumber = sequencer.getAndIncrement();&#125;/** * Creates a periodic action with given nano time and period. */ScheduledFutureTask(Runnable r, V result, long ns, long period) &#123; super(r, result); this.time = ns; this.period = period; this.sequenceNumber = sequencer.getAndIncrement();&#125;/** * Creates a one-shot action with given nanoTime-based trigger time. */ScheduledFutureTask(Callable&lt;V&gt; callable, long ns) &#123; super(callable); this.time = ns; this.period = 0; this.sequenceNumber = sequencer.getAndIncrement();&#125;/** * ScheduledThreadPoolExecutor会把待执行的任务放到工作队列DelayQueue中， * DelayQueue封装了一个PriorityQueue，PriorityQueue会对队列中的ScheduledFutureTask进行排序 * @param other * @return */public int compareTo(Delayed other) &#123; if (other == this) // compare zero if same object return 0; if (other instanceof ScheduledFutureTask) &#123; ScheduledFutureTask&lt;?&gt; x = (ScheduledFutureTask&lt;?&gt;)other; long diff = time - x.time; //首先按照time排序，time小的排在前面，time大的排在后面； //如果time相同，按照sequenceNumber排序，sequenceNumber小的排在前面， //sequenceNumber大的排在后面，换句话说，如果两个task的执行时间相同，优先执行先提交的task。 if (diff &lt; 0) return -1; else if (diff &gt; 0) return 1; else if (sequenceNumber &lt; x.sequenceNumber) return -1; else return 1; &#125; long diff = getDelay(NANOSECONDS) - other.getDelay(NANOSECONDS); return (diff &lt; 0) ? -1 : (diff &gt; 0) ? 1 : 0;&#125;public long getDelay(TimeUnit unit) &#123; //执行时间减去当前系统时间 return unit.convert(time - now(), NANOSECONDS);&#125;/** * 任务执行逻辑 * Overrides FutureTask version so as to reset/requeue if periodic. */public void run() &#123; // 是否是周期性任务 boolean periodic = isPeriodic(); // 当前线程池运行状态下如果不可以执行任务，取消该任务 if (!canRunInCurrentRunState(periodic)) cancel(false); // 如果不是周期性任务，调用FutureTask中的run方法执行 else if (!periodic) ScheduledFutureTask.super.run(); // 如果是周期性任务，调用FutureTask中的runAndReset方法执行 // runAndReset方法不会设置执行结果，所以可以重复执行任务 else if (ScheduledFutureTask.super.runAndReset()) &#123; setNextRunTime(); reExecutePeriodic(outerTask); &#125;&#125;/** * 设置下次执行时间 * Sets the next time to run for a periodic task. */private void setNextRunTime() &#123; long p = period; if (p &gt; 0) time += p; else time = triggerTime(-p);&#125;/** * 取消任务 * @param mayInterruptIfRunning * @return */public boolean cancel(boolean mayInterruptIfRunning) &#123; boolean cancelled = super.cancel(mayInterruptIfRunning); if (cancelled &amp;&amp; removeOnCancel &amp;&amp; heapIndex &gt;= 0) remove(this); return cancelled;&#125;/** * 周期性任务，重新添加任务 * Requeues a periodic task unless current run state precludes it. * Same idea as delayedExecute except drops task rather than rejecting. * * @param task the task */void reExecutePeriodic(RunnableScheduledFuture&lt;?&gt; task) &#123; if (canRunInCurrentRunState(true)) &#123; super.getQueue().add(task); if (!canRunInCurrentRunState(true) &amp;&amp; remove(task)) task.cancel(false); else //添加工作work线程 ensurePrestart(); &#125;&#125;/** * ThreadPoolExecutor中的钩子方法 * Cancels and clears the queue of all tasks that should not be run * due to shutdown policy. Invoked within super.shutdown. */@Override void onShutdown() &#123; BlockingQueue&lt;Runnable&gt; q = super.getQueue(); // 获取在线程池已 shutdown 的情况下是否继续执行现有延迟任务 boolean keepDelayed = getExecuteExistingDelayedTasksAfterShutdownPolicy(); // 获取在线程池已 shutdown 的情况下是否继续执行现有定期任务 boolean keepPeriodic = getContinueExistingPeriodicTasksAfterShutdownPolicy(); // 如果在线程池已 shutdown 的情况下不继续执行延迟任务和定期任务 // 则依次取消任务，否则则根据取消状态来判断 if (!keepDelayed &amp;&amp; !keepPeriodic) &#123; for (Object e : q.toArray()) if (e instanceof RunnableScheduledFuture&lt;?&gt;) ((RunnableScheduledFuture&lt;?&gt;) e).cancel(false); q.clear(); &#125; else &#123; // Traverse snapshot to avoid iterator exceptions for (Object e : q.toArray()) &#123; if (e instanceof RunnableScheduledFuture) &#123; RunnableScheduledFuture&lt;?&gt; t = (RunnableScheduledFuture&lt;?&gt;)e; // 如果有在 shutdown 后不继续的延迟任务或周期任务，则从队列中删除并取消任务 if ((t.isPeriodic() ? !keepPeriodic : !keepDelayed) || t.isCancelled()) &#123; // also remove if already cancelled if (q.remove(t)) t.cancel(false); &#125; &#125; &#125; &#125; tryTerminate();&#125; delayedExecute1234567891011121314151617181920212223242526private void delayedExecute(RunnableScheduledFuture&lt;?&gt; task) &#123; // 如果线程池已经关闭，使用拒绝策略拒绝任务 if (isShutdown()) reject(task); else &#123; // 添加到阻塞队列中 super.getQueue().add(task); if (isShutdown() &amp;&amp; !canRunInCurrentRunState(task.isPeriodic()) &amp;&amp; remove(task)) task.cancel(false); else // 确保线程池中至少有一个线程启动，即使corePoolSize为0 // 该方法在ThreadPoolExecutor中实现 ensurePrestart(); &#125;&#125;//aqs源码void ensurePrestart() &#123; int wc = workerCountOf(ctl.get()); if (wc &lt; corePoolSize) addWorker(null, true); else if (wc == 0) addWorker(null, false);&#125; 总结ScheduledThreadPoolExecutor继承自ThreadPoolExecutor，实现了ScheduledExecutorService接口，该接口定义了schedule等任务调度的方法。同时ScheduledThreadPoolExecutor有两个重要的内部类：DelayedWorkQueue和ScheduledFutureTask。ScheduledFutureTask继承自FutureTask，并且实现了Delayed接口，DelayedWorkQueue将会在接下来的篇幅分析，敬请期待。]]></content>
      <categories>
        <category>juc</category>
      </categories>
      <tags>
        <tag>ScheduledThreadPoolExecutor</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java线程池Executors分析]]></title>
    <url>%2F2018%2F11%2F23%2FJava%E7%BA%BF%E7%A8%8B%E6%B1%A0Executors%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[简介Executors 这个类，因为它仅仅是工具类，它的所有方法都是 static 的。 Demo123456789101112131415161718192021222324252627282930313233343536373839404142434445464748package com.fly.learn.executor;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import java.util.concurrent.Executor;import java.util.concurrent.ExecutorService;import java.util.concurrent.Executors;/** * 线程池test * @author: peijiepang * @date 2018/11/23 * @Description: */public class ThreadPoolExecutorTest &#123; private final static Logger LOGGER = LoggerFactory.getLogger(ThreadPoolExecutorTest.class); //private static ThreadPoolExecutor executor = new ThreadPoolExecutor(5, 10, 30, TimeUnit.SECONDS, new ArrayBlockingQueue&lt;Runnable&gt;(10)); //private static Executor executor = Executors.newFixedThreadPool(5); //private static Executor executor = Executors.newSingleThreadExecutor(); //private static Executor executor = Executors.newCachedThreadPool(); private static ExecutorService executor = Executors.newScheduledThreadPool(5); public void executeTask()&#123; Task1 task1 = new Task1();//构建任务 executor.execute(task1);//执行任务 &#125; /* * 基本任务2 */ class Task1 implements Runnable&#123; public void run() &#123; //具体任务的业务 for(int i=0;i&lt;1000;i++)&#123; LOGGER.info("&#123;&#125;...",i); &#125; &#125; &#125; public static void main(String[] args) &#123; ThreadPoolExecutorTest test = new ThreadPoolExecutorTest(); test.executeTask(); executor.shutdown(); while (!executor.isTerminated())&#123; LOGGER.info("finish......"); &#125; &#125;&#125; Executors可以创建的几种线程 newFixedThreadPool(int corePoolSize) 创建一个线程数固定（corePoolSize==maximumPoolSize）的线程池 核心线程会一直运行 如果一个核心线程由于异常挂了，会新创建一个线程 无界队列LinkedBlockingQueue newSingleThreadExecutor 创建一个线程数固定（corePoolSize==maximumPoolSize==1）的线程池 核心线程会一直运行 无界队列LinkedBlockingQueue 所有task都是串行执行的（即同一时刻只有一个任务在执行） newCachedThreadPool corePoolSize==0 maximumPoolSize==Integer.MAX_VALUE 队列：SynchronousQueue 创建一个线程池：当池中的线程都处于忙碌状态时，会立即新建一个线程来处理新来的任务 这种池将会在执行许多耗时短的异步任务的时候提高程序的性能 60秒内没有使用的线程将会被中止，并且从线程池中移除，因此几乎不必担心耗费资源 newScheduledThreadPool(int corePoolSize) 用于执行定时或延迟执行的任务，最典型的：异步操作时的超时回调 源码分析123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129/** * 1、创建一个线程数固定（corePoolSize==maximumPoolSize）的线程池, * 2、核心线程会一直运行 * 3、无界队列LinkedBlockingQueue */public static ExecutorService newFixedThreadPool(int nThreads) &#123; return new ThreadPoolExecutor(nThreads, nThreads, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;());&#125;public static ExecutorService newFixedThreadPool(int nThreads, ThreadFactory threadFactory) &#123; return new ThreadPoolExecutor(nThreads, nThreads, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;(), threadFactory);&#125;/** * 用于创建ForkJoin框架中用到的ForkJoinPool线程 * @param parallelism 并行数 * @return */public static ExecutorService newWorkStealingPool(int parallelism) &#123; return new ForkJoinPool (parallelism, ForkJoinPool.defaultForkJoinWorkerThreadFactory, null, true);&#125;public static ExecutorService newWorkStealingPool() &#123; return new ForkJoinPool (Runtime.getRuntime().availableProcessors(), ForkJoinPool.defaultForkJoinWorkerThreadFactory, null, true);&#125;/** * 1、创建一个线程数固定（corePoolSize==maximumPoolSize==1）的线程池 * 2、核心线程会一直运行 * 3、无界队列LinkedBlockingQueue * 注意：所有task都是串行执行的 */public static ExecutorService newSingleThreadExecutor() &#123; return new FinalizableDelegatedExecutorService (new ThreadPoolExecutor(1, 1, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;()));&#125;public static ExecutorService newSingleThreadExecutor(ThreadFactory threadFactory) &#123; return new FinalizableDelegatedExecutorService (new ThreadPoolExecutor(1, 1, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;(), threadFactory));&#125;/** * 1、创建一个线程池：当池中的线程都处于忙碌状态时，会立即新建一个线程来处理新来的任务 * 2、这种池将会在执行许多耗时短的异步任务的时候提高程序的性能。 * 3、60秒内没有使用的线程将会被中止，并且从线程池中移除，因此几乎不必担心耗费资源 * 4、队列：SynchronousQueue * 5、maximumPoolSize为Integer.MAX_VALUE */public static ExecutorService newCachedThreadPool() &#123; return new ThreadPoolExecutor(0, Integer.MAX_VALUE, 60L, TimeUnit.SECONDS, new SynchronousQueue&lt;Runnable&gt;());&#125;public static ExecutorService newCachedThreadPool(ThreadFactory threadFactory) &#123; return new ThreadPoolExecutor(0, Integer.MAX_VALUE, 60L, TimeUnit.SECONDS, new SynchronousQueue&lt;Runnable&gt;(), threadFactory);&#125;/** * 创建一个线程池：该线程池可以用于执行延时任务或者定时任务 */public static ScheduledExecutorService newSingleThreadScheduledExecutor() &#123; return new DelegatedScheduledExecutorService (new ScheduledThreadPoolExecutor(1));&#125;public static ScheduledExecutorService newSingleThreadScheduledExecutor(ThreadFactory threadFactory) &#123; return new DelegatedScheduledExecutorService (new ScheduledThreadPoolExecutor(1, threadFactory));&#125;public static ScheduledExecutorService newScheduledThreadPool(int corePoolSize) &#123; return new ScheduledThreadPoolExecutor(corePoolSize);&#125;public static ScheduledExecutorService newScheduledThreadPool( int corePoolSize, ThreadFactory threadFactory) &#123; return new ScheduledThreadPoolExecutor(corePoolSize, threadFactory);&#125;/** * 主要用于包装现有的线程池，包装之后的线程池不能修改 * @param executor * @return */public static ExecutorService unconfigurableExecutorService(ExecutorService executor) &#123; if (executor == null) throw new NullPointerException(); return new DelegatedExecutorService(executor);&#125;/** * 用于包装可以周期性执行任务的线程池，包装之后的线程池不能修改 * @param executor * @return */public static ScheduledExecutorService unconfigurableScheduledExecutorService(ScheduledExecutorService executor) &#123; if (executor == null) throw new NullPointerException(); return new DelegatedScheduledExecutorService(executor);&#125;/** * 默认的工厂方法类 * @return */public static ThreadFactory defaultThreadFactory() &#123; return new DefaultThreadFactory();&#125;]]></content>
      <categories>
        <category>juc</category>
      </categories>
      <tags>
        <tag>executors</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[分布式事务在Sharding-Sphere中的实现]]></title>
    <url>%2F2018%2F11%2F23%2F%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1%E5%9C%A8Sharding-Sphere%E4%B8%AD%E7%9A%84%E5%AE%9E%E7%8E%B0%2F</url>
    <content type="text"><![CDATA[本文根据dbaplus社群第156期线上分享整理而成.地址：https://m.qlchat.com/topic/details?topicId=2000001669563722&amp;tracePage=liveCenter 讲解人：赵俊 京东金融高级Java开发工程师 分布式事务的使用场景ACID Atomicity：原子性 事务作为整体来执行，要么全部执行，要么全不执行。 Consistency：一致性 事务应确保数据从一个一致的状态转变为另一个一致的状态。 Isolation：隔离性 多个事务并发执行时，一个事务的执行不应影响其他事务的执行。 Durability：持久性 已提交的事务修改数据会被持久保持。 关系型数据库的本地事务完美的提供了对ACID的原生支持。但在分布式的场景下，它却成为系统性能的桎梏。如何让数据库在分布式场景下满足ACID的特性或找寻相应的替代方案，是本文将要阐述的话题。 CAP和Base理论对于互联网应用而言，随着访问量和数据量的激增，传统的单体架构模式将无法满足业务的高速发展。这时，开发者需要把单体应用拆分为多个独立的小应用，把单个数据库按照分片规则拆分为多个库和多个表。 数据拆分后，如何在多个数据库节点间保证本地事务的ACID特性则成为一个技术难题，并且由此而衍生出了CAP和BASE经典理论。 CAP理论指出，对于分布式的应用而言，不可能同时满足C（一致性），A（可用性），P（分区容错性），由于网络分区是分布式应用的基本要素，因此开发者需要在C和A上做出平衡。 由于C和A互斥性，其权衡的结果就是BASE理论。 对于大部分的分布式应用而言，只要数据在规定的时间内达到最终一致性即可。我们可以把符合传统的ACID叫做刚性事务，把满足BASE理论的最终一致性事务叫做柔性事务。 一味的追求强一致性，并非最佳方案。对于分布式应用来说，刚柔并济是更加合理的设计方案，即在本地服务中采用强一致事务，在跨系统调用中采用最终一致性。如何权衡系统的性能与一致性，是十分考验架构师与开发者的设计功力的。 业界方法具体到分布式事务的实现上，业界主要采用了XA协议的强一致规范以及柔性事务的最终一致规范。 XA事物XA是X/Open CAE Specification (Distributed Transaction Processing)模型中定义的TM（Transaction Manager）与RM（Resource Manager）之间进行通信的接口。 Java中的javax.transaction.xa.XAResource定义了XA接口，它依赖数据库厂商对jdbc-driver的具体实现。 mysql-connector-java-5.1.30的实现可参考com.mysql.jdbc.jdbc2.optional.MysqlXAConnection。 在XA规范中，数据库充当RM角色，应用需要充当TM的角色，即生成全局的txId，调用XAResource接口，把多个本地事务协调为全局统一的分布式事务。 一阶段提交：弱XA 弱XA通过去掉XA的Prepare阶段，以达到减少资源锁定范围而提升并发性能的效果。典型的实现为在一个业务线程中，遍历所有的数据库连接，依次做commit或者rollback。弱XA同本地事务相比，性能损耗低，但在事务提交的执行过程中，若出现网络故障、数据库宕机等预期之外的异常，将会造成数据不一致，且无法进行回滚。基于弱XA的事务无需额外的实现成本，因此Sharding-Sphere默认支持。 二阶段提交：2PC 二阶段提交是XA的标准实现。它将分布式事务的提交拆分为2个阶段：prepare和commit/rollback。 开启XA全局事务后，所有子事务会按照本地默认的隔离级别锁定资源，并记录undo和redo日志，然后由TM发起prepare投票，询问所有的子事务是否可以进行提交：当所有子事务反馈的结果为“yes”时，TM再发起commit；若其中任何一个子事务反馈的结果为“no”，TM则发起rollback；如果在prepare阶段的反馈结果为yes，而commit的过程中出现宕机等异常时，则在节点服务重启后，可根据XA recover再次进行commit补偿，以保证数据的一致性。 2PC模型中，在prepare阶段需要等待所有参与子事务的反馈，因此可能造成数据库资源锁定时间过长，不适合并发高以及子事务生命周长较长的业务场景。 Sharding-Sphere支持基于XA的强一致性事务解决方案，可以通过SPI注入不同的第三方组件作为事务管理器实现XA协议，如Atomikos和Narayana。 柔性事务柔性事务是对XA协议的妥协和补偿，它通过对强一致性要求的降低，已达到降低数据库资源锁定时间的效果。柔性事务的种类很多，可以通过各种不同的策略来权衡使用。 一阶段提交 + 补偿 ：最大努力送达（BED） 最大努力送达，是针对于弱XA的一种补偿策略。它采用事务表记录所有的事务操作SQL，如果子事务提交成功，将会删除事务日志；如果执行失败，则会按照配置的重试次数，尝试再次提交，即最大努力的进行提交，尽量保证数据的一致性，这里可以根据不同的业务场景，平衡C和A，采用同步重试或异步重试。 这种策略的优点是无锁定资源时间，性能损耗小。缺点是尝试多次提交失败后，无法回滚，它仅适用于事务最终一定能够成功的业务场景。因此BED是通过事务回滚功能上的妥协，来换取性能的提升。 TCC： Try-Confirm-CancelTCC模型是把锁的粒度完全交给业务处理，它需要每个子事务业务都实现Try-Confirm/Cancel接口。 Try: 尝试执行业务；完成所有业务检查（一致性）；预留必须业务资源（准隔离性）； Confirm: 确认执行业务；真正执行业务，不作任何业务检查；只使用Try阶段预留的业务资源；Confirm操作满足幂等性； Cancel: 取消执行业务；释放Try阶段预留的业务资源；Cancel操作满足幂等性。 这三个阶段都会按本地事务的方式执行，不同于XA的prepare，TCC无需将XA的投票期间的所有资源挂起，因此极大的提高了吞吐量。 下面对TCC模式下，A账户往B账户汇款100元为例子，对业务的改造进行详细的分析： 汇款服务和收款服务分别需要实现，Try-Confirm-Cancel接口，并在业务初始化阶段将其注入到TCC事务管理器中。 消息驱动 消息一致性方案是通过消息中间件保证上下游应用数据操作的一致性。基本思路是将本地操作和发送消息放在一个事务中，下游应用向消息系统订阅该消息，收到消息后执行相应操作。本质上是依靠消息的重试机制，达到最终一致性。消息驱动的缺点是：耦合度高，需要在业务系统中引入MQ，导致系统复杂度增加。 SAGASaga起源于1987年Hector &amp; Kenneth发表的论文Sagas。 参考地址：https://www.cs.cornell.edu/andru/cs711/2002fa/reading/sagas.pdf Saga工作原理 Saga模型把一个分布式事务拆分为多个本地事务，每个本地事务都有相应的执行模块和补偿模块（ TCC中的Confirm和Cancel）。当Saga事务中任意一个本地事务出错时，可以通过调用相关的补偿方法恢复之前的事务，达到事务最终的一致性。 当每个Saga子事务 T1, T2, …, Tn 都有对应的补偿定义 C1, C2, …, Cn-1,那么Saga系统可以保证： 子事务序列 T1, T2, …, Tn得以完成 (最佳情况)；或者序列 T1, T2, …, Tj, Cj, …, C2, C1, 0 &lt; j &lt; n, 得以完成。由于Saga模型中没有Prepare阶段，因此事务间不能保证隔离性，当多个Saga事务操作同一资源时，就会产生更新丢失、脏数据读取等问题，这时需要在业务层控制并发，例如： 在应用层面加锁；应用层面预先冻结资源。Saga恢复方式 Saga支持向前和向后恢复： 向后恢复：补偿所有已完成的事务，如果任一子事务失败；向前恢复：重试失败的事务，假设每个子事务最终都会成功。显然，向前恢复没有必要提供补偿事务，如果你的业务中，子事务（最终）总会成功，或补偿事务难以定义或不可能，向前恢复更符合你的需求。理论上补偿事务永不失败，然而，在分布式世界中，服务器可能会宕机、网络可能会失败，甚至数据中心也可能会停电，这时需要提供故障恢复后回退的机制，比如人工干预。 总的来说，TCC和MQ都是以服务为范围进行分布式事务的处理，而XA、BED、SAGA则是以数据库为范围进行分布式处理，我们更趋向于选择后者，对于业务而言侵入小，改造的成本低。 Sharding-Sphere对分布式事务的支持Sharding-Sphere是一套开源的分布式数据库中间件解决方案组成的生态圈，它由Sharding-JDBC、Sharding-Proxy和Sharding-Sidecar这3款相互独立的产品组成。它们均提供标准化的数据分片、读写分离、柔性事务和数据治理功能，可适用于如Java同构、异构语言、容器、云原生等各种多样化的应用场景。 项目地址：https://github.com/sharding-sphere/sharding-sphere/ Sharding-Sphere同时支持XA和柔性事务，它允许每次对数据库的访问，可以自由选择事务类型。分布式事务对业务操作完全透明，极大地降低了引入分布式事务的成本。 事务模型 Sharding-Sphere事务管理器集成了XA和柔性事务模型： 对于XA事务而言，采用SPI的方式让弱XA、Atomikos、Narayana间保持互斥；对于柔性事务而言，根据每次连接中事务的类型，可以选择独立的事务管理器进行处理，每个事务管理器都会实现标准的ShardingTransaction接口，在TransactionEvent到来时，执行对应的begin、commit、rollback操作。下面将Sharding-Sphere内部如何用事件驱动方式，将事务从分片主流程中解耦进行详细说明： 从图可以看出在Sharding-core在调用执行引擎时，会根据SQL的种类产生事件进行分发。事务监听线程在收到符合要求的事件后，再调用对应的事务处理器进行处理。 Sharding-Proxy事务实现Sharding-Proxy是基于netty开发的数据库中间代理层，实现了标准的MySQL协议，可以看做是一个实现了数据分片的数据库。Sharding-Proxy已经实现了基于Atomikos的XA事务，为了保证所有的子事务都处于同一个线程之中，整个Proxy的线程模型进行了如下的调整： 当开启事务后，Proxy后端的SQL命令执行引擎将采用一通道一线程的模式，此事务线程的生命周期同通道保持一致。事务处理的具体过程与Proxy彻底解耦，即Proxy将发布事务类型的事件，然后Sharding-Sphere-TM根据传入的事务消息，选择具体的TM进行处理。 压测结果表明：XA事务的插入和更新的性能，基本上同跨库的个数呈线性关系，查询的性能基本不受影响，建议在并发量不大，每次事务涉及的库在10个以内时，可以使用XA。 Atomikos事务管理器原理分析 Atomikos的事务管理器可以内嵌到业务进程中，当应用调用TransactionManager.begin时，将会创建本次XA事务，并且与当前线程关联。同时Atomikos也对DataSource中的connection做了二次封装，代理connection中含有本次事务相关信息的状态，并且拦截了connection的JDBC操作。 在createStatement时，调用XAResource.start进行资源注册；在close时，调用XAResource.end让XA事务处于idel可提交状态；在commit或rollback时，依次调用prepare和commit进行二阶段提交。 Sharding-Sphere的Saga事务实现Sharding-Sphere通过与Apache Service Comb的合作，将采用Service Comb的Saga事务引擎作为的分布式事务实现。 Apache Service Comb是华为开源的微服务框架，其中微服务事务处理框架分为集中式和分布式协调器。未来会在Sharding-Sphere内部集成Saga集中式协调器，支持同一线程内不同服务（本地）间的分布式事务。 参考链接：https://github.com/apache/incubator-servicecomb-saga Service Comb 集中式事务协调器 集中式的协调器，包含了Saga调用请求接收、分析、执行以及结果查询的内容。任务代理模块需要预先知道Saga事务调用关系图，执行模块根据生成的调用图产生调用任务，调用相关微服务服务接口。如果服务调用执行出错，会调用服务的相关的补偿方法回滚。 Saga执行模块通过分析请求的JSON数据，来构建一个调用关系图。Sharding-Sphere是通过JSON描述Saga事务串行调用子事务或者并行调用子事务。关系调用图被Saga实现中的任务运行模块分解成为一个一个执行任务，执行任务由任务消费者获取并生成相关的调用 （同时支持串行和并行调用）。Saga任务会根据执行的情况向Saga Log中记录对应的Saga事务的关键事件，并可以通过事件查看器查查询执行情况。 Sharding-Sphere内嵌Saga事务管理器 Saga以jar包的形式提供分布式事务治理能力。 对Sharding-Sphere而言，confirm和cancel过程代表了子事务中的正常执行SQL和逆向执行SQL，（未来Sharding-Sphere将提供自动生成逆向SQL的能力）。当启用Saga柔性事务后，路由完成之后的物理数据源将开启本地自动提交事务，每次confirm和cancel都会直接提交。 在Sharding-Sphere内部，触发SQL执行引擎后，将会产生Saga事务事件，这时Sharding-Sphere事务监听器会注册本次子事务的confirm和cancel至Saga事务管理器的队列中；在业务线程触发commit和rollback后，Saga事务管理器再根据子事务执行的结果，判断进行confirm重试或者cancel流程。 未来计划未来Sharding-Sphere将按照文中介绍的Sharding-Sphere-TM逐步完善整个事务框架： 弱XA事务 （已发布） 基于Atomikos的XA事务（近期发布） 基于Narayana的XA事务（规划中） BED柔性事务（已发布） SAGA（开发中） TCC（规划中）如果前面的分享太过冗长，那么千言万语汇聚成一张表格，欢迎阅读。 QAQ1： 基于XA的事物，可以应用到微服务架构中吗？ A1： 目前我们是把事务管理器内嵌到JVM进程中，对于并发量小，短事务的业务，可以用XA。 Q2： 对于各个事务框架开发计划的先后顺序是基本什么来确定的呢？ A2： 基于难易程度，所以我们把TCC放到了最后。 Q3： 支持多语言吗？比如golang？ A3： 多语言可以用Sharding-Proxy。 Q4： 这次是Proxy实现分布式事务吧？我记得之前Sharding-JDBC有实现。 A4： 这次是整个SS的事务实现，包含Sharding-JDBC和Proxy，目前SJ的实现是弱XA和BED（最大努力送达），以后会增加SAGA和TCC。 Q5： 如果我只想用SS里的事务模块，可以吗？ A5： SS是以事件驱动的方式进行的架构，未来事务模块只负责事务相关的处理。 Q6： SAGA不支持ACID中的I，咱们这边怎么考虑的呢？ A6： 目前暂不支持隔离性，今后我们有增加I的规划，其实所有的柔性事务都不支持I，TCC增加了Try阶段，可以理解是准隔离性，使用SAGA时，可以在业务层面控制并发，防止脏读等产生。 Q7： 那意思，现在3的版本还不能单独用事务的模块？ A7： 现在3.0版本，事务模块依赖了Sharding-JDBC模块，事务模块需要监听Sharding-JDBC和Proxy中的事件，然后进行事务操作。如果你想单独用事务模块，需要按Core中定义的事件，在你的业务里进行发布。]]></content>
      <categories>
        <category>distributed transaction</category>
      </categories>
      <tags>
        <tag>shard-sphere</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java线程池AbstractExecutorService原理分析]]></title>
    <url>%2F2018%2F11%2F22%2FJava%E7%BA%BF%E7%A8%8B%E6%B1%A0AbstractExecutorService%E5%8E%9F%E7%90%86%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[简介AbstractExecutorService 抽象类派生自 ExecutorService 接口，然后在其基础上实现了几个实用的方法，这些方法提供给子类进行调用。ExecutorService又是继承Executor接口。接下来我们就来一一分析。 源码解析 Executor接口我们可以看到 Executor 接口非常简单，就一个 void execute(Runnable command) 方法，代表提交一个任务。1234567/* * @since 1.5 * @author Doug Lea */public interface Executor &#123; void execute(Runnable command);&#125; ExecutorServer接口这些方法都很好理解，一个简单的线程池主要就是这些功能，能提交任务，能获取结果，能关闭线程池，这也是为什么我们经常用这个接口的原因。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249public interface ExecutorService extends Executor &#123; /** * 关闭线程池，已提交的任务继续执行，不接受继续提交新任务 * Initiates an orderly shutdown in which previously submitted * tasks are executed, but no new tasks will be accepted. * Invocation has no additional effect if already shut down. * * &lt;p&gt;This method does not wait for previously submitted tasks to * complete execution. Use &#123;@link #awaitTermination awaitTermination&#125; * to do that. * * @throws SecurityException if a security manager exists and * shutting down this ExecutorService may manipulate * threads that the caller is not permitted to modify * because it does not hold &#123;@link * java.lang.RuntimePermission&#125;&#123;@code ("modifyThread")&#125;, * or the security manager's &#123;@code checkAccess&#125; method * denies access. */ void shutdown(); /** * 关闭线程池，尝试停止正在执行的所有任务，不接受继续提交新任务 * 它和前面的方法相比，加了一个单词“now”，区别在于它会去停止当前正在进行的任务 * Attempts to stop all actively executing tasks, halts the * processing of waiting tasks, and returns a list of the tasks * that were awaiting execution. * * &lt;p&gt;This method does not wait for actively executing tasks to * terminate. Use &#123;@link #awaitTermination awaitTermination&#125; to * do that. * * &lt;p&gt;There are no guarantees beyond best-effort attempts to stop * processing actively executing tasks. For example, typical * implementations will cancel via &#123;@link Thread#interrupt&#125;, so any * task that fails to respond to interrupts may never terminate. * * @return list of tasks that never commenced execution * @throws SecurityException if a security manager exists and * shutting down this ExecutorService may manipulate * threads that the caller is not permitted to modify * because it does not hold &#123;@link * java.lang.RuntimePermission&#125;&#123;@code ("modifyThread")&#125;, * or the security manager's &#123;@code checkAccess&#125; method * denies access. */ List&lt;Runnable&gt; shutdownNow(); /** * 线程池是否已关闭 * Returns &#123;@code true&#125; if this executor has been shut down. * * @return &#123;@code true&#125; if this executor has been shut down */ boolean isShutdown(); /** * 这个方法必须在调用shutdown或shutdownNow方法之后调用才会返回true * Returns &#123;@code true&#125; if all tasks have completed following shut down. * Note that &#123;@code isTerminated&#125; is never &#123;@code true&#125; unless * either &#123;@code shutdown&#125; or &#123;@code shutdownNow&#125; was called first. * * @return &#123;@code true&#125; if all tasks have completed following shut down */ boolean isTerminated(); /** * 等待所有任务完成，并设置超时时间 * Blocks until all tasks have completed execution after a shutdown * request, or the timeout occurs, or the current thread is * interrupted, whichever happens first. * * @param timeout the maximum time to wait * @param unit the time unit of the timeout argument * @return &#123;@code true&#125; if this executor terminated and * &#123;@code false&#125; if the timeout elapsed before termination * @throws InterruptedException if interrupted while waiting */ boolean awaitTermination(long timeout, TimeUnit unit) throws InterruptedException; /** * 提交一个 Callable 任务 * Submits a value-returning task for execution and returns a * Future representing the pending results of the task. The * Future's &#123;@code get&#125; method will return the task's result upon * successful completion. * * &lt;p&gt; * If you would like to immediately block waiting * for a task, you can use constructions of the form * &#123;@code result = exec.submit(aCallable).get();&#125; * * &lt;p&gt;Note: The &#123;@link Executors&#125; class includes a set of methods * that can convert some other common closure-like objects, * for example, &#123;@link java.security.PrivilegedAction&#125; to * &#123;@link Callable&#125; form so they can be submitted. * * @param task the task to submit * @param &lt;T&gt; the type of the task's result * @return a Future representing pending completion of the task * @throws RejectedExecutionException if the task cannot be * scheduled for execution * @throws NullPointerException if the task is null */ &lt;T&gt; Future&lt;T&gt; submit(Callable&lt;T&gt; task); /** * 提交一个 Runnable 任务，第二个参数将会放到 Future 中，作为返回值 * 因为 Runnable 的 run 方法本身并不返回任何东西 * Submits a Runnable task for execution and returns a Future * representing that task. The Future's &#123;@code get&#125; method will * return the given result upon successful completion. * * @param task the task to submit * @param result the result to return * @param &lt;T&gt; the type of the result * @return a Future representing pending completion of the task * @throws RejectedExecutionException if the task cannot be * scheduled for execution * @throws NullPointerException if the task is null */ &lt;T&gt; Future&lt;T&gt; submit(Runnable task, T result); /** * 提交一个 Runnable 任务 * Submits a Runnable task for execution and returns a Future * representing that task. The Future's &#123;@code get&#125; method will * return &#123;@code null&#125; upon &lt;em&gt;successful&lt;/em&gt; completion. * * @param task the task to submit * @return a Future representing pending completion of the task * @throws RejectedExecutionException if the task cannot be * scheduled for execution * @throws NullPointerException if the task is null */ Future&lt;?&gt; submit(Runnable task); /** * 执行所有任务，返回 Future 类型的一个 list * Executes the given tasks, returning a list of Futures holding * their status and results when all complete. * &#123;@link Future#isDone&#125; is &#123;@code true&#125; for each * element of the returned list. * Note that a &lt;em&gt;completed&lt;/em&gt; task could have * terminated either normally or by throwing an exception. * The results of this method are undefined if the given * collection is modified while this operation is in progress. * * @param tasks the collection of tasks * @param &lt;T&gt; the type of the values returned from the tasks * @return a list of Futures representing the tasks, in the same * sequential order as produced by the iterator for the * given task list, each of which has completed * @throws InterruptedException if interrupted while waiting, in * which case unfinished tasks are cancelled * @throws NullPointerException if tasks or any of its elements are &#123;@code null&#125; * @throws RejectedExecutionException if any task cannot be * scheduled for execution */ &lt;T&gt; List&lt;Future&lt;T&gt;&gt; invokeAll(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks) throws InterruptedException; /** * 也是执行所有任务，但是这里设置了超时时间 * Executes the given tasks, returning a list of Futures holding * their status and results * when all complete or the timeout expires, whichever happens first. * &#123;@link Future#isDone&#125; is &#123;@code true&#125; for each * element of the returned list. * Upon return, tasks that have not completed are cancelled. * Note that a &lt;em&gt;completed&lt;/em&gt; task could have * terminated either normally or by throwing an exception. * The results of this method are undefined if the given * collection is modified while this operation is in progress. * * @param tasks the collection of tasks * @param timeout the maximum time to wait * @param unit the time unit of the timeout argument * @param &lt;T&gt; the type of the values returned from the tasks * @return a list of Futures representing the tasks, in the same * sequential order as produced by the iterator for the * given task list. If the operation did not time out, * each task will have completed. If it did time out, some * of these tasks will not have completed. * @throws InterruptedException if interrupted while waiting, in * which case unfinished tasks are cancelled * @throws NullPointerException if tasks, any of its elements, or * unit are &#123;@code null&#125; * @throws RejectedExecutionException if any task cannot be scheduled * for execution */ &lt;T&gt; List&lt;Future&lt;T&gt;&gt; invokeAll(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks, long timeout, TimeUnit unit) throws InterruptedException; /** * 只有其中的一个任务结束了，就可以返回，返回执行完的那个任务的结果 * Executes the given tasks, returning the result * of one that has completed successfully (i.e., without throwing * an exception), if any do. Upon normal or exceptional return, * tasks that have not completed are cancelled. * The results of this method are undefined if the given * collection is modified while this operation is in progress. * * @param tasks the collection of tasks * @param &lt;T&gt; the type of the values returned from the tasks * @return the result returned by one of the tasks * @throws InterruptedException if interrupted while waiting * @throws NullPointerException if tasks or any element task * subject to execution is &#123;@code null&#125; * @throws IllegalArgumentException if tasks is empty * @throws ExecutionException if no task successfully completes * @throws RejectedExecutionException if tasks cannot be scheduled * for execution */ &lt;T&gt; T invokeAny(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks) throws InterruptedException, ExecutionException; /** * 同上一个方法，只有其中的一个任务结束了，就可以返回，返回执行完的那个任务的结果， * 不过这个带超时，超过指定的时间，抛出 TimeoutException 异常 * Executes the given tasks, returning the result * of one that has completed successfully (i.e., without throwing * an exception), if any do before the given timeout elapses. * Upon normal or exceptional return, tasks that have not * completed are cancelled. * The results of this method are undefined if the given * collection is modified while this operation is in progress. * * @param tasks the collection of tasks * @param timeout the maximum time to wait * @param unit the time unit of the timeout argument * @param &lt;T&gt; the type of the values returned from the tasks * @return the result returned by one of the tasks * @throws InterruptedException if interrupted while waiting * @throws NullPointerException if tasks, or unit, or any element * task subject to execution is &#123;@code null&#125; * @throws TimeoutException if the given timeout elapses before * any task successfully completes * @throws ExecutionException if no task successfully completes * @throws RejectedExecutionException if tasks cannot be scheduled * for execution */ &lt;T&gt; T invokeAny(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks, long timeout, TimeUnit unit) throws InterruptedException, ExecutionException, TimeoutException;&#125; AbstractExecutorService抽象类AbstractExecutorService 抽象类派生自 ExecutorService 接口，然后在其基础上实现了几个实用的方法，这些方法提供给子类进行调用。这个抽象类实现了 invokeAny 方法和 invokeAll 方法，这里的两个 newTaskFor 方法也比较有用，用于将任务包装成 FutureTask。定义于最上层接口 Executor中的 void execute(Runnable command) 由于不需要获取结果，不会进行 FutureTask 的包装。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256/** * RunnableFuture 是用于获取执行结果的，我们常用它的子类 FutureTask * @param runnable * @param value * @param &lt;T&gt; * @return */protected &lt;T&gt; RunnableFuture&lt;T&gt; newTaskFor(Runnable runnable, T value) &#123; return new FutureTask&lt;T&gt;(runnable, value);&#125;protected &lt;T&gt; RunnableFuture&lt;T&gt; newTaskFor(Callable&lt;T&gt; callable) &#123; return new FutureTask&lt;T&gt;(callable);&#125;/** * 提交任务 * @throws RejectedExecutionException &#123;@inheritDoc&#125; * @throws NullPointerException &#123;@inheritDoc&#125; */public Future&lt;?&gt; submit(Runnable task) &#123; if (task == null) throw new NullPointerException(); // 1. 将任务包装成 FutureTask RunnableFuture&lt;Void&gt; ftask = newTaskFor(task, null); // 2. 交给执行器执行，execute 方法由具体的子类来实现 execute(ftask); return ftask;&#125;/** * @throws RejectedExecutionException &#123;@inheritDoc&#125; * @throws NullPointerException &#123;@inheritDoc&#125; */public &lt;T&gt; Future&lt;T&gt; submit(Runnable task, T result) &#123; if (task == null) throw new NullPointerException(); RunnableFuture&lt;T&gt; ftask = newTaskFor(task, result); execute(ftask); return ftask;&#125;/** * @throws RejectedExecutionException &#123;@inheritDoc&#125; * @throws NullPointerException &#123;@inheritDoc&#125; */public &lt;T&gt; Future&lt;T&gt; submit(Callable&lt;T&gt; task) &#123; if (task == null) throw new NullPointerException(); RunnableFuture&lt;T&gt; ftask = newTaskFor(task); execute(ftask); return ftask;&#125;/** * 此方法目的：将 tasks 集合中的任务提交到线程池执行，任意一个线程执行完后就可以结束了 * 第二个参数 timed 代表是否设置超时机制，超时时间为第三个参数， * 如果 timed 为 true，同时超时了还没有一个线程返回结果，那么抛出 TimeoutException 异常 * the main mechanics of invokeAny. */private &lt;T&gt; T doInvokeAny(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks, boolean timed, long nanos) throws InterruptedException, ExecutionException, TimeoutException &#123; if (tasks == null) throw new NullPointerException(); // 任务数 int ntasks = tasks.size(); if (ntasks == 0) throw new IllegalArgumentException(); ArrayList&lt;Future&lt;T&gt;&gt; futures = new ArrayList&lt;Future&lt;T&gt;&gt;(ntasks); // ExecutorCompletionService 不是一个真正的执行器，参数 this 才是真正的执行器 // 它对执行器进行了包装，每个任务结束后，将结果保存到内部的一个 completionQueue 队列中 // 这也是为什么这个类的名字里面有个 Completion 的原因吧。 ExecutorCompletionService&lt;T&gt; ecs = new ExecutorCompletionService&lt;T&gt;(this); // For efficiency, especially in executors with limited // parallelism, check to see if previously submitted tasks are // done before submitting more of them. This interleaving // plus the exception mechanics account for messiness of main // loop. try &#123; // 用于保存异常信息，此方法如果没有得到任何有效的结果，那么我们可以抛出最后得到的一个异常 // Record exceptions so that if we fail to obtain any // result, we can throw the last exception we got. ExecutionException ee = null; final long deadline = timed ? System.nanoTime() + nanos : 0L; Iterator&lt;? extends Callable&lt;T&gt;&gt; it = tasks.iterator(); // 首先先提交一个任务，后面的任务到下面的 for 循环一个个提交 // Start one task for sure; the rest incrementally futures.add(ecs.submit(it.next())); // 提交了一个任务，所以任务数量减 1 --ntasks; // 正在执行的任务数(提交的时候 +1，任务结束的时候 -1) int active = 1; for (;;) &#123; // ecs 上面说了，其内部有一个 completionQueue 用于保存执行完成的结果 // BlockingQueue 的 poll 方法不阻塞，返回 null 代表队列为空 Future&lt;T&gt; f = ecs.poll(); // 为 null，说明刚刚提交的第一个线程还没有执行完成 // 在前面先提交一个任务，加上这里做一次检查，也是为了提高性能 if (f == null) &#123; if (ntasks &gt; 0) &#123; --ntasks; futures.add(ecs.submit(it.next())); ++active; &#125; // 这里是 else if，不是 if。这里说明，没有任务了，同时 active 为 0 说明 // 任务都执行完成了。其实我也没理解为什么这里做一次 break？ else if (active == 0) break; // 这里也是 else if。这里说的是，没有任务了，但是设置了超时时间，这里检测是否超时 else if (timed) &#123; // 带等待的 poll 方法 f = ecs.poll(nanos, TimeUnit.NANOSECONDS); // 如果已经超时，抛出 TimeoutException 异常，这整个方法就结束了 if (f == null) throw new TimeoutException(); nanos = deadline - System.nanoTime(); &#125; // 这里是 else。说明，没有任务需要提交，但是池中的任务没有完成，还没有超时(如果设置了超时) // take() 方法会阻塞，直到有元素返回，说明有任务结束了 else f = ecs.take(); &#125; // 有任务结束了 if (f != null) &#123; --active; try &#123; // 返回执行结果，如果有异常，都包装成 ExecutionException return f.get(); &#125; catch (ExecutionException eex) &#123; ee = eex; &#125; catch (RuntimeException rex) &#123; ee = new ExecutionException(rex); &#125; &#125; &#125; if (ee == null) ee = new ExecutionException(); throw ee; &#125; finally &#123; // 方法退出之前，取消其他的任务 for (int i = 0, size = futures.size(); i &lt; size; i++) futures.get(i).cancel(true); &#125;&#125;public &lt;T&gt; T invokeAny(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks) throws InterruptedException, ExecutionException &#123; try &#123; return doInvokeAny(tasks, false, 0); &#125; catch (TimeoutException cannotHappen) &#123; assert false; return null; &#125;&#125;public &lt;T&gt; T invokeAny(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks, long timeout, TimeUnit unit) throws InterruptedException, ExecutionException, TimeoutException &#123; return doInvokeAny(tasks, true, unit.toNanos(timeout));&#125;// 执行所有的任务，返回任务结果。// 先不要看这个方法，我们先想想，其实我们自己提交任务到线程池，也是想要线程池执行所有的任务// 只不过，我们是每次 submit 一个任务，这里以一个集合作为参数提交public &lt;T&gt; List&lt;Future&lt;T&gt;&gt; invokeAll(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks) throws InterruptedException &#123; if (tasks == null) throw new NullPointerException(); ArrayList&lt;Future&lt;T&gt;&gt; futures = new ArrayList&lt;Future&lt;T&gt;&gt;(tasks.size()); boolean done = false; try &#123; for (Callable&lt;T&gt; t : tasks) &#123; // 包装成 FutureTask RunnableFuture&lt;T&gt; f = newTaskFor(t); futures.add(f); // 提交任务 execute(f); &#125; for (int i = 0, size = futures.size(); i &lt; size; i++) &#123; Future&lt;T&gt; f = futures.get(i); if (!f.isDone()) &#123; try &#123; // 这是一个阻塞方法，直到获取到值，或抛出了异常 // 这里有个小细节，其实 get 方法签名上是会抛出 InterruptedException 的 // 可是这里没有进行处理，而是抛给外层去了。此异常发生于还没执行完的任务被取消了 f.get(); &#125; catch (CancellationException ignore) &#123; &#125; catch (ExecutionException ignore) &#123; &#125; &#125; &#125; done = true; return futures; &#125; finally &#123; // 为什么要这个？就是上面说的有异常的情况 if (!done) for (int i = 0, size = futures.size(); i &lt; size; i++) futures.get(i).cancel(true); &#125;&#125;public &lt;T&gt; List&lt;Future&lt;T&gt;&gt; invokeAll(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks, long timeout, TimeUnit unit) throws InterruptedException &#123; if (tasks == null) throw new NullPointerException(); long nanos = unit.toNanos(timeout); ArrayList&lt;Future&lt;T&gt;&gt; futures = new ArrayList&lt;Future&lt;T&gt;&gt;(tasks.size()); boolean done = false; try &#123; for (Callable&lt;T&gt; t : tasks) futures.add(newTaskFor(t)); final long deadline = System.nanoTime() + nanos; final int size = futures.size(); // Interleave time checks and calls to execute in case // executor doesn't have any/much parallelism. for (int i = 0; i &lt; size; i++) &#123; // 提交一个任务，检测一次是否超时 execute((Runnable)futures.get(i)); nanos = deadline - System.nanoTime(); if (nanos &lt;= 0L) return futures; &#125; for (int i = 0; i &lt; size; i++) &#123; Future&lt;T&gt; f = futures.get(i); if (!f.isDone()) &#123; if (nanos &lt;= 0L) return futures; try &#123; // 调用带超时的 get 方法，这里的参数 nanos 是剩余的时间， // 因为上面其实已经用掉了一些时间了 f.get(nanos, TimeUnit.NANOSECONDS); &#125; catch (CancellationException ignore) &#123; &#125; catch (ExecutionException ignore) &#123; &#125; catch (TimeoutException toe) &#123; return futures; &#125; nanos = deadline - System.nanoTime(); &#125; &#125; done = true; return futures; &#125; finally &#123; if (!done) for (int i = 0, size = futures.size(); i &lt; size; i++) futures.get(i).cancel(true); &#125;&#125; 到这里，我们发现，这个抽象类包装了一些基本的方法，可是像 submit、invokeAny、invokeAll 等方法，它们都没有真正开启线程来执行任务，它们都只是在方法内部调用了 execute 方法。至于execute是怎么实现的，可以查看另一篇文章 Java线程池ThreadPoolExecutor原理分析。]]></content>
      <categories>
        <category>juc</category>
      </categories>
      <tags>
        <tag>AbstractExecutorService</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java线程池ThreadPoolExecutor原理分析]]></title>
    <url>%2F2018%2F11%2F20%2FJava%E7%BA%BF%E7%A8%8B%E6%B1%A0ThreadPoolExecutor%E5%8E%9F%E7%90%86%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[简介线程池可以简单看做是一组线程的集合，通过使用线程池，我们可以方便的复用线程，避免了频繁创建和销毁线程所带来的开销。 类图 如上图，最顶层的接口 Executor 仅声明了一个方法execute。ExecutorService 接口在其父类接口基础上，声明了包含但不限于shutdown、submit、invokeAll、invokeAny 等方法。至于 ScheduledExecutorService 接口，则是声明了一些和定时任务相关的方法，比如 schedule和scheduleAtFixedRate。线程池的核心实现是在 ThreadPoolExecutor 类中，我们使用 Executors 调用newFixedThreadPool、newSingleThreadExecutor和newCachedThreadPool等方法创建线程池均是 ThreadPoolExecutor 类型。 原理分析 构造函数线程池的核心实现即 ThreadPoolExecutor 类。该类包含了几个核心属性，这些属性在可在构造方法进行初始化。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677/** * 概念： * corePoolSize：核心线程数，当线程数小于该值时，线程池会优先创建新线程来执行新任务 * maximumPoolSize：线程池所能维护的最大线程数 * keepAliveTime：空闲线程的存活时间 * workQueue：任务队列，用于缓存未执行的任务 * threadFactory：线程工厂。可通过工厂为新建的线程设置更有意义的名字 * handler：拒绝策略。当线程池和任务队列均处于饱和状态时，使用拒绝策略处理新任务。默认是 AbortPolicy，即直接抛出异常 * * 规则流程： * 1.线程数量小于 corePoolSize，直接创建新线程处理新的任务。 * 2.线程数量大于等于 corePoolSize，workQueue 未满，则缓存新任务。 * 3.线程数量大于等于 corePoolSize，但小于 maximumPoolSize，且 workQueue 已满。则创建新线程处理新任务 * 4.线程数量大于等于 maximumPoolSize，且 workQueue 已满，则使用拒绝策略处理新任务 * * 排队策略（当线程数量大于等于 corePoolSize，workQueue 未满时，则缓存新任务）： * 同步队列（SynchronousQueue）：该队列不存储元素，每个插入操作必须等待另一个线程调用移除操作，否则插入操作会一直阻塞 * 有界队列（ArrayBlockingQueue）：基于数组的阻塞队列，按照 FIFO 原则对元素进行排序 * 无界队列（LinkedBlockingQueue）：基于链表的阻塞队列，按照 FIFO 原则对元素进行排序 * 优先级队列（PriorityBlockingQueue）：具有优先级的阻塞队列 * * 拒绝策略（线程数量大于等于 maximumPoolSize，且 workQueue 已满，则使用拒绝策略处理新任务。）： * AbortPolicy：丢弃新任务，并抛出 RejectedExecutionException * DiscardPolicy：不做任何操作，直接丢弃新任务 * DiscardOldestPolicy：丢弃队列队首的元素，并执行新任务 * CallerRunsPolicy：由调用线程执行新任务 */public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue) &#123; this(corePoolSize, maximumPoolSize, keepAliveTime, unit, workQueue, Executors.defaultThreadFactory(), defaultHandler);&#125;public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue, ThreadFactory threadFactory) &#123; this(corePoolSize, maximumPoolSize, keepAliveTime, unit, workQueue, threadFactory, defaultHandler);&#125;public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue, RejectedExecutionHandler handler) &#123; this(corePoolSize, maximumPoolSize, keepAliveTime, unit, workQueue, Executors.defaultThreadFactory(), handler);&#125;public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue, ThreadFactory threadFactory, RejectedExecutionHandler handler) &#123; if (corePoolSize &lt; 0 || maximumPoolSize &lt;= 0 || maximumPoolSize &lt; corePoolSize || keepAliveTime &lt; 0) throw new IllegalArgumentException(); if (workQueue == null || threadFactory == null || handler == null) throw new NullPointerException(); this.corePoolSize = corePoolSize; this.maximumPoolSize = maximumPoolSize; this.workQueue = workQueue; this.keepAliveTime = unit.toNanos(keepAliveTime); this.threadFactory = threadFactory; this.handler = handler;&#125; 状态和线程数 线程池状态 RUNNING：这个没什么好说的，这是最正常的状态：接受新的任务，处理等待队列中的任务 SHUTDOWN：不接受新的任务提交，但是会继续处理等待队列中的任务 STOP：不接受新的任务提交，不再处理等待队列中的任务，中断正在执行任务的线程 TIDYING：所有的任务都销毁了，workCount 为 0。线程池的状态在转换为 TIDYING 状态时，会执行钩子方法 terminated() TERMINATED：terminated() 方法结束后，线程池的状态就会变成这个 状态转换 RUNNING -&gt; SHUTDOWN：当调用了 shutdown() 后，会发生这个状态转换，这也是最重要的 (RUNNING or SHUTDOWN) -&gt; STOP：当调用 shutdownNow() 后，会发生这个状态转换，这下要清楚 shutDown() 和 shutDownNow() 的区别了 SHUTDOWN -&gt; TIDYING：当任务队列和线程池都清空后，会由 SHUTDOWN 转换为 TIDYING STOP -&gt; TIDYING：当任务队列清空后，发生这个转换 TIDYING -&gt; TERMINATED：这个前面说了，当 terminated() 方法结束后 123456789101112131415161718192021222324252627// 采用一个 32 位的整数来存放线程池的状态和当前池中的线程数，其中高 3 位用于存放线程池状态，低 29 位表示线程数（即使只有 29 位，也已经不小了，大概 500 多万）private final AtomicInteger ctl = new AtomicInteger(ctlOf(RUNNING, 0));// 这里 COUNT_BITS 设置为 29(32-3)，意味着前三位用于存放线程状态，后29位用于存放线程数private static final int COUNT_BITS = Integer.SIZE - 3;// 000 11111111111111111111111111111// 这里得到的是 29 个 1，也就是说线程池的最大线程数是 2^29-1=536860911private static final int CAPACITY = (1 &lt;&lt; COUNT_BITS) - 1;// 我们说了，线程池的状态存放在高 3 位中// 运算结果为 111跟29个0：111 00000000000000000000000000000// 备注：负数的二进制用正数的补码表示（https://blog.csdn.net/onewalkingman/article/details/3746154）// runState is stored in the high-order bitsprivate static final int RUNNING = -1 &lt;&lt; COUNT_BITS;// 000 00000000000000000000000000000private static final int SHUTDOWN = 0 &lt;&lt; COUNT_BITS;// 001 00000000000000000000000000000private static final int STOP = 1 &lt;&lt; COUNT_BITS;// 010 00000000000000000000000000000private static final int TIDYING = 2 &lt;&lt; COUNT_BITS;// 011 00000000000000000000000000000private static final int TERMINATED = 3 &lt;&lt; COUNT_BITS;// 将整数 c 的低 29 位修改为 0，就得到了线程池的状态// Packing and unpacking ctlprivate static int runStateOf(int c) &#123; return c &amp; ~CAPACITY; &#125;// 将整数 c 的高 3 为修改为 0，就得到了线程池中的线程数private static int workerCountOf(int c) &#123; return c &amp; CAPACITY; &#125; 线程池中做任务的线程Worker 123456789101112131415161718192021222324252627282930313233343536373839404142434445private final class Worker extends AbstractQueuedSynchronizer implements Runnable&#123; /** * This class will never be serialized, but we provide a * serialVersionUID to suppress a javac warning. */ private static final long serialVersionUID = 6138294804551838833L; //真正的线程 /** Thread this worker is running in. Null if factory fails. */ final Thread thread; /** * 为什么叫 firstTask？因为在创建线程的时候，如果同时指定了这个线程起来以后需要执行的第一个任务, * 那么第一个任务就是存放在这里的(线程可不止执行这一个任务) * 当然了，也可以为 null，这样线程起来了，自己到任务队列（BlockingQueue）中取任务（getTask 方法）就行了 */ /** Initial task to run. Possibly null. */ Runnable firstTask; //用于存放此线程完全的任务数，注意了，这里用了 volatile，保证可见性 /** Per-thread task counter */ volatile long completedTasks; /** * Worker 只有这一个构造方法，传入 firstTask，也可以传 null * Creates with given first task and thread from ThreadFactory. * @param firstTask the first task (null if none) */ Worker(Runnable firstTask) &#123; setState(-1); // inhibit interrupts until runWorker this.firstTask = firstTask; // 调用 ThreadFactory 来创建一个新的线程 this.thread = getThreadFactory().newThread(this); &#125; //这里调用了外部类的 runWorker 方法 /** Delegates main run loop to outer runWorker */ public void run() &#123; runWorker(this); &#125; //以下是aqs独占锁实现...&#125; execute方法 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374/** * Executes the given task sometime in the future. The task * may execute in a new thread or in an existing pooled thread. * * If the task cannot be submitted for execution, either because this * executor has been shutdown or because its capacity has been reached, * the task is handled by the current &#123;@code RejectedExecutionHandler&#125;. * * @param command the task to execute * @throws RejectedExecutionException at discretion of * &#123;@code RejectedExecutionHandler&#125;, if the task * cannot be accepted for execution * @throws NullPointerException if &#123;@code command&#125; is null */public void execute(Runnable command) &#123; if (command == null) throw new NullPointerException(); /* * Proceed in 3 steps: * * 1. If fewer than corePoolSize threads are running, try to * start a new thread with the given command as its first * task. The call to addWorker atomically checks runState and * workerCount, and so prevents false alarms that would add * threads when it shouldn&apos;t, by returning false. * * 2. If a task can be successfully queued, then we still need * to double-check whether we should have added a thread * (because existing ones died since last checking) or that * the pool shut down since entry into this method. So we * recheck state and if necessary roll back the enqueuing if * stopped, or start a new thread if there are none. * * 3. If we cannot queue task, then we try to add a new * thread. If it fails, we know we are shut down or saturated * and so reject the task. */ //获取运行状态和线程数 int c = ctl.get(); // 如果当前线程数少于核心线程数，那么直接添加一个 worker 来执行任务， // 创建一个新的线程，并把当前任务 command 作为这个线程的第一个任务(firstTask) if (workerCountOf(c) &lt; corePoolSize) &#123; // 添加任务成功，那么就结束了。提交任务嘛，线程池已经接受了这个任务，这个方法也就可以返回了 // 至于执行的结果，到时候会包装到 FutureTask 中。 // 返回 false 代表线程池不允许提交任务 if (addWorker(command, true)) return; c = ctl.get(); &#125; // 如果线程池处于 RUNNING 状态，把这个任务添加到任务队列 workQueue 中 if (isRunning(c) &amp;&amp; workQueue.offer(command)) &#123; /* 如果任务进入了 workQueue，我们是否需要开启新的线程 * 因为线程数在 [0, corePoolSize) 是无条件开启新的线程 * 如果线程数已经大于等于 corePoolSize，那么将任务添加到队列中，然后进到这里 */ int recheck = ctl.get(); // 如果线程池已不处于 RUNNING 状态，那么移除已经入队的这个任务，并且执行拒绝策略 if (! isRunning(recheck) &amp;&amp; remove(command)) reject(command); // 如果线程池还是 RUNNING 的，并且线程数为 0，那么开启新的线程 else if (workerCountOf(recheck) == 0) addWorker(null, false); &#125; // 如果 workQueue 队列满了，那么进入到这个分支 // 以 maximumPoolSize 为界创建新的 worker， // 如果失败，说明当前线程数已经达到 maximumPoolSize，执行拒绝策略 else if (!addWorker(command, false)) reject(command);&#125;final void reject(Runnable command) &#123; // 执行拒绝策略 handler.rejectedExecution(command, this);&#125; addWorker方法 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122/** * 第一个参数是准备提交给这个线程执行的任务，之前说了，可以为 null * 第二个参数为 true 代表使用核心线程数 corePoolSize 作为创建线程的界线，也就说创建这个线程的时候， * 如果线程池中的线程总数已经达到 corePoolSize，那么不能响应这次创建线程的请求 * 如果是 false，代表使用最大线程数 maximumPoolSize 作为界线 * Checks if a new worker can be added with respect to current * pool state and the given bound (either core or maximum). If so, * the worker count is adjusted accordingly, and, if possible, a * new worker is created and started, running firstTask as its * first task. This method returns false if the pool is stopped or * eligible to shut down. It also returns false if the thread * factory fails to create a thread when asked. If the thread * creation fails, either due to the thread factory returning * null, or due to an exception (typically OutOfMemoryError in * Thread.start()), we roll back cleanly. * * @param firstTask the task the new thread should run first (or * null if none). Workers are created with an initial first task * (in method execute()) to bypass queuing when there are fewer * than corePoolSize threads (in which case we always start one), * or when the queue is full (in which case we must bypass queue). * Initially idle threads are usually created via * prestartCoreThread or to replace other dying workers. * * @param core if true use corePoolSize as bound, else * maximumPoolSize. (A boolean indicator is used here rather than a * value to ensure reads of fresh values after checking other pool * state). * @return true if successful */private boolean addWorker(Runnable firstTask, boolean core) &#123; retry: for (;;) &#123; int c = ctl.get(); int rs = runStateOf(c); // 如果线程池已关闭，并满足以下条件之一，那么不创建新的 worker： // 1. 线程池状态大于 SHUTDOWN，其实也就是 STOP, TIDYING, 或 TERMINATED // 2. firstTask != null // 3. workQueue.isEmpty() // 简单分析下： // 还是状态控制的问题，当线程池处于 SHUTDOWN 的时候，不允许提交任务，但是已有的任务继续执行 // 当状态大于 SHUTDOWN 时，不允许提交任务，且中断正在执行的任务 // 多说一句：如果线程池处于 SHUTDOWN，但是 firstTask 为 null，且 workQueue 非空，那么是允许创建 worker 的 // Check if queue empty only if necessary. if (rs &gt;= SHUTDOWN &amp;&amp; ! (rs == SHUTDOWN &amp;&amp; firstTask == null &amp;&amp; ! workQueue.isEmpty())) return false; for (;;) &#123; int wc = workerCountOf(c); if (wc &gt;= CAPACITY || wc &gt;= (core ? corePoolSize : maximumPoolSize)) return false; // 如果成功，那么就是所有创建线程前的条件校验都满足了，准备创建线程执行任务了 // 这里失败的话，说明有其他线程也在尝试往线程池中创建线程 if (compareAndIncrementWorkerCount(c)) break retry; // 由于有并发，重新再读取一下 ctl c = ctl.get(); // Re-read ctl // 正常如果是 CAS 失败的话，进到下一个里层的for循环就可以了 // 可是如果是因为其他线程的操作，导致线程池的状态发生了变更，如有其他线程关闭了这个线程池 // 那么需要回到外层的for循环 if (runStateOf(c) != rs) continue retry; // else CAS failed due to workerCount change; retry inner loop &#125; &#125; //到这里，我们认为在当前这个时刻，可以开始创建线程来执行任务了 // worker 是否已经启动 boolean workerStarted = false; // 是否已将这个 worker 添加到 workers 这个 HashSet 中 boolean workerAdded = false; Worker w = null; try &#123; // 把 firstTask 传给 worker 的构造方法 w = new Worker(firstTask); // 取 worker 中的线程对象，之前说了，Worker的构造方法会调用 ThreadFactory 来创建一个新的线程 final Thread t = w.thread; if (t != null) &#123; final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try &#123; // Recheck while holding lock. // Back out on ThreadFactory failure or if // shut down before lock acquired. int rs = runStateOf(ctl.get()); // 小于 SHUTTDOWN 那就是 RUNNING，这个自不必说，是最正常的情况 // 如果等于 SHUTDOWN，前面说了，不接受新的任务，但是会继续执行等待队列中的任务 if (rs &lt; SHUTDOWN || (rs == SHUTDOWN &amp;&amp; firstTask == null)) &#123; // worker 里面的 thread 可不能是已经启动的 if (t.isAlive()) // precheck that t is startable throw new IllegalThreadStateException(); // 加到 workers 这个 HashSet 中 workers.add(w); int s = workers.size(); // largestPoolSize 用于记录 workers 中的个数的最大值 // 因为 workers 是不断增加减少的，通过这个值可以知道线程池的大小曾经达到的最大值 if (s &gt; largestPoolSize) largestPoolSize = s; workerAdded = true; &#125; &#125; finally &#123; mainLock.unlock(); &#125; // 添加成功的话，启动这个线程 if (workerAdded) &#123; t.start(); workerStarted = true; &#125; &#125; &#125; finally &#123; // 如果线程没有启动，需要做一些清理工作，如前面 workCount 加了 1，将其减掉 if (! workerStarted) addWorkerFailed(w); &#125; // 返回线程是否启动成功 return workerStarted;&#125; addWorkFailed方法 123456789101112131415// workers 中删除掉相应的 worker// workCount 减 1private void addWorkerFailed(Worker w) &#123; final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try &#123; if (w != null) workers.remove(w); decrementWorkerCount(); // rechecks for termination, in case the existence of this worker was holding up termination tryTerminate(); &#125; finally &#123; mainLock.unlock(); &#125;&#125; runWorker方法 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107// Worker 类的 run() 方法public void run() &#123; runWorker(this);&#125;/** * 此方法由 worker 线程启动后调用，这里用一个 while 循环来不断地从等待队列中获取任务并执行 * 前面说了，worker 在初始化的时候，可以指定 firstTask，那么第一个任务也就可以不需要从队列中获取 * Main worker run loop. Repeatedly gets tasks from queue and * executes them, while coping with a number of issues: * * 1. We may start out with an initial task, in which case we * don't need to get the first one. Otherwise, as long as pool is * running, we get tasks from getTask. If it returns null then the * worker exits due to changed pool state or configuration * parameters. Other exits result from exception throws in * external code, in which case completedAbruptly holds, which * usually leads processWorkerExit to replace this thread. * * 2. Before running any task, the lock is acquired to prevent * other pool interrupts while the task is executing, and then we * ensure that unless pool is stopping, this thread does not have * its interrupt set. * * 3. Each task run is preceded by a call to beforeExecute, which * might throw an exception, in which case we cause thread to die * (breaking loop with completedAbruptly true) without processing * the task. * * 4. Assuming beforeExecute completes normally, we run the task, * gathering any of its thrown exceptions to send to afterExecute. * We separately handle RuntimeException, Error (both of which the * specs guarantee that we trap) and arbitrary Throwables. * Because we cannot rethrow Throwables within Runnable.run, we * wrap them within Errors on the way out (to the thread's * UncaughtExceptionHandler). Any thrown exception also * conservatively causes thread to die. * * 5. After task.run completes, we call afterExecute, which may * also throw an exception, which will also cause thread to * die. According to JLS Sec 14.20, this exception is the one that * will be in effect even if task.run throws. * * The net effect of the exception mechanics is that afterExecute * and the thread's UncaughtExceptionHandler have as accurate * information as we can provide about any problems encountered by * user code. * * @param w the worker */final void runWorker(Worker w) &#123; Thread wt = Thread.currentThread(); // 该线程的第一个任务(如果有的话) Runnable task = w.firstTask; w.firstTask = null; w.unlock(); // allow interrupts boolean completedAbruptly = true; try &#123; // 循环调用 getTask 获取任务 while (task != null || (task = getTask()) != null) &#123; w.lock(); // 如果线程池状态大于等于 STOP，那么意味着该线程也要中断 // If pool is stopping, ensure thread is interrupted; // if not, ensure thread is not interrupted. This // requires a recheck in second case to deal with // shutdownNow race while clearing interrupt if ((runStateAtLeast(ctl.get(), STOP) || (Thread.interrupted() &amp;&amp; runStateAtLeast(ctl.get(), STOP))) &amp;&amp; !wt.isInterrupted()) wt.interrupt(); try &#123; // 这是一个钩子方法，留给需要的子类实现 beforeExecute(wt, task); Throwable thrown = null; try &#123; // 到这里终于可以执行任务了 task.run(); &#125; catch (RuntimeException x) &#123; thrown = x; throw x; &#125; catch (Error x) &#123; thrown = x; throw x; &#125; catch (Throwable x) &#123; thrown = x; throw new Error(x); &#125; finally &#123; // 也是一个钩子方法，将 task 和异常作为参数，留给需要的子类实现 afterExecute(task, thrown); &#125; &#125; finally &#123; // 置空 task，准备 getTask 获取下一个任务 task = null; // 累加完成的任务数 w.completedTasks++; // 释放掉 worker 的独占锁 w.unlock(); &#125; &#125; completedAbruptly = false; &#125; finally &#123; // 如果到这里，需要执行线程关闭： // 1. 说明 getTask 返回 null，也就是说，这个 worker 的使命结束了，执行关闭 // 2. 任务执行过程中发生了异常 // 第一种情况，已经在代码处理了将 workCount 减 1，这个在 getTask 方法分析中会说 // 第二种情况，workCount 没有进行处理，所以需要在 processWorkerExit 中处理 processWorkerExit(w, completedAbruptly); &#125;&#125; getTask方法 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768/** * 此方法有三种可能： * 1. 阻塞直到获取到任务返回。我们知道，默认 corePoolSize 之内的线程是不会被回收的， * 它们会一直等待任务 * 2. 超时退出。keepAliveTime 起作用的时候，也就是如果这么多时间内都没有任务，那么应该执行关闭 * 3. 如果发生了以下条件，此方法必须返回 null: * - 池中有大于 maximumPoolSize 个 workers 存在(通过调用 setMaximumPoolSize 进行设置) * - 线程池处于 SHUTDOWN，而且 workQueue 是空的，前面说了，这种不再接受新的任务 * - 线程池处于 STOP，不仅不接受新的线程，连 workQueue 中的线程也不再执行 * Performs blocking or timed wait for a task, depending on * current configuration settings, or returns null if this worker * must exit because of any of: * 1. There are more than maximumPoolSize workers (due to * a call to setMaximumPoolSize). * 2. The pool is stopped. * 3. The pool is shutdown and the queue is empty. * 4. This worker timed out waiting for a task, and timed-out * workers are subject to termination (that is, * &#123;@code allowCoreThreadTimeOut || workerCount &gt; corePoolSize&#125;) * both before and after the timed wait, and if the queue is * non-empty, this worker is not the last thread in the pool. * * @return task, or null if the worker must exit, in which case * workerCount is decremented */private Runnable getTask() &#123; boolean timedOut = false; // Did the last poll() time out? for (;;) &#123; int c = ctl.get(); int rs = runStateOf(c); // Check if queue empty only if necessary. if (rs &gt;= SHUTDOWN &amp;&amp; (rs &gt;= STOP || workQueue.isEmpty())) &#123; decrementWorkerCount(); return null; &#125; int wc = workerCountOf(c); // 允许核心线程数内的线程回收，或当前线程数超过了核心线程数，那么有可能发生超时关闭 // Are workers subject to culling? boolean timed = allowCoreThreadTimeOut || wc &gt; corePoolSize; if ((wc &gt; maximumPoolSize || (timed &amp;&amp; timedOut)) &amp;&amp; (wc &gt; 1 || workQueue.isEmpty())) &#123; if (compareAndDecrementWorkerCount(c)) return null; continue; &#125; try &#123; // 到 workQueue 中获取任务 Runnable r = timed ? workQueue.poll(keepAliveTime, TimeUnit.NANOSECONDS) : workQueue.take(); if (r != null) return r; timedOut = true; &#125; catch (InterruptedException retry) &#123; // 如果此 worker 发生了中断，采取的方案是重试 // 解释下为什么会发生中断，这个读者要去看 setMaximumPoolSize 方法， // 如果开发者将 maximumPoolSize 调小了，导致其小于当前的 workers 数量， // 那么意味着超出的部分线程要被关闭。重新进入 for 循环，自然会有部分线程会返回 null timedOut = false; &#125; &#125;&#125; 总结ThreadPoolExecutor是线程池最底层的实现，需要知道几个参数的含义，还有线程work的工作流程。]]></content>
      <tags>
        <tag>ThreadPoolExecutor</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java线程同步组件Semaphore分析]]></title>
    <url>%2F2018%2F11%2F17%2FJava%E7%BA%BF%E7%A8%8B%E5%90%8C%E6%AD%A5%E7%BB%84%E4%BB%B6Semaphore%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[定义Semaphore 主要用于限量控制并发执行代码的工具类, 其内部通过 一个 permit 来进行定义并发执行的数量,本质就是aqs的共享锁. 类图 Demo1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253package com.fly.learn.reentrantlock;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import java.util.concurrent.ExecutorService;import java.util.concurrent.Executors;import java.util.concurrent.Semaphore;/** * @author: peijiepang * @date 2018/11/17 * @Description: */public class SemaphoreTest extends Thread&#123; private final static Logger LOGGER = LoggerFactory.getLogger(SemaphoreTest.class); private Semaphore semaphore; public SemaphoreTest(String threadName,Semaphore semaphore) &#123; this.semaphore = semaphore; this.setName(threadName); &#125; @Override public void run()&#123; try &#123; semaphore.acquire(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; try &#123; Thread.sleep(1000l); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; LOGGER.info("&#123;&#125;......",Thread.currentThread().getName()); semaphore.release(); &#125; public static void main(String[] args) &#123; //公平锁 Semaphore semaphore = new Semaphore(2,true); ExecutorService executorService = Executors.newFixedThreadPool(10); for (int i=0;i&lt;10;i++)&#123; executorService.submit(new SemaphoreTest("thread_"+1,semaphore)); &#125; executorService.shutdown(); LOGGER.info("finish......."); &#125;&#125; 执行结果如下123456789102018-11-17 21:05:46.644 [pool-2-thread-1] INFO c.f.l.reentrantlock.SemaphoreTest - pool-2-thread-1......2018-11-17 21:05:46.645 [pool-2-thread-2] INFO c.f.l.reentrantlock.SemaphoreTest - pool-2-thread-2......2018-11-17 21:05:47.647 [pool-2-thread-4] INFO c.f.l.reentrantlock.SemaphoreTest - pool-2-thread-4......2018-11-17 21:05:47.647 [pool-2-thread-3] INFO c.f.l.reentrantlock.SemaphoreTest - pool-2-thread-3......2018-11-17 21:05:48.650 [pool-2-thread-6] INFO c.f.l.reentrantlock.SemaphoreTest - pool-2-thread-6......2018-11-17 21:05:48.650 [pool-2-thread-5] INFO c.f.l.reentrantlock.SemaphoreTest - pool-2-thread-5......2018-11-17 21:05:49.652 [pool-2-thread-7] INFO c.f.l.reentrantlock.SemaphoreTest - pool-2-thread-7......2018-11-17 21:05:49.652 [pool-2-thread-8] INFO c.f.l.reentrantlock.SemaphoreTest - pool-2-thread-8......2018-11-17 21:05:50.657 [pool-2-thread-9] INFO c.f.l.reentrantlock.SemaphoreTest - pool-2-thread-9......2018-11-17 21:05:50.658 [pool-2-thread-10] INFO c.f.l.reentrantlock.SemaphoreTest - pool-2-thread-10...... 从上面的执行结果来看，每1s都会获取到2个令牌，符合预期Semaphore配置为2的结论。 特点1.Semaphore方法的实现通过 Sync(AQS的继承类)代理来实现 2.支持公平与非公平模式, 都是在AQS的子类里面进行, 主要区分在 tryAcquire 源码解读 构造函数Semaphore 的功能均由内部类 NonfairSync, FairSync 代理来实现 12345678910111213141516171819202122232425262728/** * 默认使用非公平模式 * Creates a &#123;@code Semaphore&#125; with the given number of * permits and nonfair fairness setting. * * @param permits the initial number of permits available. * This value may be negative, in which case releases * must occur before any acquires will be granted. */public Semaphore(int permits) &#123; sync = new NonfairSync(permits);&#125;/** * 需要指定公平或者非公平模式 * Creates a &#123;@code Semaphore&#125; with the given number of * permits and the given fairness setting. * * @param permits the initial number of permits available. * This value may be negative, in which case releases * must occur before any acquires will be granted. * @param fair &#123;@code true&#125; if this semaphore will guarantee * first-in first-out granting of permits under contention, * else &#123;@code false&#125; */public Semaphore(int permits, boolean fair) &#123; sync = fair ? new FairSync(permits) : new NonfairSync(permits);&#125; Semaphore内部类Sync 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384/** * AQS 的子类主要定义获取释放 lock * Synchronization implementation for semaphore. Uses AQS state * to represent permits. Subclassed into fair and nonfair * versions. */abstract static class Sync extends AbstractQueuedSynchronizer &#123; private static final long serialVersionUID = 1192457210091910933L; /** * 指定许可 初始化 Semaphore * 许可对应aqs中的state * @param permits */ Sync(int permits) &#123; setState(permits); &#125; /** * 获取许可 * @return */ final int getPermits() &#123; return getState(); &#125; /** * 非公平方式获取多个许可 * @param acquires * @return */ final int nonfairTryAcquireShared(int acquires) &#123; for (;;) &#123; int available = getState(); int remaining = available - acquires;// 判断获取 acquires 的剩余 permit 数目 if (remaining &lt; 0 || compareAndSetState(available, remaining))// cas改变 state return remaining; &#125; &#125; /** * 释放许可 * @param releases * @return */ protected final boolean tryReleaseShared(int releases) &#123; for (;;) &#123; int current = getState(); int next = current + releases; if (next &lt; current) // overflow throw new Error("Maximum permit count exceeded"); if (compareAndSetState(current, next)) return true; &#125; &#125; /** * 减少许可 * @param reductions */ final void reducePermits(int reductions) &#123; for (;;) &#123; int current = getState(); int next = current - reductions; if (next &gt; current) // underflow throw new Error("Permit count underflow"); if (compareAndSetState(current, next)) return; &#125; &#125; /** * 将许可设置为0 * @return */ final int drainPermits() &#123; for (;;) &#123; int current = getState(); if (current == 0 || compareAndSetState(current, 0)) return current; &#125; &#125;&#125; Semaphore 内部类 FairSync, NonfairSync这两个类均继承 Sync, 两者的区别主要在于在获取时判断是否有线程在 AQS 的 Sync Queue 里面进行等待获取 1234567891011121314151617181920212223242526272829303132333435363738394041424344/** * 非公平模式 * NonFair version */static final class NonfairSync extends Sync &#123; private static final long serialVersionUID = -2694183684443567898L; NonfairSync(int permits) &#123; super(permits); &#125; protected int tryAcquireShared(int acquires) &#123; return nonfairTryAcquireShared(acquires);//直接调用父类的方法 &#125;&#125;/** * 公平模式 * Fair version */static final class FairSync extends Sync &#123; private static final long serialVersionUID = 2014338818796000944L; FairSync(int permits) &#123; super(permits); &#125; /** * 公平版本获取 permit 主要看是否由前继节点 * @param acquires * @return */ protected int tryAcquireShared(int acquires) &#123; for (;;) &#123; if (hasQueuedPredecessors())// 1. 判断是否Sync Queue 里面是否有前继节点 return -1; int available = getState(); int remaining = available - acquires; if (remaining &lt; 0 || compareAndSetState(available, remaining))// 2. cas 改变state return remaining; &#125; &#125;&#125; Semaphore permit获取方式这边值贴释放1个许可的源码，释放多个许可源码无非只是增加前置校验而已 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165/** * 调用 acquireSharedInterruptibly 响应中断的方式获取 permit * Acquires a permit from this semaphore, blocking until one is * available, or the thread is &#123;@linkplain Thread#interrupt interrupted&#125;. * * &lt;p&gt;Acquires a permit, if one is available and returns immediately, * reducing the number of available permits by one. * * &lt;p&gt;If no permit is available then the current thread becomes * disabled for thread scheduling purposes and lies dormant until * one of two things happens: * &lt;ul&gt; * &lt;li&gt;Some other thread invokes the &#123;@link #release&#125; method for this * semaphore and the current thread is next to be assigned a permit; or * &lt;li&gt;Some other thread &#123;@linkplain Thread#interrupt interrupts&#125; * the current thread. * &lt;/ul&gt; * * &lt;p&gt;If the current thread: * &lt;ul&gt; * &lt;li&gt;has its interrupted status set on entry to this method; or * &lt;li&gt;is &#123;@linkplain Thread#interrupt interrupted&#125; while waiting * for a permit, * &lt;/ul&gt; * then &#123;@link InterruptedException&#125; is thrown and the current thread's * interrupted status is cleared. * * @throws InterruptedException if the current thread is interrupted */public void acquire() throws InterruptedException &#123; sync.acquireSharedInterruptibly(1);&#125;//aqs代码--调用到aqs中的方法，然后在调用到子类实现的tryAcquireSharedpublic final void acquireSharedInterruptibly(int arg) throws InterruptedException &#123; if (Thread.interrupted()) throw new InterruptedException(); if (tryAcquireShared(arg) &lt; 0) doAcquireSharedInterruptibly(arg);&#125;/** * 调用 acquireUninterruptibly 非响应中断的方式获取 permit * Acquires a permit from this semaphore, blocking until one is * available. * * &lt;p&gt;Acquires a permit, if one is available and returns immediately, * reducing the number of available permits by one. * * &lt;p&gt;If no permit is available then the current thread becomes * disabled for thread scheduling purposes and lies dormant until * some other thread invokes the &#123;@link #release&#125; method for this * semaphore and the current thread is next to be assigned a permit. * * &lt;p&gt;If the current thread is &#123;@linkplain Thread#interrupt interrupted&#125; * while waiting for a permit then it will continue to wait, but the * time at which the thread is assigned a permit may change compared to * the time it would have received the permit had no interruption * occurred. When the thread does return from this method its interrupt * status will be set. */public void acquireUninterruptibly() &#123; sync.acquireShared(1);&#125;//aqs源码public final void acquireShared(int arg) &#123; if (tryAcquireShared(arg) &lt; 0) doAcquireShared(arg);&#125;/** * 尝试获取 permit,其实就是调用非公平锁的获取许可方法 * Acquires a permit from this semaphore, only if one is available at the * time of invocation. * * &lt;p&gt;Acquires a permit, if one is available and returns immediately, * with the value &#123;@code true&#125;, * reducing the number of available permits by one. * * &lt;p&gt;If no permit is available then this method will return * immediately with the value &#123;@code false&#125;. * * &lt;p&gt;Even when this semaphore has been set to use a * fair ordering policy, a call to &#123;@code tryAcquire()&#125; &lt;em&gt;will&lt;/em&gt; * immediately acquire a permit if one is available, whether or not * other threads are currently waiting. * This &amp;quot;barging&amp;quot; behavior can be useful in certain * circumstances, even though it breaks fairness. If you want to honor * the fairness setting, then use * &#123;@link #tryAcquire(long, TimeUnit) tryAcquire(0, TimeUnit.SECONDS) &#125; * which is almost equivalent (it also detects interruption). * * @return &#123;@code true&#125; if a permit was acquired and &#123;@code false&#125; * otherwise */public boolean tryAcquire() &#123; return sync.nonfairTryAcquireShared(1) &gt;= 0;&#125;/** * 尝试的获取 permit, 支持超时与中断 * Acquires the given number of permits from this semaphore, if all * become available within the given waiting time and the current * thread has not been &#123;@linkplain Thread#interrupt interrupted&#125;. * * &lt;p&gt;Acquires the given number of permits, if they are available and * returns immediately, with the value &#123;@code true&#125;, * reducing the number of available permits by the given amount. * * &lt;p&gt;If insufficient permits are available then * the current thread becomes disabled for thread scheduling * purposes and lies dormant until one of three things happens: * &lt;ul&gt; * &lt;li&gt;Some other thread invokes one of the &#123;@link #release() release&#125; * methods for this semaphore, the current thread is next to be assigned * permits and the number of available permits satisfies this request; or * &lt;li&gt;Some other thread &#123;@linkplain Thread#interrupt interrupts&#125; * the current thread; or * &lt;li&gt;The specified waiting time elapses. * &lt;/ul&gt; * * &lt;p&gt;If the permits are acquired then the value &#123;@code true&#125; is returned. * * &lt;p&gt;If the current thread: * &lt;ul&gt; * &lt;li&gt;has its interrupted status set on entry to this method; or * &lt;li&gt;is &#123;@linkplain Thread#interrupt interrupted&#125; while waiting * to acquire the permits, * &lt;/ul&gt; * then &#123;@link InterruptedException&#125; is thrown and the current thread's * interrupted status is cleared. * Any permits that were to be assigned to this thread, are instead * assigned to other threads trying to acquire permits, as if * the permits had been made available by a call to &#123;@link #release()&#125;. * * &lt;p&gt;If the specified waiting time elapses then the value &#123;@code false&#125; * is returned. If the time is less than or equal to zero, the method * will not wait at all. Any permits that were to be assigned to this * thread, are instead assigned to other threads trying to acquire * permits, as if the permits had been made available by a call to * &#123;@link #release()&#125;. * * @param permits the number of permits to acquire * @param timeout the maximum time to wait for the permits * @param unit the time unit of the &#123;@code timeout&#125; argument * @return &#123;@code true&#125; if all permits were acquired and &#123;@code false&#125; * if the waiting time elapsed before all permits were acquired * @throws InterruptedException if the current thread is interrupted * @throws IllegalArgumentException if &#123;@code permits&#125; is negative */public boolean tryAcquire(int permits, long timeout, TimeUnit unit) throws InterruptedException &#123; if (permits &lt; 0) throw new IllegalArgumentException(); return sync.tryAcquireSharedNanos(permits, unit.toNanos(timeout));&#125;//aqs源码public final boolean tryAcquireSharedNanos(int arg, long nanosTimeout) throws InterruptedException &#123; if (Thread.interrupted()) throw new InterruptedException(); return tryAcquireShared(arg) &gt;= 0 || doAcquireSharedNanos(arg, nanosTimeout);&#125; Semaphore permit 释放方法这边值贴释放1个许可的源码，释放多个许可源码无非只是增加前置校验而已 123456789101112131415161718192021222324252627282930313233343536/** * 释放 permit * Releases the given number of permits, returning them to the semaphore. * * &lt;p&gt;Releases the given number of permits, increasing the number of * available permits by that amount. * If any threads are trying to acquire permits, then one * is selected and given the permits that were just released. * If the number of available permits satisfies that thread's request * then that thread is (re)enabled for thread scheduling purposes; * otherwise the thread will wait until sufficient permits are available. * If there are still permits available * after this thread's request has been satisfied, then those permits * are assigned in turn to other threads trying to acquire permits. * * &lt;p&gt;There is no requirement that a thread that releases a permit must * have acquired that permit by calling &#123;@link Semaphore#acquire acquire&#125;. * Correct usage of a semaphore is established by programming convention * in the application. * * @param permits the number of permits to release * @throws IllegalArgumentException if &#123;@code permits&#125; is negative */public void release(int permits) &#123; if (permits &lt; 0) throw new IllegalArgumentException(); sync.releaseShared(permits);&#125;//aqs源码public final boolean releaseShared(int arg) &#123; if (tryReleaseShared(arg)) &#123; doReleaseShared(); return true; &#125; return false;&#125; 总结Semaphore 通过 AQS中的 state 来进行控制 permit 的获取控制, 其实它就是一个限制数量的 ReadLock; 但要真正理解 Semaphore, 还需要看 AbstractQueuedSynchronizer源码分析。]]></content>
      <categories>
        <category>juc</category>
      </categories>
      <tags>
        <tag>Semaphore</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java线程同步组件CyclicBarrier分析]]></title>
    <url>%2F2018%2F11%2F14%2FJava%E7%BA%BF%E7%A8%8B%E5%90%8C%E6%AD%A5%E7%BB%84%E4%BB%B6CyclicBarrier%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[简介与 CountDownLatch 的实现方式不同，CyclicBarrier 并没有直接通过 AQS 实现同步功能，而是在重入锁 ReentrantLock 的基础上实现的。在 CyclicBarrier 中，线程访问 await 方法需先获取锁才能访问。在最后一个线程访问 await 方法前，其他线程进入 await 方法中后，会调用 Condition 的 await 方法进入等待状态。在最后一个线程进入 CyclicBarrier await 方法后，该线程将会调用 Condition 的 signalAll 方法唤醒所有处于等待状态中的线程。同时，最后一个进入 await 的线程还会重置 CyclicBarrier 的状态，使其可以重复使用。 在创建 CyclicBarrier 对象时，需要转入一个值，用于初始化 CyclicBarrier 的成员变量 parties，该成员变量表示屏障拦截的线程数。当到达屏障的线程数小于 parties 时，这些线程都会被阻塞住。当最后一个线程到达屏障后，此前被阻塞的线程才会被唤醒。 Demo例子12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152package com.fly.learn.reentrantlock;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import java.util.concurrent.BrokenBarrierException;import java.util.concurrent.CyclicBarrier;/** * @author: peijiepang * @date 2018/11/14 * @Description: */public class CyclicBarrierTest &#123; private final static Logger LOGGER = LoggerFactory.getLogger(CyclicBarrierTest.class); public static void main(String[] args) throws BrokenBarrierException, InterruptedException &#123; CyclicBarrier cb = new CyclicBarrier(3, new Thread("barrierAction") &#123; public void run() &#123; LOGGER.info(Thread.currentThread().getName() + " barrier action"); &#125; &#125;); MyThread t1 = new MyThread("t1", cb); MyThread t2 = new MyThread("t2", cb); t1.start(); t2.start(); LOGGER.info(Thread.currentThread().getName() + " going to await"); cb.await(); LOGGER.info(Thread.currentThread().getName() + " continue"); &#125;&#125;class MyThread extends Thread &#123; private final static Logger LOGGER = LoggerFactory.getLogger(MyThread.class); private CyclicBarrier cb; public MyThread(String name, CyclicBarrier cb) &#123; super(name); this.cb = cb; &#125; public void run() &#123; LOGGER.info(Thread.currentThread().getName() + " going to await"); try &#123; cb.await(); LOGGER.info(Thread.currentThread().getName() + " continue"); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;&#125; 12345672018-11-14 23:14:23.641 [main] INFO c.f.l.r.CyclicBarrierTest - main going to await2018-11-14 23:14:23.641 [t2] INFO com.fly.learn.reentrantlock.MyThread - t2 going to await2018-11-14 23:14:23.640 [t1] INFO com.fly.learn.reentrantlock.MyThread - t1 going to await2018-11-14 23:14:23.648 [t1] INFO c.f.l.r.CyclicBarrierTest - t1 barrier action2018-11-14 23:14:23.648 [t1] INFO com.fly.learn.reentrantlock.MyThread - t1 continue2018-11-14 23:14:23.649 [t2] INFO com.fly.learn.reentrantlock.MyThread - t2 continue2018-11-14 23:14:23.650 [main] INFO c.f.l.r.CyclicBarrierTest - main continue 源码分析 类图CyclicBarrier 是基于重入锁 ReentrantLock 实现相关逻辑的。所以要弄懂 CyclicBarrier 的源码，仅需有 ReentrantLock 相关的背景知识即可。关于重入锁 ReentrantLock 方面的知识，有兴趣的朋友可以参考我之前写的文章 Java 重入锁 ReentrantLock原理分析。下面看一下 CyclicBarrier 的代码结构吧，如下: 构造函数 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758/** * Each use of the barrier is represented as a generation instance. * The generation changes whenever the barrier is tripped, or * is reset. There can be many generations associated with threads * using the barrier - due to the non-deterministic way the lock * may be allocated to waiting threads - but only one of these * can be active at a time (the one to which &#123;@code count&#125; applies) * and all the rest are either broken or tripped. * There need not be an active generation if there has been a break * but no subsequent reset. */private static class Generation &#123; // 用于记录屏障有没有被破坏 boolean broken = false;&#125;/** The lock for guarding barrier entry */private final ReentrantLock lock = new ReentrantLock();/** Condition to wait on until tripped */private final Condition trip = lock.newCondition();/** The number of parties */private final int parties;//线程数，即当 parties 个线程到达屏障后，屏障才会放行/* The command to run when tripped */private final Runnable barrierCommand;//回调对象，如果不为 null，会在第 parties 个线程到达屏障后被执行/** The current generation *//** * CyclicBarrier 是可循环使用的屏障，这里使用 Generation 记录当前轮次 CyclicBarrier * 的运行状态。当所有线程到达屏障后，generation 将会被更新，表示 CyclicBarrier 进入新一 * 轮的运行轮次中。 */private Generation generation = new Generation();/** * Number of parties still waiting. Counts down from parties to 0 * on each generation. It is reset to parties on each new * generation or when broken. */private int count;//计数器，当 count &gt; 0 时，到达屏障的线程会进入等待状态。当最后一个线程到达屏障后，count 自减至0。最后一个到达的线程会执行回调方法，并唤醒其他处于等待状态中的线程。/** * 创建一个允许 parties 个线程通行的屏障 * @param parties */public CyclicBarrier(int parties) &#123; this(parties, null);&#125;/** * 创建一个允许 parties 个线程通行的屏障，若 barrierAction 回调对象不为 null， * 则在最后一个线程到达屏障后，执行相应的回调逻辑 */public CyclicBarrier(int parties, Runnable barrierAction) &#123; if (parties &lt;= 0) throw new IllegalArgumentException(); this.parties = parties; this.count = parties; this.barrierCommand = barrierAction;&#125; await分析 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193public int await() throws InterruptedException, BrokenBarrierException &#123; try &#123; return dowait(false, 0L); &#125; catch (TimeoutException toe) &#123; throw new Error(toe); // cannot happen &#125;&#125;private final ReentrantLock lock = new ReentrantLock();/** * Main barrier code, covering the various policies. */private int dowait(boolean timed, long nanos) throws InterruptedException, BrokenBarrierException, TimeoutException &#123; final ReentrantLock lock = this.lock; // 加锁 lock.lock(); try &#123; final Generation g = generation; // 如果 g.broken = true，表明屏障被破坏了，这里直接抛出异常 if (g.broken) throw new BrokenBarrierException(); if (Thread.interrupted()) &#123; // 如果线程中断，则调用 breakBarrier 破坏屏障 breakBarrier(); throw new InterruptedException(); &#125; /* * index 表示线程到达屏障的顺序，index = parties - 1 表明当前线程是第一个 * 到达屏障的。index = 0，表明当前线程是最有一个到达屏障的。 */ int index = --count; if (index == 0) &#123; // tripped // 当 index = 0 时，唤醒所有处于等待状态的线程 boolean ranAction = false; try &#123; final Runnable command = barrierCommand; // 如果回调对象不为 null，则执行回调 if (command != null) command.run(); ranAction = true; // 重置屏障状态，使其进入新一轮的运行过程中 nextGeneration(); return 0; &#125; finally &#123; // 若执行回调的过程中发生异常，此时调用 breakBarrier 破坏屏障 if (!ranAction) breakBarrier(); &#125; &#125; // loop until tripped, broken, interrupted, or timed out //线程运行到此处的线程都会被屏障挡住，并进入等待状态。 for (;;) &#123; try &#123; if (!timed) trip.await(); else if (nanos &gt; 0L) nanos = trip.awaitNanos(nanos); &#125; catch (InterruptedException ie) &#123; /* * 若下面的条件成立，则表明本轮运行还未结束。此时调用 breakBarrier * 破坏屏障，唤醒其他线程，并抛出异常 */ if (g == generation &amp;&amp; ! g.broken) &#123; breakBarrier(); throw ie; &#125; else &#123; // We're about to finish waiting even if we had not // been interrupted, so this interrupt is deemed to // "belong" to subsequent execution. /* * 若上面的条件不成立，则有两种可能： * 1. g != generation * 此种情况下，表明循环屏障的第 g 轮次的运行已经结束，屏障已经 * 进入了新的一轮运行轮次中。当前线程在稍后返回 到达屏障 的顺序即可 * * 2. g = generation 但 g.broken = true * 此种情况下，表明已经有线程执行过 breakBarrier 方法了，当前 * 线程则会在稍后抛出 BrokenBarrierException */ Thread.currentThread().interrupt(); &#125; &#125; // 屏障被破坏，则抛出 BrokenBarrierException 异常 if (g.broken) throw new BrokenBarrierException(); // 屏障进入新的运行轮次，此时返回线程在上一轮次到达屏障的顺序 if (g != generation) return index; // 超时判断 if (timed &amp;&amp; nanos &lt;= 0L) &#123; breakBarrier(); throw new TimeoutException(); &#125; &#125; &#125; finally &#123; lock.unlock(); &#125;&#125;/** * 开启新的一轮运行过程 */private void nextGeneration() &#123; // signal completion of last generation trip.signalAll();// 唤醒所有处于等待状态中的线程 // set up next generation count = parties;// 重置 count generation = new Generation();// 重新创建 Generation，表明进入循环屏障进入新的一轮运行轮次中&#125;/** * 破坏屏障 */private void breakBarrier() &#123; generation.broken = true;// 设置屏障是否被破坏标志 count = parties;// 重置 count trip.signalAll();// 唤醒所有处于等待状态中的线程&#125;//------------------------AQS----------------------//public final void signalAll() &#123; if (!isHeldExclusively()) // 不被当前线程独占，抛出异常 throw new IllegalMonitorStateException(); // 保存condition队列头结点 Node first = firstWaiter; if (first != null) // 头结点不为空 // 唤醒所有等待线程 doSignalAll(first);&#125;private void doSignalAll(Node first) &#123; // condition队列的头结点尾结点都设置为空 lastWaiter = firstWaiter = null; // 循环 do &#123; // 获取first结点的nextWaiter域结点 Node next = first.nextWaiter; // 设置first结点的nextWaiter域为空 first.nextWaiter = null; // 将first结点从condition队列转移到sync队列 transferForSignal(first); // 重新设置first first = next; &#125; while (first != null);&#125;final boolean transferForSignal(Node node) &#123; /* * If cannot change waitStatus, the node has been cancelled. */ if (!compareAndSetWaitStatus(node, Node.CONDITION, 0)) return false; /* * Splice onto queue and try to set waitStatus of predecessor to * indicate that thread is (probably) waiting. If cancelled or * attempt to set waitStatus fails, wake up to resync (in which * case the waitStatus can be transiently and harmlessly wrong). */ Node p = enq(node); int ws = p.waitStatus; if (ws &gt; 0 || !compareAndSetWaitStatus(p, ws, Node.SIGNAL)) LockSupport.unpark(node.thread); return true;&#125;private Node enq(final Node node) &#123; for (;;) &#123; // 无限循环，确保结点能够成功入队列 // 保存尾结点 Node t = tail; if (t == null) &#123; // 尾结点为空，即还没被初始化 if (compareAndSetHead(new Node())) // 头结点为空，并设置头结点为新生成的结点 tail = head; // 头结点与尾结点都指向同一个新生结点 &#125; else &#123; // 尾结点不为空，即已经被初始化过 // 将node结点的prev域连接到尾结点 node.prev = t; if (compareAndSetTail(t, node)) &#123; // 比较结点t是否为尾结点，若是则将尾结点设置为node // 设置尾结点的next域为node t.next = node; return t; // 返回尾结点 &#125; &#125; &#125;&#125; reset分析 123456789101112131415/** * reset 方法用于强制重置屏障，使屏障进入新一轮的运行过程中 */public void reset() &#123; final ReentrantLock lock = this.lock; lock.lock(); try &#123; // 破坏屏障 breakBarrier(); // break the current generation // 开启新一轮的运行过程 nextGeneration(); // start a new generation &#125; finally &#123; lock.unlock(); &#125;&#125; 与CountDownLatch区别 差异点 CountDownLatch CyclicBarrier 是否可循环使用 否 是 是否可设置回调 否 是 总结CyclicBarrier底层是基于ReentrantLock和AbstractQueuedSynchronizer来实现的.]]></content>
      <categories>
        <category>juc</category>
      </categories>
      <tags>
        <tag>CyclicBarrier</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java 线程同步组件 CountDownLatch]]></title>
    <url>%2F2018%2F11%2F12%2FJava%E7%BA%BF%E7%A8%8B%E5%90%8C%E6%AD%A5%E7%BB%84%E4%BB%B6CountDownLatch%2F</url>
    <content type="text"><![CDATA[简介CountDownLatch 允许一个或一组线程等待其他线程完成后再恢复运行。线程可通过调用await方法进入等待状态，在其他线程调用countDown方法将计数器减为0后，处于等待状态的线程即可恢复运行。 CountDownLatch 的同步功能是基于 AQS 实现的，CountDownLatch 使用 AQS 中的 state 成员变量作为计数器。在 state 不为0的情况下，凡是调用 await 方法的线程将会被阻塞，并被放入 AQS 所维护的同步队列中进行等待。大致示意图如下：每个阻塞的线程都会被封装成节点对象，节点之间通过 prev 和 next 指针形成同步队列。初始情况下，队列的头结点是一个虚拟节点。该节点仅是一个占位符，没什么特别的意义。每当有一个线程调用 countDown 方法，就将计数器 state–。当 state 被减至0时，队列中的节点就会按照 FIFO 顺序被唤醒，被阻塞的线程即可恢复运行。 CountDownLatch 本身的原理并不难理解，不过如果大家想深入理解 CountDownLatch 的实现细节，那么需要先去学习一下 AQS 的相关原理。CountDownLatch 是基于 AQS 实现的，所以理解 AQS 是学习 CountDownLatch 的前置条件，可以读这篇文章 AbstractQueuedSynchronizer源码分析。 Demo例子该例子前几天写在这篇文章 ReentrantLock源码分析123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354/** * reentrantloct 测试 * @author: peijiepang * @date 2018/11/7 * @Description: */public class ReentrantLockTest extends Thread&#123; private final static Logger LOGGER = LoggerFactory.getLogger(ReentrantLockTest.class); private ReentrantLock reentrantLock = new ReentrantLock(); private CountDownLatch countDownLatch = null; public static int j = 0; public ReentrantLockTest(String threadName,CountDownLatch countDownLatch) &#123; super(threadName); this.countDownLatch = countDownLatch; &#125; @Override public void run() &#123; for(int i=0;i&lt;1000;i++)&#123; //可限时加锁 //reentrantLock.tryLock(1000,TimeUnit.MILLISECONDS); //可响应线程中断请求 //reentrantLock.lockInterruptibly(); //可指定公平锁 //ReentrantLock fairLock = new ReentrantLock(true); reentrantLock.lock(); try&#123; LOGGER.info("&#123;&#125;:&#123;&#125;",Thread.currentThread().getName(),i); j++; &#125;finally &#123; reentrantLock.unlock(); &#125; &#125; countDownLatch.countDown(); &#125; public static void main(String[] args) throws InterruptedException &#123; CountDownLatch countDownLatch = new CountDownLatch(2); ReentrantLockTest reentrantLockTest1 = new ReentrantLockTest("thread1",countDownLatch); ReentrantLockTest reentrantLockTest2 = new ReentrantLockTest("thread2",countDownLatch); reentrantLockTest1.start(); reentrantLockTest2.start(); countDownLatch.await(); LOGGER.info("---------j:&#123;&#125;",j); &#125;&#125; 源码分析 类图 构造函数 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768/** * CountDownLatch 的同步控制器，继承自 AQS */private static final class Sync extends AbstractQueuedSynchronizer &#123; private static final long serialVersionUID = 4982264981922014374L; Sync(int count) &#123; setState(count); // 设置 AQS state &#125; int getCount() &#123; return getState(); &#125; /** * 尝试在共享状态下获取同步状态，该方法在 AQS 中是抽象方法，这里进行了覆写 * @param acquires * @return */ protected int tryAcquireShared(int acquires) &#123; return (getState() == 0) ? 1 : -1; //如果 state = 0，则返回1，表明可获取同步状态 此时线程调用 await 方法时就不会被阻塞。 &#125; /** * 尝试在共享状态下释放同步状态，该方法在 AQS 中也是抽象方法 * @param releases * @return */ protected boolean tryReleaseShared(int releases) &#123; // Decrement count; signal when transition to zero /* * 下面的逻辑是将 state--，state 减至0时，调用 await 等待的线程会被唤醒。 * 这里使用循环 + CAS，表明会存在竞争的情况，也就是多个线程可能会同时调用 * countDown 方法。在 state 不为0的情况下，线程调用 countDown 是必须要完 * 成 state-- 这个操作。所以这里使用了循环 + CAS，确保 countDown 方法可正 * 常运行。 */ for (;;) &#123; int c = getState(); // 获取 state if (c == 0) return false; int nextc = c-1; if (compareAndSetState(c, nextc)) // 使用 CAS 设置新的 state 值 return nextc == 0; &#125; &#125;&#125;/** * 同步器 */private final Sync sync;/** * Constructs a &#123;@code CountDownLatch&#125; initialized with the given count. * * @param count the number of times &#123;@link #countDown&#125; must be invoked * before threads can pass through &#123;@link #await&#125; * @throws IllegalArgumentException if &#123;@code count&#125; is negative *//** * CountDownLatch 的构造方法，该方法要求传入大于0的整型数值作为计数器 * @param count */public CountDownLatch(int count) &#123; if (count &lt; 0) throw new IllegalArgumentException("count &lt; 0"); this.sync = new Sync(count); //初始化 Sync&#125; await分析CountDownLatch中有两个版本的 await 方法，一个响应中断，另一个在此基础上增加了超时功能。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208/** * 该方法会使线程进入等待状态，直到计数器减至0，或者线程被中断。当计数器为0时，调用 * 此方法将会立即返回，不会被阻塞住。 */public void await() throws InterruptedException &#123; sync.acquireSharedInterruptibly(1); //调用 AQS 中的 acquireSharedInterruptibly 方法&#125;/** * 带有超时功能的 await * @param timeout * @param unit * @return * @throws InterruptedException */public boolean await(long timeout, TimeUnit unit) throws InterruptedException &#123; return sync.tryAcquireSharedNanos(1, unit.toNanos(timeout));&#125;//--- AbstractQueuedSynchronizer---////该函数只是简单的判断AQS的state是否为0，为0则返回1，不为0则返回-1。doAcquireSharedInterruptibly函数的源码如下 public final void acquireSharedInterruptibly(int arg) throws InterruptedException &#123; // 若线程被中断，则直接抛出中断异常 if (Thread.interrupted()) throw new InterruptedException(); // 调用 Sync 中覆写的 tryAcquireShared 方法，尝试获取同步状态 if (tryAcquireShared(arg) &lt; 0) /* * 若 tryAcquireShared 小于0，则表示获取同步状态失败， * 此时将线程放入 AQS 的同步队列中进行等待。 */ doAcquireSharedInterruptibly(arg);&#125;private void doAcquireSharedInterruptibly(int arg) throws InterruptedException &#123; // 添加节点至等待队列 final Node node = addWaiter(Node.SHARED); boolean failed = true; try &#123; for (;;) &#123; // 无限循环 // 获取node的前驱节点 final Node p = node.predecessor(); if (p == head) &#123; // 前驱节点为头结点 // 试图在共享模式下获取对象状态 int r = tryAcquireShared(arg); if (r &gt;= 0) &#123; // 获取成功 // 设置头结点并进行繁殖 setHeadAndPropagate(node, r); // 设置节点next域 p.next = null; // help GC failed = false; return; &#125; &#125; if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) // 在获取失败后是否需要禁止线程并且进行中断检查 // 抛出异常 throw new InterruptedException(); &#125; &#125; finally &#123; if (failed) cancelAcquire(node); &#125;&#125;//在AQS的doAcquireSharedInterruptibly中可能会再次调用CountDownLatch的内部类Sync的tryAcquireShared方法和AQS的setHeadAndPropagate方法。setHeadAndPropagate方法源码如下private void setHeadAndPropagate(Node node, int propagate) &#123; // 获取头结点 Node h = head; // Record old head for check below // 设置头结点 setHead(node); /* * Try to signal next queued node if: * Propagation was indicated by caller, * or was recorded (as h.waitStatus either before * or after setHead) by a previous operation * (note: this uses sign-check of waitStatus because * PROPAGATE status may transition to SIGNAL.) * and * The next node is waiting in shared mode, * or we don't know, because it appears null * * The conservatism in both of these checks may cause * unnecessary wake-ups, but only when there are multiple * racing acquires/releases, so most need signals now or soon * anyway. */ // 进行判断 if (propagate &gt; 0 || h == null || h.waitStatus &lt; 0 || (h = head) == null || h.waitStatus &lt; 0) &#123; // 获取节点的后继 Node s = node.next; if (s == null || s.isShared()) // 后继为空或者为共享模式 // 以共享模式进行释放 doReleaseShared(); &#125;&#125;//该方法设置头结点并且释放头结点后面的满足条件的结点，该方法中可能会调用到AQS的doReleaseShared方法，其源码如下。private void doReleaseShared() &#123; /* * Ensure that a release propagates, even if there are other * in-progress acquires/releases. This proceeds in the usual * way of trying to unparkSuccessor of head if it needs * signal. But if it does not, status is set to PROPAGATE to * ensure that upon release, propagation continues. * Additionally, we must loop in case a new node is added * while we are doing this. Also, unlike other uses of * unparkSuccessor, we need to know if CAS to reset status * fails, if so rechecking. */ // 无限循环 for (;;) &#123; // 保存头结点 Node h = head; if (h != null &amp;&amp; h != tail) &#123; // 头结点不为空并且头结点不为尾结点 // 获取头结点的等待状态 int ws = h.waitStatus; if (ws == Node.SIGNAL) &#123; // 状态为SIGNAL if (!compareAndSetWaitStatus(h, Node.SIGNAL, 0)) // 不成功就继续 continue; // loop to recheck cases // 释放后继结点 unparkSuccessor(h); &#125; else if (ws == 0 &amp;&amp; !compareAndSetWaitStatus(h, 0, Node.PROPAGATE)) // 状态为0并且不成功，继续 continue; // loop on failed CAS &#125; if (h == head) // 若头结点改变，继续循环 break; &#125;&#125;``` &gt; 从上面的代码中可以看出，CountDownLatch await 方法实际上调用的是 AQS 的 acquireSharedInterruptibly 方法。该方法会在内部调用 Sync 所覆写的 tryAcquireShared 方法。在 state != 0时，tryAcquireShared 返回值 -1。此时线程将进入 doAcquireSharedInterruptibly 方法中，在此方法中，线程会被放入同步队列中进行等待。若 state = 0，此时 tryAcquireShared 返回1，acquireSharedInterruptibly 会直接返回。此时调用 await 的线程也不会被阻塞住。4. countDown分析```java/** * 此函数将递减锁存器的计数，如果计数到达零，则释放所有等待的线程 */public void countDown() &#123; sync.releaseShared(1);//对countDown的调用转换为对Sync对象的releaseShared（从AQS继承而来）方法的调用&#125;/** * 此函数会以共享模式释放对象，并且在函数中会调用到CountDownLatch的tryReleaseShared函数，并且可能会调用AQS的doReleaseShared函数 */public final boolean releaseShared(int arg) &#123; if (tryReleaseShared(arg)) &#123; doReleaseShared(); return true; &#125; return false;&#125;// Sync重写的tryreleasesharedprotected boolean tryReleaseShared(int releases) &#123; // Decrement count; signal when transition to zero // 无限循环 for (;;) &#123; // 获取状态 int c = getState(); if (c == 0) // 没有被线程占有 return false; // 下一个状态 int nextc = c-1; if (compareAndSetState(c, nextc)) // 比较并且设置成功 return nextc == 0; &#125;&#125;//调用aqs的doReleaseSharedprivate void doReleaseShared() &#123; /* * Ensure that a release propagates, even if there are other * in-progress acquires/releases. This proceeds in the usual * way of trying to unparkSuccessor of head if it needs * signal. But if it does not, status is set to PROPAGATE to * ensure that upon release, propagation continues. * Additionally, we must loop in case a new node is added * while we are doing this. Also, unlike other uses of * unparkSuccessor, we need to know if CAS to reset status * fails, if so rechecking. */ // 无限循环 for (;;) &#123; // 保存头结点 Node h = head; if (h != null &amp;&amp; h != tail) &#123; // 头结点不为空并且头结点不为尾结点 // 获取头结点的等待状态 int ws = h.waitStatus; if (ws == Node.SIGNAL) &#123; // 状态为SIGNAL if (!compareAndSetWaitStatus(h, Node.SIGNAL, 0)) // 不成功就继续 continue; // loop to recheck cases // 释放后继结点 unparkSuccessor(h); &#125; else if (ws == 0 &amp;&amp; !compareAndSetWaitStatus(h, 0, Node.PROPAGATE)) // 状态为0并且不成功，继续 continue; // loop on failed CAS &#125; if (h == head) // 若头结点改变，继续循环 break; &#125;&#125; 总结经过分析CountDownLatch的源码可知，其底层结构仍然是AQS，对其线程所封装的结点是采用共享模式，而ReentrantLock是采用独占模式。由于采用的共享模式，所以会导致后面的操作会有所差异，通过阅读源码就会很容易掌握CountDownLatch实现机制。]]></content>
      <categories>
        <category>juc</category>
      </categories>
      <tags>
        <tag>CountDownLatch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[AbstractQueuedSynchronizer源码分析]]></title>
    <url>%2F2018%2F11%2F10%2FAbstractQueuedSynchronizer%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[AbstractQueuedSynchronizer介绍AQS是一个用来构建锁和同步器的框架，使用AQS能简单且高效地构造出应用广泛的大量的同步器，比如我们提到的ReentrantLock，Semaphore，其他的诸如ReentrantReadWriteLock，SynchronousQueue，FutureTask等等皆是基于AQS的。当然，我们自己也能利用AQS非常轻松容易地构造出符合我们自己需求的同步器。 AQS核心思想是，如果被请求的共享资源空闲，则将当前请求资源的线程设置为有效的工作线程，并且将共享资源设置为锁定状态。如果被请求的共享资源被占用，那么就需要一套线程阻塞等待以及被唤醒时锁分配的机制，这个机制AQS是用CLH队列锁实现的，即将暂时获取不到锁的线程加入到队列中。 CLH(Craig,Landin,and Hagersten)队列是一个虚拟的双向队列（虚拟的双向队列即不存在队列实例，仅存在结点之间的关联关系）。AQS是将每条请求共享资源的线程封装成一个CLH锁队列的一个结点（Node）来实现锁的分配。 AQS原理图 AQS使用一个int成员变量来表示同步状态，通过内置的FIFO队列来完成获取资源线程的排队工作。AQS使用CAS对该同步状态进行原子操作实现对其值的修改。1private volatile int state;//共享变量，使用volatile修饰保证线程可见性 状态信息通过procted类型的getState，setState，compareAndSetState进行操作123456789101112//返回同步状态的当前值protected final int getState() &#123; return state;&#125; // 设置同步状态的值protected final void setState(int newState) &#123; state = newState;&#125;//原子地（CAS操作）将同步状态值设置为给定值update如果当前同步状态的值等于expect（期望值）protected final boolean compareAndSetState(int expect, int update) &#123; return unsafe.compareAndSwapInt(this, stateOffset, expect, update);&#125; AQS 对资源的共享方式AQS定义两种资源共享方式 Exclusive（独占）：只有一个线程能执行，如ReentrantLock。又可分为公平锁和非公平锁： 1.1 公平锁：按照线程在队列中的排队顺序，先到者先拿到锁 1.2 非公平锁：当线程要获取锁时，无视队列顺序直接去抢锁，谁抢到就是谁的 Share（共享）：多个线程可同时执行，如Semaphore/CountDownLatch。Semaphore、CountDownLatCh、 CyclicBarrier、ReadWriteLock 我们都会在后面讲到。 不同的自定义同步器争用共享资源的方式也不同。自定义同步器在实现时只需要实现共享资源 state 的获取与释放方式即可，至于具体线程等待队列的维护（如获取资源失败入队/唤醒出队等），AQS已经在上层已经帮我们实现好了。 AQS底层使用了模板方法模式同步器的设计是基于模板方法模式的，如果需要自定义同步器一般的方式是这样（模板方法模式很经典的一个应用）： 使用者继承AbstractQueuedSynchronizer并重写指定的方法。（这些重写方法很简单，无非是对于共享资源state的获取和释放） 将AQS组合在自定义同步组件的实现中，并调用其模板方法，而这些模板方法会调用使用者重写的方法。 AQS使用了模板方法模式，自定义同步器时需要重写下面几个AQS提供的模板方法：12345isHeldExclusively()//该线程是否正在独占资源。只有用到condition才需要去实现它。tryAcquire(int)//独占方式。尝试获取资源，成功则返回true，失败则返回false。tryRelease(int)//独占方式。尝试释放资源，成功则返回true，失败则返回false。tryAcquireShared(int)//共享方式。尝试获取资源。负数表示失败；0表示成功，但没有剩余可用资源；正数表示成功，且有剩余资源。tryReleaseShared(int)//共享方式。尝试释放资源，成功则返回true，失败则返回false。 默认情况下，每个方法都抛出 UnsupportedOperationException。 这些方法的实现必须是内部线程安全的，并且通常应该简短而不是阻塞。AQS类中的其他方法都是final ，所以无法被其他类使用，只有这几个方法可以被其他类使用。以ReentrantLock为例，state初始化为0，表示未锁定状态。A线程lock()时，会调用tryAcquire()独占该锁并将state+1。此后，其他线程再tryAcquire()时就会失败，直到A线程unlock()到state=0（即释放锁）为止，其它线程才有机会获取该锁。当然，释放锁之前，A线程自己是可以重复获取此锁的（state会累加），这就是可重入的概念。但要注意，获取多少次就要释放多么次，这样才能保证state是能回到零态的。 再以CountDownLatch以例，任务分为N个子线程去执行，state也初始化为N（注意N要与线程个数一致）。这N个子线程是并行执行的，每个子线程执行完后countDown()一次，state会CAS(Compare and Swap)减1。等到所有子线程都执行完后(即state=0)，会unpark()主调用线程，然后主调用线程就会从await()函数返回，继续后余动作。 一般来说，自定义同步器要么是独占方法，要么是共享方式，他们也只需实现tryAcquire-tryRelease、tryAcquireShared-tryReleaseShared中的一种即可。但AQS也支持自定义同步器同时实现独占和共享两种方式，如ReentrantReadWriteLock。 自定义实现独占锁Demo12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576package com.fly.learn.aqs;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import java.util.concurrent.locks.AbstractQueuedSynchronizer;/** * 独占锁自定义实现 * @author: peijiepang * @date 2018/11/10 * @Description: */public class ExclusiveLock &#123; private final static Logger LOGGER = LoggerFactory.getLogger(ExclusiveLock.class); /** * 独占锁实现 */ private final class Sync extends AbstractQueuedSynchronizer&#123; @Override protected boolean tryAcquire(int arg) &#123; //当状态为0的时候获取锁，CAS操作成功，则state状态为1， if (compareAndSetState(0, 1)) &#123; setExclusiveOwnerThread(Thread.currentThread()); return true; &#125; return false; &#125; @Override protected boolean tryRelease(int arg) &#123; //释放锁，将同步状态置为0 if (getState() == 0) throw new IllegalMonitorStateException(); setExclusiveOwnerThread(null); setState(0); return true; &#125; @Override protected boolean isHeldExclusively() &#123; // 1表示处于独占状态 return getState() == 1; &#125; &#125; /** * 独占锁 */ private final Sync sync = new Sync(); /** * 加锁-阻塞方式 */ public void lock()&#123; sync.acquire(1); &#125; /** * 尝试加锁，不一定成功 * @return */ public boolean tryLock()&#123; return sync.tryAcquire(1); &#125; /** * 解锁 */ public void unLock()&#123; sync.release(1); &#125;&#125; 源码分析我们先来简单描述下AQS的基本实现，前面我们提到过，AQS维护一个共享资源state，通过内置的FIFO来完成获取资源线程的排队工作。（这个内置的同步队列称为”CLH”队列）。该队列由一个一个的Node结点组成，每个Node结点维护一个prev引用和next引用，分别指向自己的前驱和后继结点。AQS维护两个指针，分别指向队列头部head和尾部tail。 当线程获取资源失败（比如tryAcquire时试图设置state状态失败），会被构造成一个结点加入CLH队列中，同时当前线程会被阻塞在队列中（通过LockSupport.park实现，其实是等待态）。当持有同步状态的线程释放同步状态时，会唤醒后继结点，然后此结点线程继续加入到对同步状态的争夺中。 Node结点 1234567891011121314151617181920static final class Node &#123; /** waitStatus值，表示线程已被取消（等待超时或者被中断）*/ static final int CANCELLED = 1; /** waitStatus值，表示后继线程需要被唤醒（unpaking）*/ static final int SIGNAL = -1; /**waitStatus值，表示结点线程等待在condition上，当被signal后，会从等待队列转移到同步到队列中 */ /** waitStatus value to indicate thread is waiting on condition */ static final int CONDITION = -2; /** waitStatus值，表示下一次共享式同步状态会被无条件地传播下去 static final int PROPAGATE = -3; /** 等待状态，初始为0 */ volatile int waitStatus; /**当前结点的前驱结点 */ volatile Node prev; /** 当前结点的后继结点 */ volatile Node next; /** 与当前结点关联的排队中的线程 */ volatile Thread thread; /** ...... */&#125; 独占式-acquire–获取同步状态 12345public final void acquire(int arg) &#123; if (!tryAcquire(arg) &amp;&amp; //调用使用者重写的tryAcquire方法，若返回true，意味着获取同步状态成功，后面的逻辑不再执行；若返回false，也就是获取同步状态失败 acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) //获取同步状态失败，构造独占式同步结点，通过addWatiter将此结点添加到同步队列的尾部（此时可能会有多个线程结点试图加入同步队列尾部，需要以线程安全的方 式添加） selfInterrupt(); //该结点以在队列中尝试获取同步状态，若获取不到，则阻塞结点线程，直到被前驱结点唤醒或者被中断。&#125; 独占式-addWaiter-为获取同步状态失败的线程，构造成一个Node结点，添加到同步队列尾部 12345678910111213141516171819202122232425262728293031323334353637383940/** * 构造新节点 * @param mode * @return */private Node addWaiter(Node mode) &#123; Node node = new Node(Thread.currentThread(), mode); // Try the fast path of enq; backup to full enq on failure Node pred = tail; //指向尾节点 if (pred != null) &#123; node.prev = pred; if (compareAndSetTail(pred, node)) &#123; //如果尾结点不为空，CAS快速尝试在尾部添加，若CAS设置成功，返回 pred.next = node; return node; &#125; &#125; enq(node); return node;&#125;/** * 如果没有节点则自旋转设置节点 * @param node * @return */private Node enq(final Node node) &#123; for (;;) &#123; Node t = tail; if (t == null) &#123; // Must initialize if (compareAndSetHead(new Node())) //如果队列为空，创建结点，同时被head和tail引用 tail = head; &#125; else &#123; node.prev = t; if (compareAndSetTail(t, node)) &#123; //cas设置尾结点，不成功就一直重试 t.next = node; return t; &#125; &#125; &#125;&#125; 独占式-acquireQueued–在等待队列中排队拿号acquireQueued内部也是一个死循环，只有前驱结点是头结点的结点，也就是老二结点，才有机会去tryAcquire；若tryAcquire成功，表示获取同步状态成功，将此结点设置为头结点；若是非老二结点，或者tryAcquire失败，则进入shouldParkAfterFailedAcquire去判断判断当前线程是否应该阻塞，若可以，调用parkAndCheckInterrupt阻塞当前线程，直到被中断或者被前驱结点唤醒。若还不能休息，继续循环。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071/** * 在等待队列中排队拿号 * @param node * @param arg * @return */final boolean acquireQueued(final Node node, int arg) &#123; boolean failed = true; try &#123; boolean interrupted = false; for (;;) &#123; final Node p = node.predecessor(); //找到当前结点的前驱结点 if (p == head &amp;&amp; tryAcquire(arg)) &#123; //如果前驱结点是头结点，才tryAcquire，其他结点是没有机会tryAcquire的。 setHead(node); //获取同步状态成功，将当前结点设置为头结点。 p.next = null; // help GC failed = false; return interrupted; &#125; if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; // 如果没有获取到同步状态，通过shouldParkAfterFailedAcquire判断是否应该阻塞，parkAndCheckInterrupt用来阻塞线程 parkAndCheckInterrupt()) interrupted = true; &#125; &#125; finally &#123; if (failed) cancelAcquire(node); &#125;&#125;/** * 主要用于检查状态是否阻塞 * @param pred * @param node * @return */private static boolean shouldParkAfterFailedAcquire(Node pred, Node node) &#123; int ws = pred.waitStatus; //拿到前驱的状态 if (ws == Node.SIGNAL) //如果已经告诉前驱拿完号后通知自己一下，那就可以安心休息了 /* * This node has already set status asking a release * to signal it, so it can safely park. */ /* * 如果前驱放弃了，那就一直往前找，直到找到最近一个正常等待的状态，并排在它的后边。 * 注意：那些放弃的结点，由于被自己“加塞”到它们前边，它们相当于形成一个无引用链，稍后就会被保安大叔赶走了(GC回收)！ */ return true; if (ws &gt; 0) &#123; /* * Predecessor was cancelled. Skip over predecessors and * indicate retry. */ do &#123; node.prev = pred = pred.prev; &#125; while (pred.waitStatus &gt; 0); pred.next = node; &#125; else &#123; /* * waitStatus must be 0 or PROPAGATE. Indicate that we * need a signal, but don't park yet. Caller will need to * retry to make sure it cannot acquire before parking. */ //如果前驱正常，那就把前驱的状态设置成SIGNAL，告诉它拿完号后通知自己一下。有可能失败，人家说不定刚刚释放完呢！ compareAndSetWaitStatus(pred, ws, Node.SIGNAL); &#125; return false;&#125;private final boolean parkAndCheckInterrupt() &#123; LockSupport.park(this); //调用park()使线程进入waiting状态 return Thread.interrupted(); //如果被唤醒，查看自己是不是被中断的。&#125; tryAcquire流程1. 调用自定义同步器的tryAcquire()尝试直接去获取资源，如果成功则直接返回；没成功，则addWaiter()将该线程加入等待队列的尾部，并标记为独占模式； 2. acquireQueued()使线程在等待队列中休息，有机会时（轮到自己，会被unpark()）会去尝试获取资源。获取到资源后才返回。如果在整个等待过程中被中断过，则返回true，否则返回false。 3. 如果线程在等待过程中被中断过，它是不响应的。只是获取资源后才再进行自我中断selfInterrupt()，将中断补上。 如下图： 独占式-release–释放同步状态 12345678910111213141516171819202122232425262728293031323334353637383940public final boolean release(int arg) &#123; if (tryRelease(arg)) &#123; //调用使用者重写的tryRelease方法，若成功，唤醒其后继结点，失败则返回false Node h = head; if (h != null &amp;&amp; h.waitStatus != 0) unparkSuccessor(h); //唤醒后继结点 return true; &#125; return false;&#125;/** * 唤醒后继结点 * @param node */private void unparkSuccessor(Node node) &#123; /* * If status is negative (i.e., possibly needing signal) try * to clear in anticipation of signalling. It is OK if this * fails or if status is changed by waiting thread. */ int ws = node.waitStatus; //获取wait状态 if (ws &lt; 0) compareAndSetWaitStatus(node, ws, 0); // 将等待状态waitStatus设置为初始值0 /* * Thread to unpark is held in successor, which is normally * just the next node. But if cancelled or apparently null, * traverse backwards from tail to find the actual * non-cancelled successor. */ Node s = node.next; if (s == null || s.waitStatus &gt; 0) &#123; //若后继结点为空，或状态为CANCEL（已失效），则从后尾部往前遍历找到一个处于正常阻塞状态的结点进行唤醒 s = null; for (Node t = tail; t != null &amp;&amp; t != node; t = t.prev) if (t.waitStatus &lt;= 0) s = t; &#125; if (s != null) LockSupport.unpark(s.thread); //使用LockSupprot唤醒结点对应的线程&#125; 共享式-acquireShared–获取同步状态共享式：共享式地获取同步状态。对于独占式同步组件来讲，同一时刻只有一个线程能获取到同步状态，其他线程都得去排队等待，其待重写的尝试获取同步状态的方法tryAcquire返回值为boolean，这很容易理解；对于共享式同步组件来讲，同一时刻可以有多个线程同时获取到同步状态，这也是“共享”的意义所在。其待重写的尝试获取同步状态的方法tryAcquireShared返回值为int。 当返回值大于0时，表示获取同步状态成功，同时还有剩余同步状态可供其他线程获取； 当返回值等于0时，表示获取同步状态成功，但没有可用同步状态； 当返回值小于0时，表示获取同步状态失败。 123456789101112131415161718192021222324252627282930313233343536373839404142public final void acquireShared(int arg) &#123; if (tryAcquireShared(arg) &lt; 0) ///返回值小于0，获取同步状态失败，排队去；获取同步状态成功，直接返回去干自己的事儿。 doAcquireShared(arg);&#125;private void doAcquireShared(int arg) &#123; final Node node = addWaiter(Node.SHARED);//构造一个共享结点，添加到同步队列尾部。若队列初始为空，先添加一个无意义的傀儡结点，再将新节点添加到队列尾部。 boolean failed = true;//是否获取成功 try &#123; boolean interrupted = false;//线程parking过程中是否被中断过 for (;;) &#123;//死循环 final Node p = node.predecessor();//找到前驱结点 if (p == head) &#123;//头结点持有同步状态，只有前驱是头结点，才有机会尝试获取同步状态 int r = tryAcquireShared(arg);//尝试获取同步装填 if (r &gt;= 0) &#123;//r&gt;=0,获取成功 setHeadAndPropagate(node, r);//获取成功就将当前结点设置为头结点，若还有可用资源，传播下去，也就是继续唤醒后继结点 p.next = null; // 方便GC if (interrupted) selfInterrupt(); failed = false; return; &#125; &#125; if (shouldParkAfterFailedAcquire(p, node) &amp;&amp;//是否能安心进入parking状态 parkAndCheckInterrupt())//阻塞线程 interrupted = true; &#125; &#125; finally &#123; if (failed) cancelAcquire(node); &#125;&#125;private void setHeadAndPropagate(Node node, int propagate) &#123; Node h = head; // Record old head for check below setHead(node); if (propagate &gt; 0 || h == null || h.waitStatus &lt; 0) &#123; Node s = node.next; if (s == null || s.isShared()) doReleaseShared(); &#125;&#125; 共享式-releaseShared–释放同步状态1234567891011121314151617181920212223242526public final boolean releaseShared(int arg) &#123; if (tryReleaseShared(arg)) &#123; doReleaseShared();//释放同步状态 return true; &#125; return false;&#125;private void doReleaseShared() &#123; for (;;) &#123;//死循环，共享模式，持有同步状态的线程可能有多个，采用循环CAS保证线程安全 Node h = head; if (h != null &amp;&amp; h != tail) &#123; int ws = h.waitStatus; if (ws == Node.SIGNAL) &#123; if (!compareAndSetWaitStatus(h, Node.SIGNAL, 0)) continue; unparkSuccessor(h);//唤醒后继结点 &#125; else if (ws == 0 &amp;&amp; !compareAndSetWaitStatus(h, 0, Node.PROPAGATE)) continue; &#125; if (h == head) break; &#125;&#125; 总结AQS是JUC中很多同步组件的构建基础，简单来讲，它内部实现主要是状态变量state和一个FIFO队列来完成，同步队列的头结点是当前获取到同步状态的结点，获取同步状态state失败的线程，会被构造成一个结点（或共享式或独占式）加入到同步队列尾部（采用自旋CAS来保证此操作的线程安全），随后线程会阻塞；释放时唤醒头结点的后继结点，使其加入对同步状态的争夺中。AQS为我们定义好了顶层的处理实现逻辑，我们在使用AQS构建符合我们需求的同步组件时，只需重写tryAcquire，tryAcquireShared，tryRelease，tryReleaseShared几个方法，来决定同步状态的释放和获取即可，至于背后复杂的线程排队，线程阻塞/唤醒，如何保证线程安全，都由AQS为我们完成了，这也是非常典型的模板方法的应用。AQS定义好顶级逻辑的骨架，并提取出公用的线程入队列/出队列，阻塞/唤醒等一系列复杂逻辑的实现，将部分简单的可由使用者决定的操作逻辑延迟到子类中去实现。]]></content>
      <categories>
        <category>juc</category>
      </categories>
      <tags>
        <tag>aqs</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ReentrantLock之Condition源码分析]]></title>
    <url>%2F2018%2F11%2F09%2FReentrantLock%E4%B9%8BCondition%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[ReentrantLock 定义Condition是JUC里面提供于控制线程释放锁, 然后进行等待其他获取锁的线程发送 signal 信号来进行唤醒的工具类. 主要特点 Condition内部主要是由一个装载线程节点 Node 的 Condition Queue 实现 对 Condition 的方法(await, signal等) 的调用必需是在本线程获取了独占锁的前提下 因为操作Condition的方法的前提是获取独占锁, 所以 Condition Queue 内部是一条不支持并发安全的单向 queue (这是相对于 AQS 里面的 Sync Queue)Demo实例12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455package com.fly.learn.reentrantlock;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import java.util.concurrent.locks.Condition;import java.util.concurrent.locks.ReentrantLock;/** * @author: peijiepang * @date 2018/11/8 * @Description: */public class ConditionTest extends Thread&#123; private final static Logger LOGGER = LoggerFactory.getLogger(ConditionTest.class); private ReentrantLock lock = null; private Condition condition = null; public ConditionTest(String name,ReentrantLock lock,Condition condition) &#123; super(name); this.lock = lock; this.condition = condition; &#125; @Override public void run() &#123; lock.lock(); try&#123; LOGGER.info("thread name:&#123;&#125; lock success.",Thread.currentThread().getName()); if(Thread.currentThread().getName().equals("test1"))&#123; condition.await();//释放锁，然后等待唤醒 LOGGER.info("thread name:&#123;&#125; 被唤醒,即将unlock.",Thread.currentThread().getName()); &#125;else if(Thread.currentThread().getName().equals("test2")) &#123; condition.signal();//唤醒等待线程 LOGGER.info("thread name:&#123;&#125; 唤醒队列中的线程,即将unlock.",Thread.currentThread().getName()); &#125; &#125;catch (InterruptedException ex)&#123; ex.printStackTrace(); &#125;finally &#123; lock.unlock(); LOGGER.info("thread name:&#123;&#125; unlock success.",Thread.currentThread().getName()); &#125; &#125; public static void main(String[] args) &#123; ReentrantLock reentrantLock = new ReentrantLock(); Condition condition = reentrantLock.newCondition(); ConditionTest test1 = new ConditionTest("test1",reentrantLock,condition); ConditionTest test2 = new ConditionTest("test2",reentrantLock,condition); test1.start(); test2.start(); &#125;&#125; 从如下执行结果来看，线程1先await释放锁，然后线程2获取到锁，接着线程2唤醒等待锁，然后线程2释放锁，最后线程1解锁等待中的锁。1234562018-11-08 23:17:50.065 [test1] INFO c.f.l.reentrantlock.ConditionTest - thread name:test1 lock success.2018-11-08 23:17:50.072 [test2] INFO c.f.l.reentrantlock.ConditionTest - thread name:test2 lock success.2018-11-08 23:17:50.072 [test2] INFO c.f.l.reentrantlock.ConditionTest - thread name:test2 唤醒队列中的线程,即将unlock.2018-11-08 23:17:50.072 [test2] INFO c.f.l.reentrantlock.ConditionTest - thread name:test2 unlock success.2018-11-08 23:17:50.072 [test1] INFO c.f.l.reentrantlock.ConditionTest - thread name:test1 被唤醒,即将unlock.2018-11-08 23:17:50.072 [test1] INFO c.f.l.reentrantlock.ConditionTest - thread name:test1 unlock success. 类图 源码分析 构造函数 1234567891011/** First node of condition queue. *//** Condition Queue 里面的头节点 */private transient Node firstWaiter;/** Last node of condition queue. *//** Condition Queue 里面的尾节点 */private transient Node lastWaiter;/** * Creates a new &#123;@code ConditionObject&#125; instance. */public ConditionObject() &#123; &#125; Condition Queue enqueue节点方法 addConditionWaiteraddConditionWaiter方法主要用于调用 Condition.await 时将当前节点封装成 一个Node, 加入到 Condition Queue里面.大家可以注意下, 下面对 Condition Queue 的操作都没考虑到 并发(Sync Queue 的队列是支持并发操作的), 这是为什么呢? 因为在进行操作 Condition 是当前的线程已经获取了AQS的独占锁, 所以不需要考虑并发的情况 1234567891011121314151617181920212223/** * Adds a new waiter to wait queue * 将当前线程封装成一个 Node 节点 放入大 Condition Queue 里面 * 大家可以注意到, 下面对 Condition Queue 的操作都没考虑到 并发(Sync Queue 的队列是支持并发操作的), 这是为什么呢? 因为在进行操作 Condition 是当前的线程已经获取了AQS的独占锁, 所以不需要考虑并发的情况 * @return */private Node addConditionWaiter() &#123; Node t = lastWaiter; // 1. Condition queue 的尾节点 // If lastWaiter is cancelled, clean out. // 2.尾节点已经Cancel, 直接进行清除, // 这里有1个问题, 1 何时出现t.waitStatus != Node.CONDITION -&gt; 在对线程进行中断时 ConditionObject -&gt; await -&gt; checkInterruptWhileWaiting -&gt; transferAfterCancelledWait "compareAndSetWaitStatus(node, Node.CONDITION, 0)" &lt;- 导致这种情况一般是 线程中断或 await 超时 // 一个注意点: 当Condition进行 awiat 超时或被中断时, Condition里面的节点是没有被删除掉的, 需要其他 await 在将线程加入 Condition Queue 时调用addConditionWaiter而进而删除, 或 await 操作差不多结束时, 调用 "node.nextWaiter != null" 进行判断而删除 (PS: 通过 signal 进行唤醒时 node.nextWaiter 会被置空, 而中断和超时时不会) if (t != null &amp;&amp; t.waitStatus != Node.CONDITION) &#123; unlinkCancelledWaiters(); // 3. 调用 unlinkCancelledWaiters 对 "waitStatus != Node.CONDITION" 的节点进行删除(在Condition里面的Node的waitStatus 要么是CONDITION(正常), 要么就是 0 (signal/timeout/interrupt)) t = lastWaiter; // 4. 获取最新的 lastWaiter &#125; Node node = new Node(Thread.currentThread(), Node.CONDITION);// 5. 将线程封装成 node 准备放入 Condition Queue 里面 if (t == null) firstWaiter = node; // 6 .Condition Queue 是空的 else t.nextWaiter = node; // 7. 最加到 queue 尾部 lastWaiter = node; // 8. 重新赋值 lastWaiter return node;&#125; Condition 唤醒 first节点方法 doSignal这里的唤醒指的是将节点从 Condition Queue 转移到 Sync Queue 里面 1234567891011/** * 唤醒 Condition Queue 里面的头节点, 注意这里的唤醒只是将 Node 从 Condition Queue 转到 Sync Queue 里面(这时的 Node 也还是能被 Interrupt) */private void doSignal(Node first) &#123; do &#123; if ( (firstWaiter = first.nextWaiter) == null) // 1. 将 first.nextWaiter 赋值给 nextWaiter 为下次做准备 lastWaiter = null; // 2. 这时若 nextWaiter == null, 则说明 Condition 为空了, 所以直接置空 lastWaiter first.nextWaiter = null; &#125; while (!transferForSignal(first) &amp;&amp; // 3. first.nextWaiter == null 是判断 Node 从 Condition queue 转移到 Sync Queue 里面是通过 signal 还是 timeout/interrupt (first = firstWaiter) != null); // 4. 调用 transferForSignal将 first 转移到 Sync Queue 里面, 返回不成功的话, 将 firstWaiter 赋值给 first&#125; Condition 唤醒 所有 节点方法 doSignalAll 123456789101112/** * 唤醒 Condition Queue 里面的所有的节点 */private void doSignalAll(Node first) &#123; lastWaiter = firstWaiter = null; // 1. 将 lastWaiter, firstWaiter 置空 do &#123; Node next = first.nextWaiter; // 2. 初始化下个换新的节点 first.nextWaiter = null; // 3. first.nextWaiter == null 是判断 Node 从 Condition queue 转移到 Sync Queue 里面是通过 signal 还是 timeout/interrupt transferForSignal(first); // 4. 调用 transferForSignal将 first 转移到 Sync Queue 里面 first = next; // 5. 开始换新 next 节点 &#125; while (first != null);&#125; Condition 删除取消节点的方法 unlinkCancelledWaiters一般的节点都会被 signal 唤醒, 从 Condition Queue 转移到 Sync Queue, 而若遇到 interrupt 或 等待超时, 则直接改变 node 的状态(从 CONDITION 变成 0), 并直接放入 Sync 里面, 而不清理Condition Queue 里面的节点, 所以需要下面的函数毫无疑问, 这是一段非常精巧的queue节点删除, 主要还是在 节点 trail 上, trail 节点可以理解为traverse整个 Condition Queue 时遇到的最后一个有效的节点 1234567891011121314151617181920212223/** * 在 调用 addConditionWaiter 将线程放入 Condition Queue 里面时 或 awiat 方法获取 差不多结束时 进行清理 Condition queue 里面的因 timeout/interrupt 而还存在的节点 * 这个删除操作比较巧妙, 其中引入了 trail 节点， 可以理解为traverse整个 Condition Queue 时遇到的最后一个有效的节点 */private void unlinkCancelledWaiters() &#123; Node t = firstWaiter; Node trail = null; while (t != null) &#123; Node next = t.nextWaiter; // 1. 先初始化 next 节点 if (t.waitStatus != Node.CONDITION) &#123; // 2. 节点不有效, 在Condition Queue 里面 Node.waitStatus 只有可能是 CONDITION 或是 0(timeout/interrupt引起的) t.nextWaiter = null; // 3. Node.nextWaiter 置空 if (trail == null) // 4. 一次都没有遇到有效的节点 firstWaiter = next; // 5. 将 next 赋值给 firstWaiter(此时 next 可能也是无效的, 这只是一个临时处理) else trail.nextWaiter = next; // 6. next 赋值给 trail.nextWaiter, 这一步其实就是删除节点 t if (next == null) lastWaiter = trail; // 7. next == null 说明 已经 traverse 完了 Condition Queue &#125; else trail = t; // 8. 将有效节点赋值给 trail t = next; &#125;&#125; Condition 唤醒首节点方法 signal 1234567891011/** * 将 Condition queue 的头节点转移到 Sync Queue 里面 * 在进行调用 signal 时, 当前的线程必须获取了 独占的锁 */public final void signal() &#123; if (!isHeldExclusively()) // 1. 判断当前的线程是否已经获取 独占锁 throw new IllegalMonitorStateException(); Node first = firstWaiter; if (first != null) doSignal(first); // 2. 调用 doSignal 进行转移&#125; Condition 唤醒所有节点方法 signalAll 12345678910/** * 将 Condition Queue 里面的节点都转移到 Sync Queue 里面 */public final void signalAll() &#123; if (!isHeldExclusively()) throw new IllegalMonitorStateException(); Node first = firstWaiter; if (first != null) doSignalAll(first);&#125; Condition 释放锁进行等待方法 awaitUninterruptibly 123456789101112131415/** * 不响应线程中断的方式进行 await */public final void awaitUninterruptibly() &#123; Node node = addConditionWaiter(); // 1. 将当前线程封装成一个 Node 放入 Condition Queue 里面 int savedState = fullyRelease(node); // 2. 释放当前线程所获取的所有的独占锁(PS: 独占的锁支持重入), 等等, 为什么要释放呢? 以为你调用 awaitUninterruptibly 方法的前提就是你已经获取了 独占锁 boolean interrupted = false; // 3. 线程中断标识 while (!isOnSyncQueue(node)) &#123; // 4. 这里是一个 while loop, 调用 isOnSyncQueue 判断当前的 Node 是否已经被转移到 Sync Queue 里面 LockSupport.park(this); // 5. 若当前 node 不在 sync queue 里面, 则先 block 一下等待其他线程调用 signal 进行唤醒; (这里若有其他线程对当前线程进行 中断的换, 也能进行唤醒) if (Thread.interrupted()) // 6. 判断这是唤醒是 signal 还是 interrupted(Thread.interrupted()会清楚线程的中断标记, 但没事, 我们有步骤7中的interrupted进行记录) interrupted = true; // 7. 说明这次唤醒是被中断而唤醒的,这个标记若是true的话, 在 awiat 离开时还要 自己中断一下(selfInterrupt), 其他的函数可能需要线程的中断标识 &#125; if (acquireQueued(node, savedState) || interrupted) // 8. acquireQueued 返回 true 说明线程在 block 的过程中式被 inetrrupt 过(其实 acquireQueued 返回 true 也有可能其中有一次唤醒是 通过 signal) selfInterrupt(); // 9. 自我中断, 外面的线程可以通过这个标识知道, 整个 awaitUninterruptibly 运行过程中 是否被中断过&#125; Condition 释放锁 进行等待的方法 awaitawait 此方法响应中断请求, 当接受到中断请求后会将节点从 Condition Queue 转移到 Sync Queue 12345678910111213141516171819202122/** * 支持 InterruptedException 的 await &lt;- 注意这里即使是线程被中断, * 还是需要获取了独占的锁后, 再 调用 lock.unlock 进行释放锁 */public final void await() throws InterruptedException &#123; if (Thread.interrupted()) // 1. 判断线程是否中断 throw new InterruptedException(); Node node = addConditionWaiter(); // 2. 将线程封装成一个 Node 放到 Condition Queue 里面, 其中可能有些清理工作 int savedState = fullyRelease(node); // 3. 释放当前线程所获取的所有的锁 (PS: 调用 await 方法时, 当前线程是必须已经获取了独占的锁) int interruptMode = 0; while (!isOnSyncQueue(node)) &#123; // 4. 判断当前线程是否在 Sync Queue 里面(这里 Node 从 Condtion Queue 里面转移到 Sync Queue 里面有两种可能 (1) 其他线程调用 signal 进行转移 (2) 当前线程被中断而进行Node的转移(就在checkInterruptWhileWaiting里面进行转移)) LockSupport.park(this); // 5. 当前线程没在 Sync Queue 里面, 则进行 block if ((interruptMode = checkInterruptWhileWaiting(node)) != 0)// 6. 判断此次线程的唤醒是否因为线程被中断, 若是被中断, 则会在checkInterruptWhileWaiting的transferAfterCancelledWait 进行节点的转移; 返回值 interruptMode != 0 break; &#125; if (acquireQueued(node, savedState) &amp;&amp; interruptMode != THROW_IE)// 7. 调用 acquireQueued在 Sync Queue 里面进行 独占锁的获取, 返回值表明在获取的过程中有没有被中断过 interruptMode = REINTERRUPT; if (node.nextWaiter != null) // clean up if cancelled // 8. 通过 "node.nextWaiter != null" 判断 线程的唤醒是中断还是 signal, 因为通过中断唤醒的话, 此刻代表线程的 Node 在 Condition Queue 与 Sync Queue 里面都会存在 unlinkCancelledWaiters(); // 9. 进行 cancelled 节点的清除 if (interruptMode != 0) // 10. "interruptMode != 0" 代表通过中断的方式唤醒线程 reportInterruptAfterWait(interruptMode); // 11. 根据 interruptMode 的类型决定是抛出异常, 还是自己再中断一下&#125; Condition 释放锁 进行等待的方法 awaitNanosawaitNanos 具有超时功能, 与响应中断的功能, 不管中断还是超时都会 将节点从 Condition Queue 转移到 Sync Queue 1234567891011121314151617181920212223242526272829303132333435/** * 所有 awaitXX 方法其实就是 * 0. 将当前的线程封装成 Node 加入到 Condition 里面 * 1. 丢到当前线程所拥有的 独占锁, * 2. 等待 其他获取 独占锁的线程的唤醒, 唤醒从 Condition Queue 到 Sync Queue 里面, 进而获取 独占锁 * 3. 最后获取 lock 之后, 在根据线程唤醒的方式(signal/interrupt) 进行处理 * 4. 最后还是需要调用 lock./unlock 进行释放锁 */public final long awaitNanos(long nanosTimeout) throws InterruptedException &#123; if (Thread.interrupted()) // 1. 判断线程是否中断 throw new InterruptedException(); Node node = addConditionWaiter(); // 2. 将线程封装成一个 Node 放到 Condition Queue 里面, 其中可能有些清理工作 int savedState = fullyRelease(node); // 3. 释放当前线程所获取的所有的锁 (PS: 调用 await 方法时, 当前线程是必须已经获取了独占的锁) final long deadline = System.nanoTime() + nanosTimeout; // 4. 计算 wait 的截止时间 int interruptMode = 0; while (!isOnSyncQueue(node)) &#123; // 5. 判断当前线程是否在 Sync Queue 里面(这里 Node 从 Condtion Queue 里面转移到 Sync Queue 里面有两种可能 (1) 其他线程调用 signal 进行转移 (2) 当前线程被中断而进行Node的转移(就在checkInterruptWhileWaiting里面进行转移)) if (nanosTimeout &lt;= 0L) &#123; // 6. 等待时间超时(这里的 nanosTimeout 是有可能 &lt; 0), transferAfterCancelledWait(node); // 7. 调用 transferAfterCancelledWait 将 Node 从 Condition 转移到 Sync Queue 里面 break; &#125; if (nanosTimeout &gt;= spinForTimeoutThreshold) // 8. 当剩余时间 &lt; spinForTimeoutThreshold, 其实函数 spin 比用 LockSupport.parkNanos 更高效 LockSupport.parkNanos(this, nanosTimeout);// 9. 进行线程的 block if ((interruptMode = checkInterruptWhileWaiting(node)) != 0)// 10. 判断此次线程的唤醒是否因为线程被中断, 若是被中断, 则会在checkInterruptWhileWaiting的transferAfterCancelledWait 进行节点的转移; 返回值 interruptMode != 0 break; // 说明此是通过线程中断的方式进行唤醒, 并且已经进行了 node 的转移, 转移到 Sync Queue 里面 nanosTimeout = deadline - System.nanoTime(); // 11. 计算剩余时间 &#125; if (acquireQueued(node, savedState) &amp;&amp; interruptMode != THROW_IE)// 12. 调用 acquireQueued在 Sync Queue 里面进行 独占锁的获取, 返回值表明在获取的过程中有没有被中断过 interruptMode = REINTERRUPT; if (node.nextWaiter != null) // 13. 通过 "node.nextWaiter != null" 判断 线程的唤醒是中断还是 signal, 因为通过中断唤醒的话, 此刻代表线程的 Node 在 Condition Queue 与 Sync Queue 里面都会存在 unlinkCancelledWaiters(); // 14. 进行 cancelled 节点的清除 if (interruptMode != 0) // 15. "interruptMode != 0" 代表通过中断的方式唤醒线程 reportInterruptAfterWait(interruptMode); // 16. 根据 interruptMode 的类型决定是抛出异常, 还是自己再中断一下 return deadline - System.nanoTime(); // 17 这个返回值代表是 通过 signal 还是 超时&#125; 11.Condition 释放锁 进行等待的方法 awaitUntil123456789101112131415161718192021222324252627282930313233@Overridepublic boolean awaitUntil(Date deadline) throws InterruptedException &#123; long abstime = deadline.getTime(); // 1. 判断线程是否中断 if(Thread.interrupted())&#123; throw new InterruptedException(); &#125; Node node = addConditionWaiter(); // 2. 将线程封装成一个 Node 放到 Condition Queue 里面, 其中可能有些清理工作 int savedState = fullyRelease(node); // 3. 释放当前线程所获取的所有的锁 (PS: 调用 await 方法时, 当前线程是必须已经获取了独占的锁) boolean timeout = false; int interruptMode = 0; while(!isOnSyncQueue(node))&#123; // 4. 判断当前线程是否在 Sync Queue 里面(这里 Node 从 Condtion Queue 里面转移到 Sync Queue 里面有两种可能 (1) 其他线程调用 signal 进行转移 (2) 当前线程被中断而进行Node的转移(就在checkInterruptWhileWaiting里面进行转移)) if(System.currentTimeMillis() &gt; abstime)&#123; // 5. 计算是否超时 timeout = transferAfterCancelledWait(node); // 6. 调用 transferAfterCancelledWait 将 Node 从 Condition 转移到 Sync Queue 里面 break; &#125; LockSupport.parkUntil(this, abstime); // 7. 进行 线程的阻塞 if((interruptMode = checkInterruptWhileWaiting(node)) != 0)&#123; // 8. 判断此次线程的唤醒是否因为线程被中断, 若是被中断, 则会在checkInterruptWhileWaiting的transferAfterCancelledWait 进行节点的转移; 返回值 interruptMode != 0 break; // 说明此是通过线程中断的方式进行唤醒, 并且已经进行了 node 的转移, 转移到 Sync Queue 里面 &#125; &#125; if(acquireQueued(node, savedState) &amp;&amp; interruptMode != THROW_IE)&#123; // 9. 调用 acquireQueued在 Sync Queue 里面进行 独占锁的获取, 返回值表明在获取的过程中有没有被中断过 interruptMode = REINTERRUPT; &#125; if(node.nextWaiter != null)&#123; // 10. 通过 "node.nextWaiter != null" 判断 线程的唤醒是中断还是 signal, 因为通过中断唤醒的话, 此刻代表线程的 Node 在 Condition Queue 与 Sync Queue 里面都会存在 unlinkCancelledWaiters(); // 11. 进行 cancelled 节点的清除 &#125; if(interruptMode != 0)&#123; // 12. "interruptMode != 0" 代表通过中断的方式唤醒线程 reportInterruptAfterWait(interruptMode); // 13. 根据 interruptMode 的类型决定是抛出异常, 还是自己再中断一下 &#125; return !timeout; // 13. 返回是否通过 interrupt 进行线程的唤醒&#125; 总结Condition主要是为了在J.U.C框架中提供和Java传统的监视器风格的wait，notify和notifyAll方法类似的功能。]]></content>
      <categories>
        <category>juc</category>
      </categories>
      <tags>
        <tag>condition</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ReentrantLock源码分析]]></title>
    <url>%2F2018%2F11%2F07%2FReentrantLock%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[ReentrantLock 定义ReentrantLock 是 JUC 中提供的可中断, 可重入获取, 支持超时, 支持尝试获取锁它主要有一下特点: 可重入, 一个线程获取独占锁后, 可多次获取, 多次释放(synchronized也一样, 只是synchronized内的代码执行异常后会自动释放到monitor上的锁) 支持中断(synchronized不支持) 支持超时机制, 支持尝试获取lock, 支持公不公平获取lock(主要区别在 判断 AQS 中的 Sync Queue 里面是否有其他线程等待获取 lock) 支持调用 Condition 提供的 await(释放lock, 并等待), signal(将线程节点从 Condition Queue 转移到 Sync Queue 里面) 在运行 synchronized 里面的代码若抛出异常, 则会自动释放监视器上的lock, 而 ReentrantLock 是需要显示的调用 unlock方法 Demo用法123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354/** * reentrantloct 测试 * @author: peijiepang * @date 2018/11/7 * @Description: */public class ReentrantLockTest extends Thread&#123; private final static Logger LOGGER = LoggerFactory.getLogger(ReentrantLockTest.class); private ReentrantLock reentrantLock = new ReentrantLock(); private CountDownLatch countDownLatch = null; public static int j = 0; public ReentrantLockTest(String threadName,CountDownLatch countDownLatch) &#123; super(threadName); this.countDownLatch = countDownLatch; &#125; @Override public void run() &#123; for(int i=0;i&lt;1000;i++)&#123; //可限时加锁 //reentrantLock.tryLock(1000,TimeUnit.MILLISECONDS); //可响应线程中断请求 //reentrantLock.lockInterruptibly(); //可指定公平锁 //ReentrantLock fairLock = new ReentrantLock(true); reentrantLock.lock(); try&#123; LOGGER.info("&#123;&#125;:&#123;&#125;",Thread.currentThread().getName(),i); j++; &#125;finally &#123; reentrantLock.unlock(); &#125; &#125; countDownLatch.countDown(); &#125; public static void main(String[] args) throws InterruptedException &#123; CountDownLatch countDownLatch = new CountDownLatch(2); ReentrantLockTest reentrantLockTest1 = new ReentrantLockTest("thread1",countDownLatch); ReentrantLockTest reentrantLockTest2 = new ReentrantLockTest("thread2",countDownLatch); reentrantLockTest1.start(); reentrantLockTest2.start(); countDownLatch.await(); LOGGER.info("---------j:&#123;&#125;",j); &#125;&#125; 类结构如下图 Sync是ReentrantLock的内部抽象类，继承自AbstractQueuedSynchronizer，实现了简单的获取锁和释放锁。NonfairSync和FairSync分别表示“非公平锁”和“公平锁”，都继承于Sync，并且都是ReentrantLock的内部类。 FairSync和NofairSync是继承Sync，公平锁和非公平锁的实现 ReentrantLock实现了Lock接口的lock-unlock方法，根据fair参数决定使用NonfairSync还是FairSync。 源码分析 构造函数，默认是非公平锁(吞吐量大)12345678910111213141516171819/** * 默认创建非公平锁 * Creates an instance of &#123;@code ReentrantLock&#125;. * This is equivalent to using &#123;@code ReentrantLock(false)&#125;. */public ReentrantLock() &#123; sync = new NonfairSync();&#125;/** * 通过fair来指定是否公平还是非公平 * Creates an instance of &#123;@code ReentrantLock&#125; with the * given fairness policy. * * @param fair &#123;@code true&#125; if this lock should use a fair ordering policy */public ReentrantLock(boolean fair) &#123; sync = fair ? new FairSync() : new NonfairSync();&#125; ReentrantLock的 lock 获取释放都是通过内部类 Sync 的子类 FairSync, NonfairSync 来实现, 而且两者都是继承 Sync, 而Sync是继承 AQS, 接下来我们看 FairSync 与 NonfairSync ReentrantLock 内部类 FairSync 与 NonfairSync1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768/** * 继承 Sync 实现非公平 * 公不公平的获取锁的区别: * 1. 非公平-&gt; 在获取时先cas改变一下 AQS 的state值, 改变成功就获取, 不然就加入到 AQS 的 Sync Queue 里面 * 2. 每次获取lock之前判断是否 AQS 里面的 Sync Queue 是否有等待获取的线程 * Sync object for non-fair locks */static final class NonfairSync extends Sync &#123; private static final long serialVersionUID = 7316153563782823691L; /** * Performs lock. Try immediate barge, backing up to normal * acquire on failure. */ final void lock() &#123; // 先cas改变一下 state 成功就表示获取 if (compareAndSetState(0, 1)) setExclusiveOwnerThread(Thread.currentThread());// 获取成功设置 exclusiveOwnerThread else acquire(1);// 获取不成功, 调用 AQS 的 acquire 进行获取 &#125; /** * 尝试获取锁 * @param acquires * @return */ protected final boolean tryAcquire(int acquires) &#123; return nonfairTryAcquire(acquires); &#125;&#125;/** * 继承 Sync的公平的方式获取锁 * Sync object for fair locks */static final class FairSync extends Sync &#123; private static final long serialVersionUID = -3000897897090466540L; final void lock() &#123; acquire(1); &#125; /** * 公平的方式获取锁 * Fair version of tryAcquire. Don't grant access unless * recursive call or no waiters or is first. */ protected final boolean tryAcquire(int acquires) &#123; final Thread current = Thread.currentThread();// 1. 获取当前的 线程 int c = getState();// 2. c == 0 -&gt; 现在还没有线程获取锁 if (c == 0) &#123; if (!hasQueuedPredecessors() &amp;&amp; compareAndSetState(0, acquires)) &#123; // 3. 判断 AQS Sync Queue 里面是否有线程等待获取 锁,若没有 直接 CAS 获取lock setExclusiveOwnerThread(current);// 4. 获取 lock 成功 设置 exclusiveOwnerThread return true; &#125; &#125; else if (current == getExclusiveOwnerThread()) &#123; // 5. 已经有线程获取锁, 判断是否是当前的线程 //判断是否可重入 int nextc = c + acquires; // 6. 下面是进行lock 的重入, 就是计数器加 1 if (nextc &lt; 0) throw new Error("Maximum lock count exceeded"); setState(nextc); return true; &#125; return false; &#125;&#125; 从代码中, 我们可以看出公平公平主要区别： 非公平-&gt; 在获取时先cas改变一下 AQS 的state值, 改变成功就获取, 不然就加入到 AQS 的 Sync Queue 里面 每次获取lock之前判断是否 AQS 里面的 Sync Queue 是否有等待获取的线程 ReentrantLock 内部类 Sync1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283/*** Base of synchronization control for this lock. Subclassed* into fair and nonfair versions below. Uses AQS state to* represent the number of holds on the lock.*/abstract static class Sync extends AbstractQueuedSynchronizer &#123; private static final long serialVersionUID = -5179523762034025860L; /** * Performs &#123;@link Lock#lock&#125;. The main reason for subclassing * is to allow fast path for nonfair version. */ abstract void lock(); /** * Performs non-fair tryLock. tryAcquire is implemented in * subclasses, but both need nonfair try for trylock method. */ final boolean nonfairTryAcquire(int acquires) &#123; final Thread current = Thread.currentThread(); int c = getState(); if (c == 0) &#123; if (compareAndSetState(0, acquires)) &#123; setExclusiveOwnerThread(current); return true; &#125; &#125; else if (current == getExclusiveOwnerThread()) &#123; int nextc = c + acquires; if (nextc &lt; 0) // overflow throw new Error("Maximum lock count exceeded"); setState(nextc); return true; &#125; return false; &#125; protected final boolean tryRelease(int releases) &#123; int c = getState() - releases; if (Thread.currentThread() != getExclusiveOwnerThread()) throw new IllegalMonitorStateException(); boolean free = false; if (c == 0) &#123; free = true; setExclusiveOwnerThread(null); &#125; setState(c); return free; &#125; protected final boolean isHeldExclusively() &#123; // While we must in general read state before owner, // we don't need to do so to check if current thread is owner return getExclusiveOwnerThread() == Thread.currentThread(); &#125; final ConditionObject newCondition() &#123; return new ConditionObject(); &#125; // Methods relayed from outer class final Thread getOwner() &#123; return getState() == 0 ? null : getExclusiveOwnerThread(); &#125; final int getHoldCount() &#123; return isHeldExclusively() ? getState() : 0; &#125; final boolean isLocked() &#123; return getState() != 0; &#125; /** * Reconstitutes the instance from a stream (that is, deserializes it). */ private void readObject(java.io.ObjectInputStream s) throws java.io.IOException, ClassNotFoundException &#123; s.defaultReadObject(); setState(0); // reset to unlocked state &#125;&#125; nonfairTryAcquire, tryRelease方法都是获取 lock 的模版方法, 主逻辑在 AQS 里面, 以后会有专门的博客来分析。 ReentrantLock 获取lock方法 lock()1234567891011121314151617public void lock() &#123; sync.lock();&#125;//NonfairSync lockfinal void lock() &#123; // 先cas改变一下 state 成功就表示获取 if (compareAndSetState(0, 1)) setExclusiveOwnerThread(Thread.currentThread());// 获取成功设置 exclusiveOwnerThread else acquire(1);// 获取不成功, 调用 AQS 的 acquire 进行获取&#125;//FairSync lock 调用aqs的acquirefinal void lock() &#123; acquire(1);&#125; 从上诉代码中我们可以看到最终都调用了AQS的 acquire 方法 ReentrantLock 响应中断的获取 lock此方法与不响应的唯一区别时, 遇到线程中断直接抛出异常, 获取失败也是调用了aqs的方法进行中断 1234567/** * 带中断的获取锁(被其他线程中断后就直接返回) * @throws InterruptedException */public void lockInterruptibly() throws InterruptedException &#123; sync.acquireInterruptibly(1);&#125; ReentrantLock 响应中断及超时的获取 lock 1234567/** * 带中断 及 timeout 的获取锁 (线程被中断或获取超时就直接 return ) * @return */public boolean tryLock() &#123; return sync.nonfairTryAcquire(1);&#125; ReentrantLock 释放 lock 123456/** * 释放锁 */public void unlock() &#123; sync.release(1);&#125; Condition相关，目前这边只写和reentrantlock相关部分 12345678910111213141516171819202122232425262728293031323334353637383940/** * 是否有线程在 Condition Queue 里面等待获取锁 */public boolean hasWaiters(Condition condition)&#123; if(condition == null)&#123; throw new NullPointerException(); &#125; if(!(condition instanceof KAbstractQueuedSynchronizer.ConditionObject))&#123; throw new IllegalArgumentException(" not owber "); &#125; return sync.hasWaiters((KAbstractQueuedSynchronizer.ConditionObject)condition);&#125;/** * Condition Queue 里面等待获取锁的长度 */public int getWaitQueueLength(Condition condition)&#123; if(condition == null)&#123; throw new NullPointerException(); &#125; if(!(condition instanceof KAbstractQueuedSynchronizer.ConditionObject))&#123; throw new IllegalArgumentException("not owner"); &#125; return sync.getWaitQueueLength((KAbstractQueuedSynchronizer.ConditionObject)condition);&#125;/** * Condition Queue 里面等待获取锁的线程 */protected Collection&lt;Thread&gt; getWaitingThreads(Condition condition)&#123; if(condition == null)&#123; throw new NullPointerException(); &#125; if(!(condition instanceof KAbstractQueuedSynchronizer.ConditionObject))&#123; throw new IllegalArgumentException("not owner"); &#125; return sync.getWaitingThreads((KAbstractQueuedSynchronizer.ConditionObject)condition);&#125; 总结由于ReentrantLock还涉的知识点还挺多的，考虑到篇幅问题，我们将会在接下来几篇解析Condition和AQS源码。]]></content>
      <categories>
        <category>juc</category>
      </categories>
      <tags>
        <tag>reentrantlock</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Synchronized做了哪些底层优化？和ReenTrantLock的区别？]]></title>
    <url>%2F2018%2F11%2F06%2FSynchronized%E5%81%9A%E4%BA%86%E5%93%AA%E4%BA%9B%E5%BA%95%E5%B1%82%E4%BC%98%E5%8C%96%EF%BC%9F%E5%92%8CReenTrantLock%E7%9A%84%E5%8C%BA%E5%88%AB%EF%BC%9F%2F</url>
    <content type="text"><![CDATA[synchronized关键字最主要的三种使用方式的总结 修饰实例方法，作用于当前对象实例加锁，进入同步代码前要获得当前对象实例的锁 修饰静态方法，作用于当前类对象加锁，进入同步代码前要获得当前类对象的锁 。也就是给当前类加锁，会作用于类的所有对象实例，因为静态成员不属于任何一个实例对象，是类成员（ static 表明这是该类的一个静态资源，不管new了多少个对象，只有一份，所以对该类的所有对象都加了锁）。所以如果一个线程A调用一个实例对象的非静态 synchronized 方法，而线程B需要调用这个实例对象所属类的静态 synchronized 方法，是允许的，不会发生互斥现象，因为访问静态 synchronized 方法占用的锁是当前类的锁，而访问非静态 synchronized 方法占用的锁是当前实例对象锁。 修饰代码块，指定加锁对象，对给定对象加锁，进入同步代码库前要获得给定对象的锁。 和 synchronized 方法一样，synchronized(this)代码块也是锁定当前对象的。synchronized 关键字加到 static 静态方法和 synchronized(class)代码块上都是是给 Class 类上锁。这里再提一下：synchronized关键字加到非 static 静态方法上是给对象实例上锁。另外需要注意的是：尽量不要使用 synchronized(String a) 因为JVM中，字符串常量池具有缓冲功能！ 下面我已一个常见的面试题为例讲解一下 synchronized 关键字的具体使用。 面试中面试官经常会说：“单例模式了解吗？来给我手写一下！给我解释一下双重检验锁方式实现单利模式的原理呗！” 双重校验锁实现对象单例（线程安全） 1234567891011121314151617181920public class Singleton &#123; private volatile static Singleton uniqueInstance; private Singleton() &#123; &#125; public static Singleton getUniqueInstance() &#123; //先判断对象是否已经实例过，没有实例化过才进入加锁代码 if (uniqueInstance == null) &#123; //类对象加锁 synchronized (Singleton.class) &#123; if (uniqueInstance == null) &#123; uniqueInstance = new Singleton(); &#125; &#125; &#125; return uniqueInstance; &#125;&#125; 另外，需要注意 uniqueInstance 采用 volatile 关键字修饰也是很有必要。 uniqueInstance 采用 volatile 关键字修饰也是很有必要的， uniqueInstance = new Singleton(); 这段代码其实是分为三步执行： 为 uniqueInstance 分配内存空间 初始化 uniqueInstance 将 uniqueInstance 指向分配的内存地址 但是由于 JVM 具有指令重排的特性，执行顺序有可能变成 1-&gt;3-&gt;2。指令重排在单线程环境下不会出先问题，但是在多线程环境下会导致一个线程获得还没有初始化的实例。例如，线程 T1 执行了 1 和 3，此时 T2 调用 getUniqueInstance() 后发现 uniqueInstance 不为空，因此返回 uniqueInstance，但此时 uniqueInstance 还未被初始化。 使用 volatile 可以禁止 JVM 的指令重排，保证在多线程环境下也能正常运行。 synchronized 关键字底层原理总结 synchronized 同步语句块的情况12345public void test1()&#123; synchronized (this)&#123; LOGGER.info("synchronized this 代码块"); &#125;&#125; 字节码信息（命令：javap -c -s -v -l SynchronizedDemo.class）123456789101112131415161718192021public void test1(); descriptor: ()V flags: ACC_PUBLIC Code: stack=2, locals=3, args_size=1 0: aload_0 1: dup 2: astore_1 3: monitorenter 4: getstatic #2 // Field LOGGER:Lorg/slf4j/Logger; 7: ldc #3 // String synchronized this 代码块 9: invokeinterface #4, 2 // InterfaceMethod org/slf4j/Logger.info:(Ljava/lang/String;)V 14: aload_1 15: monitorexit 16: goto 24 19: astore_2 20: aload_1 21: monitorexit 22: aload_2 23: athrow 24: return 从上面我们可以看出： synchronized 同步语句块的实现使用的是 monitorenter 和 monitorexit 指令，其中 monitorenter 指令指向同步代码块的开始位置，monitorexit 指令则指明同步代码块的结束位置。 当执行 monitorenter 指令时，线程试图获取锁也就是获取 monitor(monitor对象存在于每个Java对象的对象头中，synchronized 锁便是通过这种方式获取锁的，也是为什么Java中任意对象可以作为锁的原因) 的持有权.当计数器为0则可以成功获取，获取后将锁计数器设为1也就是加1。相应的在执行 monitorexit 指令后，将锁计数器设为0，表明锁被释放。如果获取对象锁失败，那当前线程就要阻塞等待，直到锁被另外一个线程释放为止。 synchronized 修饰方法的的情况123public synchronized void test2()&#123; LOGGER.info("synchronized this 代码块2"); &#125; 字节码信息如下：123456789101112131415public synchronized void test2(); descriptor: ()V flags: ACC_PUBLIC, ACC_SYNCHRONIZED Code: stack=2, locals=1, args_size=1 0: getstatic #2 // Field LOGGER:Lorg/slf4j/Logger; 3: ldc #5 // String synchronized this 代码块2 5: invokeinterface #4, 2 // InterfaceMethod org/slf4j/Logger.info:(Ljava/lang/String;)V 10: return LineNumberTable: line 22: 0 line 23: 10 LocalVariableTable: Start Length Slot Name Signature 0 11 0 this Lcom/fly/learn/sync/SynchronizedDemo; synchronized 修饰的方法并没有 monitorenter 指令和 monitorexit 指令，取得代之的确实是 ACC_SYNCHRONIZED 标识，该标识指明了该方法是一个同步方法，JVM 通过该 ACC_SYNCHRONIZED 访问标志来辨别一个方法是否声明为同步方法，从而执行相应的同步调用。 synchronized 类锁情况12345public void test3()&#123; synchronized (SynchronizedDemo.class)&#123; LOGGER.info("synchronized this 代码块2"); &#125;&#125; 字节码信息如下：12345678910111213141516171819202122232425public void test3(); descriptor: ()V flags: ACC_PUBLIC Code: stack=2, locals=3, args_size=1 0: ldc #6 // class com/fly/learn/sync/SynchronizedDemo 2: dup 3: astore_1 4: monitorenter 5: getstatic #2 // Field LOGGER:Lorg/slf4j/Logger; 8: ldc #5 // String synchronized this 代码块2 10: invokeinterface #4, 2 // InterfaceMethod org/slf4j/Logger.info:(Ljava/lang/String;)V 15: aload_1 16: monitorexit 17: goto 25 20: astore_2 21: aload_1 22: monitorexit 23: aload_2 24: athrow 25: return Exception table: from to target type 5 17 20 any 20 23 20 any 这个和test1类似，无非是这个monitorenter指向类信息。 在 Java 早期版本中，synchronized 属于重量级锁，效率低下，因为监视器锁（monitor）是依赖于底层的操作系统的 Mutex Lock 来实现的，Java 的线程是映射到操作系统的原生线程之上的。如果要挂起或者唤醒一个线程，都需要操作系统帮忙完成，而操作系统实现线程之间的切换时需要从用户态转换到内核态，这个状态之间的转换需要相对比较长的时间，时间成本相对较高，这也是为什么早期的 synchronized 效率低的原因。庆幸的是在 Java 6 之后 Java 官方对从 JVM 层面对synchronized 较大优化，所以现在的 synchronized 锁效率也优化得很不错了。JDK1.6对锁的实现引入了大量的优化，如自旋锁、适应性自旋锁、锁消除、锁粗化、偏向锁、轻量级锁等技术来减少锁操作的开销。 JDK1.6 之后的底层优化JDK1.6 对锁的实现引入了大量的优化，如偏向锁、轻量级锁、自旋锁、适应性自旋锁、锁消除、锁粗化等技术来减少锁操作的开销。 锁主要存在四中状态，依次是：无锁状态、偏向锁状态、轻量级锁状态、重量级锁状态，他们会随着竞争的激烈而逐渐升级。注意锁可以升级不可降级，这种策略是为了提高获得锁和释放锁的效率。 偏向锁 引入偏向锁的目的和引入轻量级锁的目的很像，他们都是为了没有多线程竞争的前提下，减少传统的重量级锁使用操作系统互斥量产生的性能消耗。但是不同是：轻量级锁在无竞争的情况下使用 CAS 操作去代替使用互斥量。而偏向锁在无竞争的情况下会把整个同步都消除掉。 会在对象头和栈帧中的锁记录里存储锁偏向的线程ID，以后该线程在进入和退出同步块时不需要进行CAS操作来加锁和解锁，只需简单地测试一下对象头的Mark Word里是否存储着指向当前线程的偏向锁。如果测试成功，表示线程已经获得了锁。如果测试失败，则需要再测试一下Mark Word中偏向锁的标识是否设置成1（表示当前是偏向锁）：如果没有设置，则使用CAS竞争锁；如果设置了，则尝试使用CAS将对象头的偏向锁指向当前线程。 轻量级锁 倘若偏向锁失败，虚拟机并不会立即升级为重量级锁，它还会尝试使用一种称为轻量级锁的优化手段(1.6之后加入的)。轻量级锁不是为了代替重量级锁，它的本意是在没有多线程竞争的前提下，减少传统的重量级锁使用操作系统互斥量产生的性能消耗，因为使用轻量级锁时，不需要申请互斥量。另外，轻量级锁的加锁和解锁都用到了CAS操作。 轻量级锁能够提升程序同步性能的依据是“对于绝大部分锁，在整个同步周期内都是不存在竞争的”，这是一个经验数据。如果没有竞争，轻量级锁使用 CAS 操作避免了使用互斥操作的开销。但如果存在锁竞争，除了互斥量开销外，还会额外发生CAS操作，因此在有锁竞争的情况下，轻量级锁比传统的重量级锁更慢！如果锁竞争激烈，那么轻量级将很快膨胀为重量级锁！ 自旋锁和自适应自旋 轻量级锁失败后，虚拟机为了避免线程真实地在操作系统层面挂起，还会进行一项称为自旋锁的优化手段。 互斥同步对性能最大的影响就是阻塞的实现，因为挂起线程/恢复线程的操作都需要转入内核态中完成（用户态转换到内核态会耗费时间）。 自旋锁在 JDK1.6 之前其实就已经引入了，不过是默认关闭的，需要通过--XX:+UseSpinning参数来开启。JDK1.6及1.6之后，就改为默认开启的了。需要注意的是：自旋等待不能完全替代阻塞，因为它还是要占用处理器时间。如果锁被占用的时间短，那么效果当然就很好了！反之，相反！自旋等待的时间必须要有限度。如果自旋超过了限定次数任然没有获得锁，就应该挂起线程。自旋次数的默认值是10次，用户可以修改--XX:PreBlockSpin来更改。 另外,在 JDK1.6 中引入了自适应的自旋锁。自适应的自旋锁带来的改进就是：自旋的时间不在固定了，而是和前一次同一个锁上的自旋时间以及锁的拥有者的状态来决定，虚拟机变得越来越“聪明”了。 锁消除 锁消除理解起来很简单，它指的就是虚拟机即使编译器在运行时，如果检测到那些共享数据不可能存在竞争，那么就执行锁消除。锁消除可以节省毫无意义的请求锁的时间。 锁粗化 原则上，我们再编写代码的时候，总是推荐将同步快的作用范围限制得尽量小——只在共享数据的实际作用域才进行同步，这样是为了使得需要同步的操作数量尽可能变小，如果存在锁竞争，那等待线程也能尽快拿到锁。 大部分情况下，上面的原则都是没有问题的，但是如果一系列的连续操作都对同一个对象反复加锁和解锁，那么会带来很多不必要的性能消耗。 Synchronized 和 ReenTrantLock 的对比 两者都是可重入锁“可重入锁”概念是：自己可以再次获取自己的内部锁。比如一个线程获得了某个对象的锁，此时这个对象锁还没有释放，当其再次想要获取这个对象的锁的时候还是可以获取的，如果不可锁重入的话，就会造成死锁。同一个线程每次获取锁，锁的计数器都自增1，所以要等到锁的计数器下降为0时才能释放锁。 synchronized 依赖于 JVM 而 ReenTrantLock 依赖于 APIsynchronized 是依赖于 JVM 实现的，前面我们也讲到了 虚拟机团队在 JDK1.6 为 synchronized 关键字进行了很多优化，但是这些优化都是在虚拟机层面实现的，并没有直接暴露给我们。ReenTrantLock 是 JDK 层面实现的（也就是 API 层面，需要 lock() 和 unlock 方法配合 try/finally 语句块来完成），所以我们可以通过查看它的源代码，来看它是如何实现的。 ReenTrantLock 比 synchronized 增加了一些高级功能主要来说主要有三点：1.等待可中断；2.可实现公平锁；3.可实现选择性通知（锁可以绑定多个条件）3.1 ReenTrantLock提供了一种能够中断等待锁的线程的机制，通过lock.lockInterruptibly()来实现这个机制。也就是说正在等待的线程可以选择放弃等待，改为处理其他事情。3.2 ReenTrantLock可以指定是公平锁还是非公平锁。而synchronized只能是非公平锁。所谓的公平锁就是先等待的线程先获得锁。 ReenTrantLock默认情况是非公平的，可以通过 ReenTrantLock类的ReentrantLock(boolean fair)构造方法来制定是否是公平的。3.3 synchronized关键字与wait()和notify/notifyAll()方法相结合可以实现等待/通知机制，ReentrantLock类当然也可以实现，但是需要借助于Condition接口与newCondition() 方法。Condition是JDK1.5之后才有的，它具有很好的灵活性，比如可以实现多路通知功能也就是在一个Lock对象中可以创建多个Condition实例（即对象监视器），线程对象可以注册在指定的Condition中，从而可以有选择性的进行线程通知，在调度线程上更加灵活。 在使用notify/notifyAll()方法进行通知时，被通知的线程是由 JVM 选择的，用ReentrantLock类结合Condition实例可以实现“选择性通知” ，这个功能非常重要，而且是Condition接口默认提供的。而synchronized关键字就相当于整个Lock对象中只有一个Condition实例，所有的线程都注册在它一个身上。如果执行notifyAll()方法的话就会通知所有处于等待状态的线程这样会造成很大的效率问题，而Condition实例的signalAll()方法 只会唤醒注册在该Condition实例中的所有等待线程。 性能已不是选择标准在JDK1.6之前，synchronized 的性能是比 ReenTrantLock 差很多。具体表示为：synchronized 关键字吞吐量岁线程数的增加，下降得非常严重。而ReenTrantLock 基本保持一个比较稳定的水平。我觉得这也侧面反映了， synchronized 关键字还有非常大的优化余地。后续的技术发展也证明了这一点，我们上面也讲了在 JDK1.6 之后 JVM 团队对 synchronized 关键字做了很多优化。JDK1.6 之后，synchronized 和 ReenTrantLock 的性能基本是持平了。所以网上那些说因为性能才选择 ReenTrantLock 的文章都是错的！JDK1.6之后，性能已经不是选择synchronized和ReenTrantLock的影响因素了！而且虚拟机在未来的性能改进中会更偏向于原生的synchronized，所以还是提倡在synchronized能满足你的需求的情况下，优先考虑使用synchronized关键字来进行同步！优化后的synchronized和ReenTrantLock一样，在很多地方都是用到了CAS操作。 什么时候选择用 ReentrantLock 代替 synchronized？既然如此，我们什么时候才应该使用 ReentrantLock 呢？答案非常简单 —— 在确实需要一些 synchronized 所没有的特性的时候，比如时间锁等候、可中断锁等候、无块结构锁、多个条件变量或者轮询锁。 ReentrantLock 还具有可伸缩性的好处，应当在高度争用的情况下使用它，但是请记住，大多数 synchronized块几乎从来没有出现过争用，所以可以把高度争用放在一边。我建议用 synchronized 开发，直到确实证明 synchronized 不合适，而不要仅仅是假设如果使用 ReentrantLock“性能会更好”。请记住，这些是供高级用户使用的高级工具。（而且，真正的高级用户喜欢选择能够找到的最简单工具，直到他们认为简单的工具不适用为止。）。一如既往，首先要把事情做好，然后再考虑是不是有必要做得更快。]]></content>
      <categories>
        <category>juc</category>
      </categories>
      <tags>
        <tag>synchronize</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[zookeeper权限相关]]></title>
    <url>%2F2018%2F08%2F26%2Fzookeeper%E6%9D%83%E9%99%90%E7%9B%B8%E5%85%B3%2F</url>
    <content type="text"><![CDATA[Zookeeper使用ACL来控制访问Znode，ACL的实现和UNIX的实现非常相似：它采用权限位来控制那些操作被允许，那些操作被禁止。但是和标准的UNIX权限不同的是，Znode没有限制用户（user，即文件的所有者），组（group）和其他（world）。Zookeepr是没有所有者的概念的。 每个ZNode的ACL是独立的，且子节点不会继承父节点的ACL。例如：Znode /app对于ip为172.16.16.1只有只读权限，而/app/status是world可读，那么任何人都可以获取/app/status;所以在Zookeeper中权限是没有继承和传递关系的，每个Znode的权限都是独立存在的。 Zookeeper支持可插拔的权限认证方案，分为三个维度：scheme，user，permission。通常表示为scheme:id，permissions，其中Scheme表示使用何种方式来进行访问控制，Id代表用户，Permission表示有什么权限。下面分别说说这三个维度： zookeeper支持权限如下（permissions）： CREATE：可以创建子节点 READ：可以获取该节点的数据，也可以读取该节点所有的子节点 WRITE：可以写数据到该节点 DELETE：可以删除子节点 ADMIN：可以在该节点中设置权限 内置的ACL Schemes： world： 只有一个id：anyone，world:anyone表示任何人都有访问权限，Zookeeper把任何人都有权限的节点都归属于world:anyone auth：不需要任何id， 只要是通过auth的user都有权限 digest： 使用用户名/密码的方式验证，采用username:BASE64(SHA1(password))的字符串作为ACL的ID ip： 使用客户端的IP地址作为ACL的ID，设置的时候可以设置一个ip段，比如ip:192.168.1.0/16, 表示匹配前16个bit的IP段 sasl：sasl的对应的id，是一个通过sasl authentication用户的id，zookeeper-3.4.4中的sasl authentication是通过kerberos来实现的，也就是说用户只有通过了kerberos认证，才能访问它有权限的node.]]></content>
      <categories>
        <category>zookeeper</category>
      </categories>
      <tags>
        <tag>zookeeper</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[git命令大全]]></title>
    <url>%2F2018%2F08%2F26%2Fgit%E5%91%BD%E4%BB%A4%E5%A4%A7%E5%85%A8%2F</url>
    <content type="text"><![CDATA[远程仓库相关命令检出仓库：$ git clone git://github.com/jquery/jquery.git 查看远程仓库：$ git remote -v 添加远程仓库：$ git remote add [name] [url] 删除远程仓库：$ git remote rm [name] 修改远程仓库：$ git remote set-url –push [name] [newUrl] 拉取远程仓库：$ git pull [remoteName] [localBranchName] 推送远程仓库：$ git push [remoteName] [localBranchName] *如果想把本地的某个分支test提交到远程仓库，并作为远程仓库的master分支，或者作为另外一个名叫test的分支，如下： $git push origin test:master // 提交本地test分支作为远程的master分支 $git push origin test:test // 提交本地test分支作为远程的test分支 分支(branch)操作相关命令查看本地分支：$ git branch 查看远程分支：$ git branch -r 创建本地分支：$ git branch [name] —-注意新分支创建后不会自动切换为当前分支 切换分支：$ git checkout [name] 创建新分支并立即切换到新分支：$ git checkout -b [name] 删除分支：$ git branch -d [name] —- -d选项只能删除已经参与了合并的分支，对于未有合并的分支是无法删除的。如果想强制删除一个分支，可以使用-D选项 合并分支：$ git merge [name] —-将名称为[name]的分支与当前分支合并 创建远程分支(本地分支push到远程)：$ git push origin [name] 删除远程分支：$ git push origin :heads/[name] 或 $ gitpush origin :[name] *创建空的分支：(执行命令之前记得先提交你当前分支的修改，否则会被强制删干净没得后悔) $git symbolic-ref HEAD refs/heads/[name] $rm .git/index $git clean -fdx 版本(tag)操作相关命令查看版本：$ git tag 创建版本：$ git tag [name] 删除版本：$ git tag -d [name] 查看远程版本：$ git tag -r 创建远程版本(本地版本push到远程)：$ git push origin [name] 删除远程版本：$ git push origin :refs/tags/[name] 合并远程仓库的tag到本地：$ git pull origin –tags 上传本地tag到远程仓库：$ git push origin –tags 创建带注释的tag：$ git tag -a [name] -m ‘yourMessage’ 忽略一些文件、文件夹不提交 在仓库根目录下创建名称为“.gitignore”的文件，写入不需要的文件夹名或文件，每个元素占一行即可，如targetbin*.db]]></content>
      <categories>
        <category>git</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[zookeeper常用命令]]></title>
    <url>%2F2018%2F08%2F25%2Fzookeeper%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[服务管理 启动ZK服务: zkServer.sh start 查看ZK状态: zkServer.sh status 停止ZK服务: zkServer.sh stop 重启ZK服务: zkServer.sh restart 常用命令 客户端登录sudo sh zkCli.sh -server zk1.host.dxy:2181 查看当前节点数据 ls / 查看当前节点数据并能看到更新次数等数据 ls2 / 创建一个新的节点并设置关联值 create /test “test” 获取节点内容 get /test 修改文件内容 set /test “test1” 删除文件 delete /test 删除节点及子节点 rmr /test 打印节点状态 stat /test 退出会话 quit ACL权限 为某个节点设置ACL权限 setAcl /test world:anyone:cdwra 查看节点的ACL权限 getAcl /test 添加认证信息，类似于登录，如果某个节点需要认证后才能查看，需要此命令 addauth digest admin:admin 四字命令ZooKeeper 支持某些特定的四字命令字母与其的交互，用来获取服务的当前状态及相关信息。在客户端可以通过 telnet 或 nc 向 ZooKeeper 提交相应的命令。命令行如下：1echo conf | nc zk1.host.dxy 2181 stat 查看节点是否是leader echo stat | nc 127.0.0.1 2181|grep Mode conf 输出相关服务配置的详细信息 cons 列出所有连接到服务器的客户端的完全的连接 / 会话的详细信息。包括“接受 / 发送”的包数量、会话 id 、操作延迟、最后的操作执行等等信息 dump 列出未经处理的会话和临时节点 envi 输出关于服务环境的详细信息（区别于 conf 命令） reqs 列出未经处理的请求 ruok 测试服务是否处于正确状态。如果确实如此，那么服务返回“ imok ”，否则不做任何相应 stat 输出关于性能和连接的客户端的列表 wchs 列出服务器 watch 的详细信息 wchc 通过 session 列出服务器 watch 的详细信息，它的输出是一个与 watch 相关的会话的列表 wchp 通过路径列出服务器 watch 的详细信息。它输出一个与 session 相关的路径]]></content>
      <categories>
        <category>zookeeper</category>
      </categories>
      <tags>
        <tag>zookeeper</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[spring-cloud服务网关中的Timeout设置]]></title>
    <url>%2F2018%2F08%2F24%2Fspring-cloud%E6%9C%8D%E5%8A%A1%E7%BD%91%E5%85%B3%E4%B8%AD%E7%9A%84Timeout%E8%AE%BE%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[大家在初次使用spring-cloud的gateway的时候，肯定会被里面各种的Timeout搞得晕头转向。hytrix有设置，ribbon也有。我们一开始也是乱设一桶，Github上各种项目里也没几个设置正确的。对Timeout的研究源于一次log中的warning o.s.c.n.z.f.r.s.AbstractRibbonCommand : The Hystrix timeout of 60000ms for the command pay is set lower than the combination of the Ribbon read and connect timeout, 111000ms. hytrix超时时间log出自AbstractRibbonCommand.java，那么索性研究一下源码123456789101112131415161718192021222324252627protected static int getHystrixTimeout(IClientConfig config, String commandKey) &#123; int ribbonTimeout = getRibbonTimeout(config, commandKey); DynamicPropertyFactory dynamicPropertyFactory = DynamicPropertyFactory.getInstance(); // 获取默认的hytrix超时时间 int defaultHystrixTimeout = dynamicPropertyFactory.getIntProperty("hystrix.command.default.execution.isolation.thread.timeoutInMilliseconds", 0).get(); // 获取具体服务的hytrix超时时间，这里应该是hystrix.command.foo.execution.isolation.thread.timeoutInMilliseconds int commandHystrixTimeout = dynamicPropertyFactory.getIntProperty("hystrix.command." + commandKey + ".execution.isolation.thread.timeoutInMilliseconds", 0).get(); int hystrixTimeout; // hystrixTimeout的优先级是 具体服务的hytrix超时时间 &gt; 默认的hytrix超时时间 &gt; ribbon超时时间 if(commandHystrixTimeout &gt; 0) &#123; hystrixTimeout = commandHystrixTimeout; &#125; else if(defaultHystrixTimeout &gt; 0) &#123; hystrixTimeout = defaultHystrixTimeout; &#125; else &#123; hystrixTimeout = ribbonTimeout; &#125; // 如果默认的或者具体服务的hytrix超时时间小于ribbon超时时间就会警告 if(hystrixTimeout &lt; ribbonTimeout) &#123; LOGGER.warn("The Hystrix timeout of " + hystrixTimeout + "ms for the command " + commandKey + " is set lower than the combination of the Ribbon read and connect timeout, " + ribbonTimeout + "ms."); &#125; return hystrixTimeout;&#125; 紧接着，看一下我们的配置是什么12345678910111213hystrix: command: default: execution: isolation: thread: timeoutInMilliseconds: 600000 ribbon: ReadTimeout: 50000 ConnectTimeout: 500 MaxAutoRetries: 0 MaxAutoRetriesNextServer: 1 ribbon超时时间这里ribbon的超时时间是111000ms，那么为什么log中写的ribbon时间是50000ms? 继续分析源码：123456789101112131415161718192021protected static int getRibbonTimeout(IClientConfig config, String commandKey) &#123; int ribbonTimeout; // 这是比较异常的情况，不说 if (config == null) &#123; ribbonTimeout = RibbonClientConfiguration.DEFAULT_READ_TIMEOUT + RibbonClientConfiguration.DEFAULT_CONNECT_TIMEOUT; &#125; else &#123; // 这里获取了四个参数，ReadTimeout，ConnectTimeout，MaxAutoRetries， MaxAutoRetriesNextServer int ribbonReadTimeout = getTimeout(config, commandKey, "ReadTimeout", IClientConfigKey.Keys.ReadTimeout, RibbonClientConfiguration.DEFAULT_READ_TIMEOUT); int ribbonConnectTimeout = getTimeout(config, commandKey, "ConnectTimeout", IClientConfigKey.Keys.ConnectTimeout, RibbonClientConfiguration.DEFAULT_CONNECT_TIMEOUT); int maxAutoRetries = getTimeout(config, commandKey, "MaxAutoRetries", IClientConfigKey.Keys.MaxAutoRetries, DefaultClientConfigImpl.DEFAULT_MAX_AUTO_RETRIES); int maxAutoRetriesNextServer = getTimeout(config, commandKey, "MaxAutoRetriesNextServer", IClientConfigKey.Keys.MaxAutoRetriesNextServer, DefaultClientConfigImpl.DEFAULT_MAX_AUTO_RETRIES_NEXT_SERVER); // 原来ribbonTimeout的计算方法在这里，以上文的设置为例 // ribbonTimeout = (50000 + 50000) * (0 + 1) * (1 + 1) = 200000 ribbonTimeout = (ribbonReadTimeout + ribbonConnectTimeout) * (maxAutoRetries + 1) * (maxAutoRetriesNextServer + 1); &#125; return ribbonTimeout;&#125; 可以看到ribbonTimeout是一个总时间，所以从逻辑上来讲，作者希望hystrixTimeout要大于ribbonTimeout，否则hystrix熔断了以后，ribbon的重试就都没有意义了。 ribbon单服务设置到这里最前面的疑问已经解开了，但是hytrix可以分服务设置timeout，ribbon可不可以? 源码走起，这里看的文件是DefaultClientConfigImpl.java1234567891011121314151617181920212223242526272829303132// 这是获取配置的入口方法，如果是null，那么用默认值// 所有ribbon的默认值的都在该类中设置了，可以自己看一下public &lt;T&gt; T get(IClientConfigKey&lt;T&gt; key, T defaultValue) &#123; T value = get(key); if (value == null) &#123; value = defaultValue; &#125; return value;&#125;// 这是核心方法 protected Object getProperty(String key) &#123; if (enableDynamicProperties) &#123; String dynamicValue = null; DynamicStringProperty dynamicProperty = dynamicProperties.get(key); // dynamicProperties其实是一个缓存，首次访问foo服务的时候会加载 if (dynamicProperty != null) &#123; dynamicValue = dynamicProperty.get(); &#125; // 如果缓存没有，那么就再获取一次，注意这里的getConfigKey(key)是生成key的方法 if (dynamicValue == null) &#123; dynamicValue = DynamicProperty.getInstance(getConfigKey(key)).getString(); // 如果还是没有取默认值，getDefaultPropName(key)生成key的方法 if (dynamicValue == null) &#123; dynamicValue = DynamicProperty.getInstance(getDefaultPropName(key)).getString(); &#125; &#125; if (dynamicValue != null) &#123; return dynamicValue; &#125; &#125; return properties.get(key);&#125; 小结感觉ribbon和hytrix的配置获取源码略微有点乱，所以也导致大家在设置的时候有些无所适从。spring-cloud的代码一直在迭代，无论github上还是文档可能都相对滞后，这时候阅读源码并且动手debug一下是最能接近事实真相的了。]]></content>
      <categories>
        <category>问题及解决</category>
      </categories>
      <tags>
        <tag>spring-cloud</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ideaVim使用记录]]></title>
    <url>%2F2018%2F05%2F02%2FideaVim%E4%BD%BF%E7%94%A8%E8%AE%B0%E5%BD%95%2F</url>
    <content type="text"><![CDATA[背景开发写代码一直想脱离鼠标操作，看起来高大上一点，最近开始idea用vim操作。以下是vim的简单快捷键。 keymap 记录 跳转到指定行：{行数}g 标签特切换：gt或者gT,前者顺序切换，后者逆向切换 单词移动：w/W，移动到下个单词开头；b/B,倒退到上个单词开头。大写的会忽略标点。命令前加数字表示执行次数，如2W 删除当前单词并进入插入模式：cw 撤销：u;恢复被撤销的操作：ctrl+r v进入选择字符，V进入行选择模式 用y命令将文本存入寄存器,普通模式下小写p把寄存器内容复制到当前位置之后,大写P把寄存器内容复制到当前位置之前 剪切操作，先v选择多行，然后d删除，最后到需要粘贴的地方p 跳转到特定行,按:n 如 :23 跳转到23行 x(小写) -&gt; 正向按字符单位进行删除 向右删除 X(大写) -&gt; 反向按字符单位进行删除 向左删除 $ -&gt; 当前行的最后一个字符 G -&gt; 跳转到最后一行 组合技巧 全选： ggvG 调换两个字符位置： xp 复制一行： yyp 调换两行位置： ddp 复制后，在命令模式下 np n代表数字你想要粘贴的数目,如 10p]]></content>
      <categories>
        <category>vim</category>
      </categories>
      <tags>
        <tag>vim</tag>
        <tag>idea</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mycat分片规则使用指南]]></title>
    <url>%2F2018%2F05%2F01%2FMycat%E5%88%86%E7%89%87%E8%A7%84%E5%88%99%E4%BD%BF%E7%94%A8%E6%8C%87%E5%8D%97%2F</url>
    <content type="text"><![CDATA[枚举法通过在配置文件中配置可能的枚举id，自己配置分片，本规则适用于特定的场景，比如有些业务需要按照省 份或区县来做保存，而全国省份区县固定的，这类业务使用本条规则，配置如下12345678910111213141516&lt;tableRule name=&quot;sharding-by-intfile&quot;&gt; &lt;rule&gt; &lt;!--标识将要分片的表字段--&gt; &lt;columns&gt;user_id&lt;/columns&gt; &lt;!--分片函数--&gt; &lt;algorithm&gt;hash-int&lt;/algorithm&gt; &lt;/rule&gt;&lt;/tableRule&gt;&lt;function name=&quot;hash-int&quot; class=&quot;com.dxy.mycat.route.function.PartitionByFileMap&quot;&gt; &lt;!--标识配置文件名称--&gt; &lt;property name=&quot;mapFile&quot;&gt;partition-hash-int.txt&lt;/property&gt; &lt;!--type默认值为0，0表示Integer，非零表示String--&gt; &lt;property name=&quot;type&quot;&gt;0&lt;/property&gt; &lt;!--所有的节点配置都是从0开始，及0代表节点1--&gt; &lt;property name=&quot;defaultNode&quot;&gt;0&lt;/property&gt;&lt;/function&gt; partition-hash-int.txt 配置：12310000=010010=1DEFAULT_NODE=1 配置说明: 上面 columns 标识将要分片的表字段，algorithm 分片函数，其中分片函数配置中，mapFile 标识配置文件名称，type为分片字段的类型，默认值为 0，0 表示 Integer，非零表示 String， 所有的节点配置都是从 0 开始，及 0 代表节点 1；defaultNode 默认节点:小于 0 表示不设置默认节点，大于等于 0 表示设置默认节点，默认节点的作用:枚举分片时，如果碰到不识别的枚举值，就让它路由到默认节点；如果不配置默认节点(defaultNode 值小于 0 表示不配置默认节点)，碰到不识别的枚举值就会报错 固定分片hash算法本条规则类似于十进制的求模运算，区别在于是二进制的操作,是取 id 的二进制低 10 位，即 id 二进制 &amp;1111111111。此算法的优点在于如果按照 10 进制取模运算，在连续插入 1-10 时候 1-10 会被分到 1-10 个分片，增 大了插入的事务控制难度，而此算法根据二进制则可能会分到连续的分片，减少插入事务事务控制难度。123456789101112131415&lt;tableRule name=&quot;rule1&quot;&gt; &lt;rule&gt; &lt;!--标识将要分片的表字段--&gt; &lt;columns&gt;user_id&lt;/columns&gt; &lt;!--分片函数--&gt; &lt;algorithm&gt;func1&lt;/algorithm&gt; &lt;/rule&gt;&lt;/tableRule&gt;&lt;function name=&quot;func1&quot; class=&quot;com.dxy.mycat.route.function.PartitionByLong&quot;&gt; &lt;!--分片个数列表--&gt; &lt;property name=&quot;partitionCount&quot;&gt;2,1&lt;/property&gt; &lt;!--分片范围列表--&gt; &lt;property name=&quot;partitionLength&quot;&gt;256,512&lt;/property&gt; &lt;!--分区长度:默认为最大2^n=1024 ,即最大支持1024分区--&gt;&lt;/function&gt; 配置说明: 上面 columns 标识将要分片的表字段，algorithm 分片函数，partitionCount 分片个数列表，partitionLength 分片范围列表 分区长度:默认为最大 2^n=1024 ,即最大支持 1024 分区, 约束:12count,length两个数组的长度必须是一致的。1024 = sum((count[i]*length[i])). count和length两个向量的点积恒等于1024 用法例子：12345678910111213141516本例的分区策略：希望将数据水平分成3份，前两份各占25%，第三份占50%。（故本例非均匀分区）// |&lt;---------------------1024------------------------&gt;|// |&lt;----256---&gt;|&lt;----256---&gt;|&lt;----------512----------&gt;|// | partition0 | partition1 | partition2 |// | 共2份,故count[0]=2 | 共1份，故count[1]=1 |int[] count = new int[] &#123; 2, 1 &#125;;int[] length = new int[] &#123; 256, 512 &#125;;PartitionUtil pu = new PartitionUtil(count, length);// 下面代码演示分别以offerId字段或memberId字段根据上述分区策略拆分的分配结果int DEFAULT_STR_HEAD_LEN = 8; // cobar默认会配置为此值long offerId = 12345;String memberId = &quot;qiushuo&quot;;// 若根据offerId分配，partNo1将等于0，即按照上述分区策略，offerId为12345时将会被分配到partition0中int partNo1 = pu.partition(offerId);// 若根据memberId分配，partNo2将等于2，即按照上述分区策略，memberId为qiushuo时将会被分到partition2中int partNo2 = pu.partition(memberId, 0, DEFAULT_STR_HEAD_LEN); 如果需要平均分配设置：平均分为4分片，partitionCount*partitionLength=10241234&lt;function name=&quot;func1&quot; class=&quot;com.dxy.mycat.route.function.PartitionByLong&quot;&gt; &lt;property name=&quot;partitionCount&quot;&gt;4&lt;/property&gt; &lt;property name=&quot;partitionLength&quot;&gt;256&lt;/property&gt;&lt;/function&gt; 范围约定此分片适用于，提前规划好分片字段某个范围属于哪个分片,start &lt;= range &lt;= end.K=1000,M=10000.123456789101112&lt;tableRule name=&quot;auto-sharding-long&quot;&gt; &lt;rule&gt; &lt;!--标识将要分片的表字段--&gt; &lt;columns&gt;user_id&lt;/columns&gt; &lt;!--分片函数--&gt; &lt;algorithm&gt;rang-long&lt;/algorithm&gt; &lt;/rule&gt;&lt;/tableRule&gt;&lt;function name=&quot;rang-long&quot; class=&quot;com.dxy.mycat.route.function.AutoPartitionByLong&quot;&gt; &lt;!--配置文件路径--&gt; &lt;property name=&quot;mapFile&quot;&gt;autopartition-long.txt&lt;/property&gt;&lt;/function&gt; 123456789# range start-end ,data node index# 所有的节点配置都是从0开始，及0代表节点1，此配置非常简单，即预先制定可能的id范围到某个分片# K=1000,M=10000.0-500M=0500M-1000M=11000M-1500M=2或0-10000000=010000001-20000000=1 配置说明: 上面 columns 标识将要分片的表字段，algorithm 分片函数，rang-long 函数中 mapFile 代表配置文件路径defaultNode 超过范围后的默认节点。 所有的节点配置都是从 0 开始，及 0 代表节点 1，此配置非常简单，即预先制定可能的 id 范围到某个分片0-500M=0 500M-1000M=11000M-1500M=2 或0-10000000=0 10000001-20000000=1 求模法此种配置非常明确即根据 id进行十进制求模预算，相比固定分片 hash，此种在批量插入时可能存在批量插入单 事务插入多数据分片，增大事务一致性难度。123456789101112&lt;tableRule name=&quot;mod-long&quot;&gt; &lt;rule&gt; &lt;!--标识将要分片的表字段--&gt; &lt;columns&gt;user_id&lt;/columns&gt; &lt;!--分片函数--&gt; &lt;algorithm&gt;mod-long&lt;/algorithm&gt; &lt;/rule&gt;&lt;/tableRule&gt;&lt;function name=&quot;mod-long&quot; class=&quot;com.dxy.mycat.route.function.PartitionByMod&quot;&gt; &lt;!--注意！这里填写数据库节点数，否则无法分片--&gt; &lt;property name=&quot;count&quot;&gt;3&lt;/property&gt;&lt;/function&gt; 日期列分区法12345678910111213&lt;tableRule name=&quot;sharding-by-date&quot;&gt; &lt;rule&gt; &lt;!--标识将要分片的表字段--&gt; &lt;columns&gt;create_time&lt;/columns&gt; &lt;!--分片函数--&gt; &lt;algorithm&gt;sharding-by-date&lt;/algorithm&gt; &lt;/rule&gt;&lt;/tableRule&gt; &lt;function name=&quot;sharding-by-date&quot; class=&quot;com.dxy.mycat.route.function.PartitionByDate&quot;&gt; &lt;property name=&quot;dateFormat&quot;&gt;yyyy-MM-dd&lt;/property&gt; &lt;property name=&quot;sBeginDate&quot;&gt;2015-01-01&lt;/property&gt; &lt;property name=&quot;sPartionDay&quot;&gt;10&lt;/property&gt;&lt;/function&gt; 配置中配置了开始日期，分区天数，即默认从开始日期算起，分隔10天一个分区1234Assert.assertEquals(true, 0 == partition.calculate(&quot;2015-01-01&quot;));Assert.assertEquals(true, 0 == partition.calculate(&quot;2015-01-10&quot;));Assert.assertEquals(true, 1 == partition.calculate(&quot;2015-01-11&quot;));Assert.assertEquals(true, 12 == partition.calculate(&quot;2015-05-01&quot;)); 配置说明: columns :标识将要分片的表字段;algorithm :分片函数;dateFormat :日期格式;sBeginDate :开始日期;sEndDate:结束日期;sPartionDay :分区天数，即默认从开始日期算起，分隔 10 天一个分区; 通配取模此种规则是取模运算与范围约束的结合，主要为了后续数据迁移做准备，即可以自主决定取模后数据的节点分布。1234567891011121314151617&lt;tableRule name=&quot;sharding-by-pattern&quot;&gt; &lt;rule&gt; &lt;!--标识将要分片的表字段--&gt; &lt;columns&gt;user_id&lt;/columns&gt; &lt;!--分片函数--&gt; &lt;algorithm&gt;sharding-by-pattern&lt;/algorithm&gt; &lt;/rule&gt;&lt;/tableRule&gt;&lt;function name=&quot;sharding-by-pattern&quot; class=&quot;com.dxy.mycat.route.function.PartitionByPattern&quot;&gt; &lt;!--求模基数--&gt; &lt;property name=&quot;patternValue&quot;&gt;256&lt;/property&gt; &lt;!--默认节点--&gt; &lt;!--如果配置了默认，则不会按照求模运算--&gt; &lt;property name=&quot;defaultNode&quot;&gt;2&lt;/property&gt; &lt;!-- 配置文件路径--&gt; &lt;property name=&quot;mapFile&quot;&gt;partition-pattern.txt&lt;/property&gt;&lt;/function&gt; partition-pattern.txt ：12345678910111213# id partition range start-end ,data node index###### first host configuration1-32=033-64=165-96=297-128=3######## second host configuration129-160=4161-192=5193-224=6225-256=70-0=7#1-32 即代表id%256后分布的范围，如果在1-32则在分区1，其他类推，如果id非数据，则会分配在defaoultNode 默认节点 ASCII码求模通配12345678910111213141516&lt;tableRule name=&quot;sharding-by-prefixpattern&quot;&gt; &lt;rule&gt; &lt;!--标识将要分片的表字段--&gt; &lt;columns&gt;user_id&lt;/columns&gt; &lt;!--分片函数--&gt; &lt;algorithm&gt;sharding-by-prefixpattern&lt;/algorithm&gt; &lt;/rule&gt;&lt;/tableRule&gt;&lt;function name=&quot;sharding-by-pattern&quot; class=&quot;com.dxy.mycat.route.function.PartitionByPattern&quot;&gt; &lt;!--求模基数--&gt; &lt;property name=&quot;patternValue&quot;&gt;256&lt;/property&gt; &lt;!--ASCII 截取的位数--&gt; &lt;property name=&quot;prefixLength&quot;&gt;5&lt;/property&gt; &lt;!-- 配置文件路径--&gt; &lt;property name=&quot;mapFile&quot;&gt;partition-pattern.txt&lt;/property&gt;&lt;/function&gt; partition-pattern.txt：1234567891011121314151617# range start-end ,data node index# ASCII# 48-57=0-9# 64、65-90=@、A-Z# 97-122=a-z###### first host configuration1-4=05-8=19-12=213-16=3###### second host configuration17-20=421-24=525-28=629-32=70-0=7#1-32 即代表id%256后分布的范围，如果在1-32则在分区1，其他类推 此种方式类似方式6只不过采取的是将列种获取前prefixLength位列所有ASCII码的和进行求模sum%patternValue ,获取的值，在通配范围内的即 分片数，1234ASCII编码：48-57=0-9阿拉伯数字64、65-90=@、A-Z97-122=a-z 配置说明: 上面 columns 标识将要分片的表字段，algorithm 分片函数，patternValue 即求模基数，prefixLength ASCII 截取的位数mapFile 配置文件路径配置文件中，1-32 即代表 id%256 后分布的范围，如果在 1-32 则在分区 1，其他类推 例子：123456String idVal=&quot;gf89f9a&quot;;Assert.assertEquals(true, 0==autoPartition.calculate(idVal));idVal=&quot;8df99a&quot;;Assert.assertEquals(true, 4==autoPartition.calculate(idVal));idVal=&quot;8dhdf99a&quot;;Assert.assertEquals(true, 3==autoPartition.calculate(idVal)); 编程指定1234567891011121314&lt;tableRule name=&quot;sharding-by-substring&quot;&gt; &lt;rule&gt; &lt;!--标识将要分片的表字段--&gt; &lt;columns&gt;user_id&lt;/columns&gt; &lt;!--分片函数--&gt; &lt;algorithm&gt;sharding-by-substring&lt;/algorithm&gt; &lt;/rule&gt; &lt;/tableRule&gt;&lt;function name=&quot;sharding-by-substring&quot; class=&quot;com.dxy.mycat.route.function.PartitionDirectBySubString&quot;&gt; &lt;property name=&quot;startIndex&quot;&gt;0&lt;/property&gt; &lt;!-- zero-based --&gt; &lt;property name=&quot;size&quot;&gt;2&lt;/property&gt; &lt;property name=&quot;partitionCount&quot;&gt;8&lt;/property&gt; &lt;property name=&quot;defaultPartition&quot;&gt;0&lt;/property&gt;&lt;/function&gt; 此方法为直接根据字符子串（必须是数字）计算分区号（由应用传递参数，显式指定分区号）。例如id=05-100000002在此配置中代表根据id中从startIndex=0，开始，截取siz=2位数字即05，05就是获取的分区，如果没传默认分配到defaultPartition 字符串拆分hash解析不推荐使用12345678910111213141516&lt;tableRule name=&quot;sharding-by-stringhash&quot;&gt; &lt;rule&gt; &lt;!--标识将要分片的表字段--&gt; &lt;columns&gt;user_id&lt;/columns&gt; &lt;!--分片函数--&gt; &lt;algorithm&gt;sharding-by-stringhash&lt;/algorithm&gt; &lt;/rule&gt;&lt;/tableRule&gt;&lt;function name=&quot;sharding-by-substring&quot; class=&quot;com.dxy.mycat.route.function.PartitionDirectBySubString&quot;&gt; &lt;!--字符串hash求模基数--&gt; &lt;property name=length&gt;512&lt;/property&gt; &lt;!-- zero-based --&gt; &lt;!--分区数--&gt; &lt;property name=&quot;count&quot;&gt;2&lt;/property&gt; &lt;!--预算位--&gt; &lt;property name=&quot;hashSlice&quot;&gt;0:2&lt;/property&gt;&lt;/function&gt; 配置说明： 上面 columns 标识将要分片的表字段，algorithm 分片函数 函数中 partitionLength 代表字符串 hash 求模基数，partitionCount 分区数，hashSlice hash 预算位，即根据子字符串中 int 值 hash 运算123456&gt; &quot;2&quot; -&amp;gt; (0,2)&lt;br/&gt;&gt; &quot;1:2&quot; -&amp;gt; (1,2)&lt;br/&gt;&gt; &quot;1:&quot; -&amp;gt; (1,0)&lt;br/&gt;&gt; &quot;-1:&quot; -&amp;gt; (-1,0)&lt;br/&gt;&gt; &quot;:-1&quot; -&amp;gt; (0,-1)&lt;br/&gt;&gt; &quot;:&quot; -&amp;gt; (0,0)&lt;br/&gt; 例子12345678910111213141516171819202122String idVal=null; rule.setPartitionLength(&quot;512&quot;); rule.setPartitionCount(&quot;2&quot;); rule.init(); rule.setHashSlice(&quot;0:2&quot;);// idVal = &quot;0&quot;;// Assert.assertEquals(true, 0 == rule.calculate(idVal));// idVal = &quot;45a&quot;;// Assert.assertEquals(true, 1 == rule.calculate(idVal)); //last 4rule = new PartitionByString();rule.setPartitionLength(&quot;512&quot;);rule.setPartitionCount(&quot;2&quot;);rule.init();//last 4 charactersrule.setHashSlice(&quot;-4:0&quot;);idVal = &quot;aaaabbb0000&quot;;Assert.assertEquals(true, 0 == rule.calculate(idVal));idVal = &quot;aaaabbb2359&quot;;Assert.assertEquals(true, 0 == rule.calculate(idVal)); 一致性hash1234567891011121314151617&lt;tableRule name=&quot;sharding-by-murmur&quot;&gt; &lt;rule&gt; &lt;columns&gt;user_id&lt;/columns&gt; &lt;algorithm&gt;murmur&lt;/algorithm&gt; &lt;/rule&gt;&lt;/tableRule&gt;&lt;function name=&quot;murmur&quot; class=&quot;com.dxy.mycat.route.function.PartitionByMurmurHash&quot;&gt; &lt;property name=&quot;seed&quot;&gt;0&lt;/property&gt;&lt;!-- 默认是0--&gt; &lt;property name=&quot;count&quot;&gt;2&lt;/property&gt;&lt;!-- 要分片的数据库节点数量，必须指定，否则没法分片--&gt; &lt;property name=&quot;virtualBucketTimes&quot;&gt;160&lt;/property&gt;&lt;!-- 一个实际的数据库节点被映射为这么多虚拟节点，默认是160倍，也就是虚拟节点数是物理节点数的160倍--&gt; &lt;!-- &lt;property name=&quot;weightMapFile&quot;&gt;weightMapFile&lt;/property&gt; 节点的权重，没有指定权重的节点默认是1。以properties文件的格式填写，以从0开始到count-1的整数值也就是节点索引为key，以节点权重值为值。所有权重值必须是正整数，否则以1代替 --&gt; &lt;!-- &lt;property name=&quot;bucketMapPath&quot;&gt;/etc/mycat/bucketMapPath&lt;/property&gt; 用于测试时观察各物理节点与虚拟节点的分布情况，如果指定了这个属性，会把虚拟节点的murmur hash值与物理节点的映射按行输出到这个文件，没有默认值，如果不指定，就不会输出任何东西 --&gt;&lt;/function&gt; 一致性hash预算有效解决了分布式数据的扩容问题，前1-9中id规则都多少存在数据扩容难题，而10规则解决了数据扩容难点]]></content>
      <categories>
        <category>mycat</category>
      </categories>
      <tags>
        <tag>mycat</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mycat部署文档之Haproxy]]></title>
    <url>%2F2018%2F05%2F01%2FMycat%E9%83%A8%E7%BD%B2%E6%96%87%E6%A1%A3%E4%B9%8BHaproxy%2F</url>
    <content type="text"><![CDATA[Haproxy HAProxy是一个使用C语言编写的自由及开放源代码软件，其提供高可用性、负载均衡，以及基于TCP和HTTP的应用程序代理。 HAProxy特别适用于那些负载特大的web站点，这些站点通常又需要会话保持或七层处理。HAProxy运行在当前的硬件上，完全可以支持数以万计的并发连接。并且它的运行模式使得它可以很简单安全的整合进您当前的架构中， 同时可以保护你的web服务器不被暴露到网络上。 安装依赖包依赖gcc和make安装包 sudo apt-get build-dep gcc 安装完了可以执行如下的命令来查看版本， gcc –version 安装make安装包 sudo apt install ubuntu-make 下载123[root@haproxy-server-master ~]# cd /home/dxy/temp/[root@haproxy-server-master src]# wget http://pkgs.fedoraproject.org/repo/pkgs/haproxy/haproxy-1.7.9.tar.gz/sha512/d1ed791bc9607dbeabcfc6a1853cf258e28b3a079923b63d3bf97504dd59e64a5f5f44f9da968c23c12b4279e8d45ff3bd39418942ca6f00d9d548c9a0ccfd73/haproxy-1.7.9.tar.gz[root@haproxy-server-master src]# tar -xvf haproxy-1.7.9.tar.gz 安装12345[root@haproxy-server-master src]# cd haproxy-1.7.9[root@haproxy-server-master haproxy-1.7.9]# uname -r3.10.0-514.el7.x86_64[root@haproxy-server-master haproxy-1.7.9]# make TARGET=linux2628 ARCH=x86_64 PREFIX=/home/dxy/haproxy[root@haproxy-server-master haproxy-1.7.9]# make install PREFIX=/home/dxy/haproxy 参数说明： TARGET=linux310，内核版本，使用uname -r查看内核，如：3.10.0-514.el7，此时该参数就为linux310；kernel 大于2.6.28的可以用：TARGET=linux2628； ARCH=x86_64，系统位数； PREFIX=/home/dxy/haproxy #/home/dxy/haproxy，为haprpxy安装路径。 配置文件1.79及以后的版本解压后文件内就没有haproxy.cfg文件，所以需要我们自己找个模板写一下。 由于没有配置其他的服务器，这里就简单的添加一个可以让Haproxy启动的配置。 haproxy 配置中分成五部分内容，分别如下： global：参数是进程级的，通常是和操作系统相关。这些参数一般只设置一次，如果配置无误，就不需要再次进行修改； defaults：配置默认参数，这些参数可以被用到frontend，backend，Listen组件； frontend：接收请求的前端虚拟节点，Frontend可以更加规则直接指定具体使用后端的backend； backend：后端服务集群的配置，是真实服务器，一个Backend对应一个或者多个实体服务器； Listen Fronted和backend的组合体。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394[root@haproxy-server-master haproxy]# mkdir conf[root@haproxy-server-master haproxy]# lsconf doc sbin share[root@haproxy-server-master haproxy]# cd conf/[root@haproxy-server-master conf]# vim haproxy.cfgglobal # 全局参数的设置 log 127.0.0.1 local0 info # log语法：log &lt;address_1&gt;[max_level_1] # 全局的日志配置，使用log关键字，指定使用127.0.0.1上的syslog服务中的local0日志设备，记录日志等级为info的日志 user haproxy group haproxy # 设置运行haproxy的用户和组，也可使用uid，gid关键字替代之 daemon # 以守护进程的方式运行 nbproc 16 # 设置haproxy启动时的进程数，根据官方文档的解释，我将其理解为：该值的设置应该和服务器的CPU核心数一致，即常见的2颗8核心CPU的服务器，即共有16核心，则可以将其值设置为：&lt;=16 ，创建多个进程数，可以减少每个进程的任务队列，但是过多的进程数也可能会导致进程的崩溃。这里我设置为16 maxconn 4096 # 定义每个haproxy进程的最大连接数 ，由于每个连接包括一个客户端和一个服务器端，所以单个进程的TCP会话最大数目将是该值的两倍。 #ulimit -n 65536 # 设置最大打开的文件描述符数，在1.4的官方文档中提示，该值会自动计算，所以不建议进行设置 pidfile /var/run/haproxy.pid # 定义haproxy的pid defaults # 默认部分的定义 mode http # mode语法：mode &#123;http|tcp|health&#125; 。http是七层模式，tcp是四层模式，health是健康检测，返回OK log 127.0.0.1 local3 err # 使用127.0.0.1上的syslog服务的local3设备记录错误信息 retries 3 # 定义连接后端服务器的失败重连次数，连接失败次数超过此值后将会将对应后端服务器标记为不可用 option httplog # 启用日志记录HTTP请求，默认haproxy日志记录是不记录HTTP请求的，只记录“时间[Jan 5 13:23:46] 日志服务器[127.0.0.1] 实例名已经pid[haproxy[25218]] 信息[Proxy http_80_in stopped.]”，日志格式很简单。 option redispatch # 当使用了cookie时，haproxy将会将其请求的后端服务器的serverID插入到cookie中，以保证会话的SESSION持久性；而此时，如果后端的服务器宕掉了，但是客户端的cookie是不会刷新的，如果设置此参数，将会将客户的请求强制定向到另外一个后端server上，以保证服务的正常。 option abortonclose # 当服务器负载很高的时候，自动结束掉当前队列处理比较久的链接 option dontlognull # 启用该项，日志中将不会记录空连接。所谓空连接就是在上游的负载均衡器或者监控系统为了探测该服务是否存活可用时，需要定期的连接或者获取某一固定的组件或页面，或者探测扫描端口是否在监听或开放等动作被称为空连接；官方文档中标注，如果该服务上游没有其他的负载均衡器的话，建议不要使用该参数，因为互联网上的恶意扫描或其他动作就不会被记录下来 option httpclose # 这个参数我是这样理解的：使用该参数，每处理完一个request时，haproxy都会去检查http头中的Connection的值，如果该值不是close，haproxy将会将其删除，如果该值为空将会添加为：Connection: close。使每个客户端和服务器端在完成一次传输后都会主动关闭TCP连接。与该参数类似的另外一个参数是“option forceclose”，该参数的作用是强制关闭对外的服务通道，因为有的服务器端收到Connection: close时，也不会自动关闭TCP连接，如果客户端也不关闭，连接就会一直处于打开，直到超时。 contimeout 5000 # 设置成功连接到一台服务器的最长等待时间，默认单位是毫秒，新版本的haproxy使用timeout connect替代，该参数向后兼容 clitimeout 3000 # 设置连接客户端发送数据时的成功连接最长等待时间，默认单位是毫秒，新版本haproxy使用timeout client替代。该参数向后兼容 srvtimeout 3000 # 设置服务器端回应客户度数据发送的最长等待时间，默认单位是毫秒，新版本haproxy使用timeout server替代。该参数向后兼容listen status # 定义一个名为status的部分 bind 0.0.0.0:1080 # 定义监听的套接字 mode http # 定义为HTTP模式 log global # 继承global中log的定义 stats refresh 30s # stats是haproxy的一个统计页面的套接字，该参数设置统计页面的刷新间隔为30s stats uri /admin?stats # 设置统计页面的uri为/admin?stats stats realm Private lands # 设置统计页面认证时的提示内容 stats auth admin:password # 设置统计页面认证的用户和密码，如果要设置多个，另起一行写入即可 stats hide-version # 隐藏统计页面上的haproxy版本信息## listen: 用于定义通过关联“前端”和“后端”一个完整的代理，通常只对TCP流量有用listen mycat_servers bind :3306 ## 绑定端口 mode tcp option tcplog ## 记录TCP请求日志 option tcpka ##是否允许向server和client发送keepalive option httpchk OPTIONS * HTTP/1.1\r\nHost:\ www ## 后端服务状态检测 ### 向后端服务器的48700端口（端口值在后端服务器上通过xinetd配置）发送 OPTIONS 请求 ### (原理请参考HTTP协议) ，HAProxy会根据返回内容来判断后端服务是否可用. ### 2xx 和 3xx 的响应码表示健康状态，其他响应码或无响应表示服务器故障。 balance roundrobin ## 定义负载均衡算法，可用于&quot;defaults&quot;、&quot;listen&quot;和&quot;backend&quot;中,默认为轮询方式 server mycat_01 192.168.1.203:8066 check port 48700 inter 2000ms rise 2 fall 3 weight 10 server mycat_02 192.168.1.204:8066 check port 48700 inter 2000ms rise 2 fall 3 weight 10 ## 格式：server ### serser 在后端声明一个server，只能用于listen和backend区段 ###为此服务器指定的内部名称，其将会出现在日志及警告信息中 ###此服务器的IPv4地址，也支持使用可解析的主机名，但要在启动时需要解析主机名至响应的IPV4地址 ### [:[port]]指定将客户端连接请求发往此服务器时的目标端口，此为可选项 ### [param*]为此server设定的一系列参数，均为可选项，参数比较多，下面仅说明几个常用的参数： #### weight:权重，默认为1，最大值为256，0表示不参与负载均衡 #### backup:设定为备用服务器，仅在负载均衡场景中的其他server均不可以启用此server #### check:启动对此server执行监控状态检查，其可以借助于额外的其他参数完成更精细的设定 #### inter:设定监控状态检查的时间间隔，单位为毫秒，默认为2000， ##### 也可以使用fastinter和downinter来根据服务器端专题优化此事件延迟 #### rise:设置server从离线状态转换至正常状态需要检查的次数（不设置的情况下，默认值为2） #### fall:设置server从正常状态转换至离线状态需要检查的次数（不设置的情况下，默认值为3） #### cookie:为指定server设定cookie值，此处指定的值将会在请求入站时被检查， ##### 第一次为此值挑选的server将会被后续的请求所选中，其目的在于实现持久连接的功能 #### maxconn:指定此服务器接受的最大并发连接数，如果发往此服务器的连接数目高于此处指定的值， #####其将被放置于请求队列，以等待其他连接被释放 Mycat状态监测安装xinetd组件，用于开放监听端口 sudo apt-get install xinetd 在Mycat server1 Mycat server2上都需要添加检测端口48700的脚本，为此需要用到xinetd首先在xinetd目录下面增加脚本与端口的映射配置文件 vim /etc/xinetd.d/mycat_status1234567891011service mycat_status&#123; flags = REUSE socket_type = stream port = 48700 wait = no user = nobody server = /home/dxy/mycat/bin/mycat_status.sh log_on_failure += USERID disable = no&#125; 注意：mycat_status检测脚本已经平台已经打包在安装包里面了的，由于里面用到了source，ubuntu请参考http://www.linuxdiyf.com/linux/22530.html解决。 增加service端口映射 123vim /etc/services# Local servicesmycat_status 48700/tcp 重启xinetd1service xinetd restart 启动haproxy1[root@haproxy-server-master conf]# /home/dxy/haproxy/sbin/haproxy -f /home/dxy/haproxy/conf/haproxy.cfg 验证一下是否启动成功：123[root@haproxy-server-master conf]# lsof -i :1080COMMAND PID USER FD TYPE DEVICE SIZE/OFF NODE NAMEhaproxy 2221 root 3u IPv4 20285 0t0 TCP *:socks (LISTEN) haproxy管理平台地址：http://127.0.0.1:1080/admin?stats haproxy记录日志（可选）默认 haproxy 是不记录日志的，为了记录日志需要配置 syslog 模块，在 linux 下是 rsyslogd 服务。 先安装 rsyslog（系统应该都安装了，先查看一下） 1sudo apt install rsyslog 添加haproxy的日志配置 vim /etc/rsyslog.d/haproxy.conf 123$ModLoad imudp$UDPServerRun 514local0.* /home/dxy/haproxy/logs/haproxy.log 日志的level: local0～local7 16～23保留为本地使用 0 debug 有调式信息的，日志信息最多 1 info 一般信息的日志，最常用 2 notice 最具有重要性的普通条件的信息 3 warning 警告级别 4 err 错误级别，阻止某个功能或者模块不能正常工作的信息 5 crit 严重级别，阻止整个系统或者整个软件不能正常工作的信息 6 alert 需要立刻修改的信息 7 emerg 内核崩溃等严重信息 修改 /etc/rsyslog.conf 文件 在#### RULES ####上面一行的地方加入以下内容（文件里应该默认有这个配置，可以看一下）： 1234[root@haproxy-server-master /]# vim /etc/rsyslog.conf# Include all config files in /etc/rsyslog.d/$IncludeConfig /etc/rsyslog.d/*.conf 修改 /etc/sysconfig/rsyslog 文件 123[root@haproxy-server-master /]# vim /etc/default/rsyslogSYSLOGD_OPTIONS=&quot;-r -m 0 -c 2&quot; 相关解释说明: -r:打开接受外来日志消息的功能,其监控514 UDP端口; -x:关闭自动解析对方日志服务器的FQDN信息,这能避免DNS不完整所带来的麻烦; -m:修改syslog的内部mark消息写入间隔时间(0为关闭),例如240为每隔240分钟写入一次”–MARK–”信息; -h:默认情况下,syslog不会发送从远端接受过来的消息到其他主机,而使用该选项,则把该开关打开,所有 接受到的信息都可根据syslog.conf中定义的@主机转发过去。 保存，重启 rsyslog 服务123456789101112131415[root@haproxy-server-master /]# systemctl restart rsyslog.service[root@haproxy-server-master /]# systemctl status rsyslog.service● rsyslog.service - System Logging Service Loaded: loaded (/usr/lib/systemd/system/rsyslog.service; enabled; vendor preset: enabled) Active: active (running) since 一 2017-11-27 10:51:26 CST; 11s ago Docs: man:rsyslogd(8) http://www.rsyslog.com/doc/ Main PID: 3855 (rsyslogd) CGroup: /system.slice/rsyslog.service └─3855 /usr/sbin/rsyslogd -n11月 27 10:51:26 haproxy-server-master systemd[1]: Starting System Logging Service...11月 27 10:51:26 haproxy-server-master rsyslogd[3855]: [origin software=&quot;rsyslogd&quot; swVersion=&quot;8.24.0&quot; x-pid=&quot;38...tart11月 27 10:51:26 haproxy-server-master systemd[1]: Started System Logging Service.Hint: Some lines were ellipsized, use -l to show in full. 现在你就可以看到日志（/home/dxy/haproxy/logs/haproxy.log）了（如果没有，重启一下Haproxy）。]]></content>
      <categories>
        <category>mycat</category>
      </categories>
      <tags>
        <tag>mycat</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mycat部署文档之Keepalived]]></title>
    <url>%2F2018%2F05%2F01%2FMycat%E9%83%A8%E7%BD%B2%E6%96%87%E6%A1%A3%E4%B9%8BKeepalived%2F</url>
    <content type="text"><![CDATA[keepalived 安装直接通过apt-get方式安装最简单1234[root@bogon /]# apt-get install libssl-dev openssl libpopt-dev[root@bogon /]# apt-get install -y keepalived[root@bogon /]# keepalived -v[root@bogon /]# Keepalived v1.2.13 (08/03,2017) 编写 Haproxy 状态监测12345678910[root@bogon /]# vim /etc/keepalived/check_haproxy.sh#!/bin/shif [ $(ps -C haproxy --no-header | wc -l) -eq 0 ]; then /home/dxy/haproxy/sbin/haproxy -f /home/dxy/haproxy/conf/haproxy.cfgfisleep 2if [ $(ps -C haproxy --no-header | wc -l) -eq 0 ]; then killall keepalivedfi 设置keepalived master的最简配置1234567891011121314151617181920212223242526272829303132333435363738394041424344454647! Configuration File for keepalived# global setting , notify email settingglobal_defs &#123; #存在于同一个网段中，一组keepalived的各个节点都有不同的名字 #在全局设置中，我们还可以设置管理员的email信息等。 router_id LVS_V1&#125;#这个是我们在上一小结讲到的haproxy检查脚本，我们保存在这个文件中（注意文件权限）vrrp_script chkhaproxy &#123; script &quot;/etc/keepalived/check_haproxy.sh&quot; #每10秒钟，检查一次 interval 10&#125;#keepalived实例设置，是最重要的设置信息vrrp_instance VI_1 &#123; #state状态MASTER表示是主要工作节点。 #一个keepalived组中，最多只有一个MASTER节点，当然也可以没有 state MASTER #实例所绑定的网卡设备，我的网卡设备是ens33。您按照您自己的来 interface ens33 #同一个keepalived组，节点的设置必须一样，这样才会被识别 virtual_router_id 52 #节点优先级，BACKUP的优先级一定要比MASTER的优先级低 priority 100 #组播信息发送间隔，两个节点设置必须一样 advert_int 1 #实际的ens33上的固定ip地址 mcast_src_ip 192.168.1.11 #验证信息，只有验证信息相同，才能被加入到一个组中。 authentication &#123; auth_type PASS auth_pass 1111 &#125; #虚拟地址和绑定的端口，如果有多个，就绑定多个 #dev 是指定浮动IP要绑定的网卡设备号 virtual_ipaddress &#123; 192.168.1.10 dev ens33 &#125; #设置的检查脚本 #关联上方的“vrrp_script chkhaproxy” track_script &#123; chkhaproxy &#125;&#125; 设置keepalived slave的最简配置12345678910111213141516171819202122232425262728293031323334353637! Configuration File for keepalived# global setting , notify email settingglobal_defs &#123; #这里和master节点不同 router_id LVS_V2&#125;#check haproxyvrrp_script chkhaproxy &#123; script &quot;/etc/keepalived/check_haproxy.sh&quot; interval 10&#125;# instance settingvrrp_instance VI_1 &#123; # 这里和Master节点不一样 state BACKUP interface ens33 # 这里一定是一样的 virtual_router_id 52 # 这里的优先级比Master节点低 priority 99 advert_int 1 # 这里和Master节点不一样 mcast_src_ip=192.168.1.12 authentication &#123; auth_type PASS auth_pass 1111 &#125; virtual_ipaddress &#123; 192.168.1.10 dev ens33 &#125; track_script &#123; chkhaproxy &#125;&#125; 以上配置中请注意几个关键点： 注意 haproxy 状态检查的脚本的位置，根据自己创建文件的位置不一样，脚本检查的指定位置也不一样； 注意优先级，MASTER节点的优先级一定要高于所有的BACKUP节点； 注意局域网的组播地址，一定要可用。局域网内所有keepalived节点都是利用组播方式寻找对方； 谁说BACKUP节点只能有一个！？ 最后，keepalived一定要注册成服务形式，您可以想象上面所有脚本、配置、命令如果重启后再来一次，会是什么情况。 接下来，我们要开始启动 Master 节点和 Backup 节点了，为了准确的查看日志状态，您需要观察系统日志。系统日志所在的位置：1tail -f /var/log/messages 启动keepalived1[root@localhost ~]# service keepalived start 如果设置和启动都是成功的，您不会在日志信息中收到任何的keepalived报错信息。接下来您就可以使用192.168.1.10这个IP访问 haproxy了. 验证Keepalived是否正常启动在主备机环境中输入以下命令，查看当前系统网络配置信息：123456789101112131415# ip a1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN group default link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever inet6 ::1/128 scope host valid_lft forever preferred_lft forever2: eth0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast state UP group default qlen 1000 link/ether 08:00:27:07:f5:db brd ff:ff:ff:ff:ff:ff inet 192.168.1.11/24 brd 192.168.16.255 scope global eth0 valid_lft forever preferred_lft forever inet 192.168.1.10/24 scope global secondary eth0 valid_lft forever preferred_lft forever inet6 fe80::a00:27ff:fe07:f5db/64 scope link valid_lft forever preferred_lft forever 可以发现eth0下多了inet 192.168.1.10/24，表明keepalived已正常工作。 参考地址 http://valleylord.github.io/post/201603-mycat-haproxy/ http://www.itpux.com/thread-4668-1-1.html https://blog.csdn.net/u012758088/article/details/78651964 http://kingleema.com/2015/11/14/setup-keepalived-on-ubuntu-server/]]></content>
      <categories>
        <category>mycat</category>
      </categories>
      <tags>
        <tag>mycat</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mycat运维部署文档]]></title>
    <url>%2F2018%2F05%2F01%2FMycat%E8%BF%90%E7%BB%B4%E9%83%A8%E7%BD%B2%E6%96%87%E6%A1%A3%2F</url>
    <content type="text"><![CDATA[环境准备 JDK 下载，至少JDK1.7版本及以上http://www.oracle.com/technetwork/java/javase/downloads/jdk7-downloads-1880260.html MySQL 下载http://dev.mysql.com/downloads/mysql/5.5.html#downloads 注:MyCAT 支持多种数据库接入，如:MySQL、SQLServer、Oracle、MongoDB 等，推荐使用MySQL 做集群。 安装与部署平台组有提供编译好的安装包，支持 windows、Linux、Mac、Solaris 等系统上安装与运行。解压安装包建议放在 /usr/local/Mycat 目录下，创建mycat用户，改变目录权限为mycat123$ tar zxf Mycat-server-1.6-RELEASE-20161028204710-linux.tar.gz$ useradd mycat$ chown -R mycat.mycat /usr/local/mycat mysql设置通过部署发现在Mycat中部署逻辑表表名大小写混合时，在Mycat连接后出现全变小，所以需要修改mysql不忽略表名大小写，需要手动到/etc/my.cnf 下配置 lower_case_table_names=1 环境变量设置123$ vim /etc/profileMYCAT_HOME=/usr/local/mycatsource /etc/profile jdk设置启动前，需修改java的命令配置，打开conf/wrapper.conf文件，修改wrapper.java.command项，如下123# Java Applicationwrapper.java.command=/opt/java8/bin/javawrapper.working.dir=.. 内存设置启动前，一般需要修改JVM配置参数，打开conf/wrapper.conf文件，如下行的内容为2G和2048，可根据本机配置情况修改为512M或其它值。 以下配置跟jvm参数完全一致，可以根据自己的jvm参数调整1234567891011121314151617# Java Additional Parameterswrapper.java.additional.1=wrapper.java.additional.1=-DMYCAT_HOME=.wrapper.java.additional.2=-serverwrapper.java.additional.3=-XX:MaxPermSize=512M #JVM最大允许分配的非堆内存wrapper.java.additional.4=-XX:+AggressiveOptswrapper.java.additional.5=-XX:MaxDirectMemorySize=100mwrapper.java.additional.6=-Dcom.sun.management.jmxremotewrapper.java.additional.7=-Dcom.sun.management.jmxremote.port=1984wrapper.java.additional.8=-Dcom.sun.management.jmxremote.authenticate=falsewrapper.java.additional.9=-Dcom.sun.management.jmxremote.ssl=falsewrapper.java.additional.10=-Xmx2048m #VM最大允许分配的堆内存wrapper.java.additional.11=-Xms2048m #JVM初始分配的堆内存wrapper.java.additional.12=-XX:+UseParNewGC #设置新生代使用并发收集器wrapper.java.additional.13=-XX:+UseConcMarkSweepGC #设置JVM堆的老年代使用CMS并发收集器wrapper.java.additional.14=-XX:+UseCMSCompactAtFullCollection #打开对老年代的压缩wrapper.java.additional.15=-XX:CMSFullGCsBeforeCompaction=5 #设置5才CMSGC后对堆空间进行压缩、整理 Zookeeper配置由于mycat多实例运行，需要统一的配置中心，官方建议将配置文件基于zk部署。 修改conf下的myid.properities 123456789101112131415vim myid.propertiesloadZk=true# zk集群地址，多个用&quot;,&quot;隔开zkURL=127.0.0.1:2181# zk集群内Mycat集群IDclusterId=dxy-ucloud-mycat-cluster# Mycat集群内本实例ID，禁止重复myid=ucloud_mycat_01# Mycat集群内节点个数clusterSize=2clusterNodes=ucloud_mycat_01,ucloud_mycat_02#server booster ; booster install on db same server,will reset all minCon to 1type=serverboosterDataHosts=dataHost1 初始化zk数据。注意：zk配置文件统一需要在zkconf目录下 1sh $mycat_home/bin/init_zk_data.sh 启动MycatServer1/usr/local/mycat/bin/mycat start 注:mycat 支持的命令{ console | start | stop | restart | status | dump } 数据迁移mysql配置调整，编辑/etc/my.cnf添加123[mysqldump]max_allowed_packet = 16M#default-character-set = utf8mb4 mysqldump导入报ERROR 1153 (08S01) at line 1133809: Got a packet bigger than ‘max_allowed_packet’ bytes错误，因为MySQL允许的默认大小为1MB。 导出数据注意，Mycat在执行INSERT语句时需要完整INSERT语句(用列名)12345mysqldump -uroot -p -c --skip-add-locks --skip-extended-insert --no-autocommit databaseName &gt; databaseName.sql# -c 参数不可少，-c, 全称为–complete-insert 表示使用完整的 insert 语句(用列名字)。# --skip-add-locks 表示导数据时不加锁，如果加锁涉及多分片时容易导致死锁。# --skip-extended-insert 将每行数据输出为一个单独的insert语句# --no-autocommit 参数在每个表格所有的插入语句的前后分别增加SET autocommit = 0和COMMIT语句。相比没有这个参数，插入速度能差出至少200倍，分别是10000QPS和50QPS 导入数据12mysql -uroot -ptest -h192.168.99.216 -P8006 TESTDB #连接Mycatsource /databaseName.sql #导入数据 成功后可以在分片已经存入数据。错误日志在 logs/mycat.log文件中1连接Mycat select * from table 时，Mycat默认limit 100此配置可从schema.xml文件中修改sqlMaxLimit=&quot;100&quot;定义 验证迁移数据完整性查询所有表的主键1SELECT k.column_name,k.table_name FROM information_schema.table_constraints t JOIN information_schema.key_column_usage k USING (constraint_name,table_schema,table_name) WHERE t.constraint_type=&apos;PRIMARY KEY&apos; AND t.table_schema=&apos;数据库&apos;; 查询所有表的记录数(行数)12select table_name,table_rows from information_schema.tables where TABLE_SCHEMA = &apos;数据库&apos; order by table_rows desc;#对于InnoDB表，table_rows行计数仅是大概估计值。 Mycat-web监控Mycat-web 是对mycat-server提供监控服务。功能不局限于对mycat-server使用。他基于jmx对所有JVM监控。通过JDBC连接对Mycat、Mysql 监控。基于snmp协议，监控远程服务器(目前仅限于linux系统)的cpu、内存、网络、磁盘。Mycat-web 最近改名 Mycat-eye。 Mycat-eye 运行过程中需要依赖 zookeeper，因此需要先安装 zookeeper。 安装12345tar -xvf Mycat-web-1.0-SNAPSHOT-20160331220346-linux.tar.gz -C /usr/local/ 修改zookeeper地址： cd /usr/local/mycat-web/mycat-web/WEB-INF/classes vim mycat.properties zookeeper=127.0.0.1:2181 启动先启动zookeeper,在启动mycat-web12345[root@oracle_standby mycat-web]# netstat -ntpl |grep 8082 tcp 0 0 :::8082 :::* LISTEN 18288/java [root@oracle_standby mycat-web]# [root@oracle_standby mycat-web]# netstat -ntpl |grep 2181 tcp 0 0 :::2181 :::* LISTEN 18251/java 监控平台http://127.0.0.1:8082/mycat/ 注意事项 部署完成，web监控中始终没有数据。是没有开启mycat server.xml中的useSqlStat属性。开启之后，可以监控sql. 监控sql 反应很慢，一般执行sql2分钟之后，监控页面才有反应。 Keepalive+Haproxy高可用配置Mycat 作为一个代理层中间件，Mycat 系统的高可用涉及到 Mycat 本身的高可用以及后端 MySQL 的高可用，在 大多数情况下，建议采用标准的 MySQL 主从复制高可用性配置并交付给 Mycat 来完成后端 MySQL 节点的主从 自动切换。一种常见的做法是使用 MyCAT + Haproxy + Keepalived，这中做法在 mysql 集群中已经很常见了。对于 MyCAT 集群,其大致架构图如下 配置详情请参考 Mycat部署文档之Keepalived 、 Mycat部署文档之Haproxy 问题 由于公司生产环境存在多个机房，是否存在跨机房调用？答：确实存在多个机房，但是不存在跨机房调用。 目前mycat官方版本提供的schema.xml和rule.xml配置文件不能import多个文件，是否存在业务团队由于配置出错导致整体服务不可用问题？答：中间件团队将会对配置文件进行改造，支持include语法。]]></content>
      <categories>
        <category>mycat</category>
      </categories>
      <tags>
        <tag>mycat</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[分库分表方案对比]]></title>
    <url>%2F2018%2F04%2F26%2F%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8%E6%96%B9%E6%A1%88%E5%AF%B9%E6%AF%94%2F</url>
    <content type="text"><![CDATA[背景目前公司业务高速发展，各种业务数据呈井喷的态势，单表数据量急剧膨胀，随之而来是单表读写性能和吞吐量呈下降趋势而且无法应对业务高速增长产生的数据。因此需要使用分库分表机制保证高性能同时支撑和驱动业务发展，选择一款功能强大支持分库分表的中间件就成为当务之急。开源的数据库中间件众多，需要从中挑选一个适合的，并能作为映客长期演进的中间件，因此需要从多个维度对中间件进行相关测试。 分库分表方案针对数据量过大出现的性能问题，通过分库分表将数据量保持在阀值以下，可以有效分散高并发量和缓解大数据量。 分库分表一般分垂直拆分和水平拆分，根据业务将单库（表）拆分为多库（表），常用的字段和不常用的字段拆分至不同的库（表）中，可适当缓解并发量和数据量，但不能根治；垂直拆分之后依然超过单节点所能承载的阈值，则需要水平拆分来进一步处理。 水平拆分则是根据分片算法将一个库（表）拆分为多个库（表）。 分表虽然可以解决海量数据导致的性能问题，但无法解决过多请求访问同一数据库，导致其响应变慢的问题。所以水平拆分通常要采取分库的方式(合理的配合使用分库+分表)，一并解决数据量和访问量巨大的问题。 分库分表问题 事物问题在执行分库分表之后，由于数据存储到了不同的库上，数据库事务管理出现了困难。如果依赖数据库本身的分布式事务管理功能去执行事务，将付出高昂的性能代价；如果由应用程序去协助控制，形成程序逻辑上的事务，又会造成编程方面的负担。 解决方案：分布式事物(缺点：随着分片数量越来越多，性能代价越来越大) 跨库跨表的join问题在执行了分库分表之后，难以避免会将原本逻辑关联性很强的数据划分到不同的表、不同的库上，这时，表的关联操作将受到限制，我们无法join位于不同分库的表，也无法join分表粒度不同的表，结果原本一次查询能够完成的业务，可能需要多次查询才能完成。 解决方案：解决这一问题的普遍做法是分两次查询实现。在第一次查询的结果集中找出关联数据的id,根据这些id发起第二次请求得到关联数据。 跨库跨表的count,order by,group by以及聚合函数问题这些是一类问题，因为它们都需要基于全部数据集合进行计算。多数的代理都不会自动处理合并工作。 解决方案：与解决跨节点join问题的类似，分别在各个节点上得到结果后在应用程序端进行合并。和join不同的是每个结点的查询可以并行执行，因此很多时候它的速度要比单一大表快很多。但如果结果集很大，对应用程序内存的消耗是一个问题。 数据迁移，扩容等问题业界常用做法利用对2的倍数取余具有向前兼容的特性（如对4取余得1的数对2取余也是1）来分配数据，避免了行级别的数据迁移，但是依然需要进行表级别的迁移，同时对扩容规模和分表数量都有限制。总得来说，这些方案都不是十分的理想，多多少少都存在一些缺点，这也从一个侧面反映出了Sharding扩容的难度。 解决方案：目前业务没有比较成熟的方案 分布式主键问题一旦数据库被切分到多个物理结点上，我们将不能再依赖数据库自身的主键生成机制。一方面，某个分区数据库自生成的ID无法保证在全局上是唯一的；另一方面，应用程序在插入数据之前需要先获得ID,以便进行SQL路由。 解决方案：UUID、Snowflake、数据库序列等 分库/分表策略分库/分表维度确定后，一般常用有两种方式： 根据数值范围，比如用户Id为1-9999的记录分到第一个库，10000-20000的分到第二个库，以此类推。 根据数值取模，比如用户Id mod n，余数为0的记录放到第一个库，余数为1的放到第二个库，以此类推。 优劣比较 对比点 范围 取模 库数量 库数量前期数目比较小，可以随用户/业务按需增长 前期即根据mode因子确定库数量，数目一般比较大 扩容 调整库数量比较容易，一般只需为新用户增加库 需要数据迁移 热点数据 有单库热点数据问题 无热点数据，均分数据 分库数量分库数量首先和单库能处理的记录数有关，一般来说，Mysql 单库超过5000万条记录，DB压力就很大(当然处理能力和字段数量/访问模式/记录长度有进一步关系)。 在满足上述前提下，如果分库数量少，达不到分散存储和减轻DB性能压力的目的；如果分库的数量多，好处是每个库记录少，单库访问性能好，但对于跨多个库的访问，应用程序需要访问多个库，如果是并发模式，要消耗宝贵的线程资源；如果是串行模式，执行时间会急剧增加。 最后分库数量还直接影响硬件的投入，一般每个分库跑在单独物理机上，多一个库意味多一台设备。所以具体分多少个库，要综合评估，一般初次分库建议分4-8个库。 产品调研调研分析后Mycat和Sharding-jdbc功能上比较稳定成熟，支持分库分表、读写分离、分布式主键等。Tidb目前整体比较新，成本方面高，稳定性方面待考察。 Sharding-jdbc：类似TDDL，基于JDBC协议的数据库中间件产品，使用客户端直连数据库，以jar包形式提供服务，兼容JDBC和各种ORM框架，使系统在数据访问层直接具有分片化和分布式治理的能力。 特性： 轻量级框架， 直接封装的jdbc协议，jar包形式提供服务，旧代码迁移、新代码开发成本低 无需额外部署和依赖，客户端直连数据库，无需二次转发，性能高 运维层面不改动，无需关注中间件本身的 HA mycat：基于阿里开源的Cobar研发，对代码进行了彻底重构，使用NIO重构了网络模块，并优化了Buffer内核，增强了聚合，Join等基本特性.主要原理是拦截用户发送过来的SQL语句，对SQL语句做了特定的分析：如分片分析、路由分析、读写分离分析、缓存分析等，然后将此SQL发往后端的真实数据库，并将返回的结果做适当的处理，最后返回给用户。 特性： 可以负责更多的内容，将数据迁移，分布式事务等纳入 Proxy 的范畴 针对mycat和mysql有较全性能监控项统计支持 可结合Storm等分布式实时流引擎，实现数据分析和数据聚合 Tidb：实现了自动的水平伸缩，强一致性的分布式事务，基于 Raft 算法的多副本复制等重要 NewSQL 特性。 TiDB 结合了 RDBMS 和 NoSQL 的优点，部署简单，在线弹性扩容和异步表结构变更不影响业务， 真正的异地多活及自动故障恢复保障数据安全，同时兼容 MySQL 协议，使迁移使用成本降到极低。 特性： SQL支持 （TiDB 是 MySQL 兼容的） 水平线性弹性扩展 分布式事务 跨数据中心数据强一致性保证 故障自恢复的高可用 架构： TiDB 集群主要分为三个组件： TiDB Server TiDB Server 负责接收 SQL 请求，处理 SQL 相关的逻辑，并通过 PD 找到存储计算所需数据的 TiKV 地址，与 TiKV 交互获取数据，最终返回结果。 TiDB Server 是无状态的，其本身并不存储数据，只负责计算，可以无限水平扩展，可以通过负载均衡组件（如LVS、HAProxy 或 F5）对外提供统一的接入地址。 PD Server Placement Driver (简称 PD) 是整个集群的管理模块，其主要工作有三个： 一是存储集群的元信息（某个 Key 存储在哪个 TiKV 节点）；二是对 TiKV 集群进行调度和负载均衡（如数据的迁移、Raft group leader 的迁移等）；三是分配全局唯一且递增的事务 ID。PD 是一个集群，需要部署奇数个节点，一般线上推荐至少部署 3 个节点。 TiKV Server TiKV Server 负责存储数据，从外部看 TiKV 是一个分布式的提供事务的 Key-Value 存储引擎。存储数据的基本单位是 Region（区域），每个 Region 负责存储一个 Key Range （从 StartKey 到 EndKey 的左闭右开区间）的数据，每个 TiKV 节点会负责多个 Region 。TiKV 使用 Raft 协议做复制，保持数据的一致性和容灾。副本以 Region 为单位进行管理，不同节点上的多个 Region 构成一个 Raft Group，互为副本。数据在多个 TiKV 之间的负载均衡由 PD 调度，这里也是以 Region 为单位进行调度。 比较本次对比不是对MySQL数据库进行极限或压力性能测试，而是在同等软硬件环境下对选取的数据库中间件在软件/物理架构、功能特性、扩展性、SQL支持程度、容灾/容错、可用性、可维护性、接入成本等进行综合衡量。 对比点 mycat sharding-jdbc Tidb 分库分表功能 支持部分分库分表（支持单库分表，多库单表，但是不支持同时多库分表） 支持 支持 读写分离功能 支持，支持读写延时切换，支持多主模式，支持心跳监测 只支持简单的读写分离 待定 分布式事物 弱XA 当前版本不支持，未来版本支持XA事物和Base事物 完全ACID 跨库跨表的join和聚合问题 支持分页、排序、分组、聚合，内部通过堆外内存计算合并 支持分页、排序、分组、聚合,内部集成内存分组归并和流式分组归并 无 数据迁移，扩容等问题 提供迁移脚本工具（经过测试发现大数据量的时候会出现报错问题，导致迁移中断） 无 无 SQL解析 Druid解析器 自研解析器(性能高),后期规划ANTLR解析 待定 数据库连接 自研数据库连接池，存在占用连接数过大问题 SS自动选择内存限制模式和连接限制模式模式 无 数据治理 支持zk 支持zk和etcd 待定 APM监控 无 只支持sql解析和路由相关 待定 分布式主键 雪花算法、数据库序列、zk序列 雪花算法 区间分段（可能出现重复主键） 分片规则 基本支持，可自定义 基本支持，可自定义，支持多分片项 内部实现机制，无需业务制定 支持数据库 mysql、nosql(monogdb) mysql 本身就是数据库 HA haproxy+keeplive 无 水平扩展+高可用 语言 java java go 可维护性 较高（提供管控台） 较高 低（虽然提供管控台，但是由于开发语言限制与团队技术栈不一致） 接入成本 低 较高(业务方需配合) 高(业务数据需要全部迁移tidb) 社区活跃度 低 高（最近加入Apache孵化器） 高 优点 有效解决了数据库链接数多的问题，因为各工程应用只连接中间件，中间件代理了真实的物理链接，并且与后端mysql物理链接是复用型的所有的分库分表等规则集中配置在中间件上，更可控 性能高 产品较新 缺点 1.计算过程只能单节点计算，单机扩展只能调优，但是集群可以做负载均衡； 2.相对sharding-jdbc来说，由于增加一层中间代理，性能稍微降低; 3.需要保证中间件的可用性，会增加运维成本及复杂度；4.代码排查问题弱，需要熟悉mysql协议和nio相关知识； 1.业务方需要配置多数据源，分库分表走sharding数据源，其他走主数据源（目前不支持全部数据源都走sharding，由于每次sql路由都需要做sql解析，sql解析这步会检查sql的支持项）;2.sharding-jdbc目前不支持分布式事物，和社区沟通，下个版本会支持XA和Base解决方案，目前只有sharding-proxy支持XA事物;3.分布式主键采用雪花算法，但是没有考虑时间回拨问题（闰秒），还有业务方需要手动设置workid（这点确实不人性化）; 4.客户端业务复杂，如wechat项目 1.业务数据需要全部迁移，并且生产环境配置要求较高 2.成本高 综合考虑，shardjdbc整体优于mycat，tidb由于太过新颖，在加上成本问题，可以暂不考虑。 Mycat分库分表后不支持的sql语法 SELECT不支持的语法 不支持跨分片的交叉查询 跨节点的联合查询，不支持union all，union mycat支持跨库2张表的join INSERT不支持的语法 插入的字段不包含分片字段 插入的分片字段找不到对应分片 复制插入 insert into…select… 多行插入 insert into tab_a(c1,c2) values(v1,v2),(v11,v21)… UPDATE不支持的语法 更新的列包含分片列 多表更新 update a, b set a.nation=’China’, b.pwd=’123456’ where a.id=b.id 复杂多表关联更新 update a, b set a.nation=’China’ where a.id=b.id; 但支持子查询方式 update a set a.nation=’China’ where id in (select id from b); DELETE不支持语法 复杂删除sql delete a from a join b on a.id=b.id; 支持子查询方式 delete from a where a.id in (select id from b), 但表不能起别名 其他 Call procedure() MyCat未支持存储过程定义, 因而不允许调用存储过程，但可通过注解来调用各个分片上的存储过程 Select func(); 不支持这种方式直接调用自定义函数， 但支持 select id, func() from employee 只需employee所在的所有分片上存在这个函数。MySql自带函数可随意使用。 Sharding-Jdbc分库分表后不支持的sql语法 SQL项 不支持原因 INSERT INTO tbl_name (col1, col2, …) SELECT col1, col2, … FROM tbl_name WHERE col3 = ? insert into … select … INSERT INTO tbl_name SET col1 = ? insert … set … SELECT DISTINCT * FROM tbl_name WHERE column1 = ? distince SELECT COUNT(col1) as count_alias FROM tbl_name GROUP BY col1 HAVING count_alias &gt; ? having SELECT FROM tbl_name1 UNION SELECT FROM tbl_name2 union SELECT FROM tbl_name1 UNION ALL SELECT FROM tbl_name2 union all SELECT * FROM tbl_name1 WHERE (val1=?) AND (val1=?) 只支持一级冗余括号 SELECT * FROM ds.tbl_name1 不支持seheme mycat 使用教程mycat分库分表规则主要是修改server.xml、schema.xml和rule.xml。 server.xml：是Mycat服务器参数调整和用户授权的配置文件。 schema.xml：是逻辑库定义和表以及分片定义的配置文件。 rule.xml：是分片规则的配置文件，分片规则的具体一些参数信息单独存放为文件，也在这个目录下，配置文件修改需要重启MyCAT。 mycat服务端server.xml配置 1234567891011121314151617181920212223242526272829303132333435363738394041424344&lt;mycat:server xmlns:mycat="http://io.mycat/"&gt; &lt;system&gt; &lt;!-- 0为需要密码登陆、1为不需要密码登陆 ,默认为0，设置为1则需要指定默认账户--&gt; &lt;property name="nonePasswordLogin"&gt;0&lt;/property&gt; &lt;!-- 1为开启实时统计、0为关闭 --&gt; &lt;property name="useSqlStat"&gt;0&lt;/property&gt; &lt;!-- 1为开启全加班一致性检测、0为关闭 --&gt; &lt;property name="useGlobleTableCheck"&gt;0&lt;/property&gt; &lt;!-- 用来指定Mycat全局序列类型，0为本地文件，1为数据库方式，2为时间戳列方式，默认使用本地文件方式，文件方式主要用于测试--&gt; &lt;property name="sequnceHandlerType"&gt;2&lt;/property&gt; &lt;!--默认为type 0: DirectByteBufferPool | type 1 ByteBufferArena--&gt; &lt;property name="processorBufferPoolType"&gt;0&lt;/property&gt; &lt;!--分布式事务开关，0为不过滤分布式事务，1为过滤分布式事务（如果分布式事务内只涉及全局表，则不过滤），2为不过滤分布式事务,但是记录分布式事务日志--&gt; &lt;property name="handleDistributedTransactions"&gt;0&lt;/property&gt; &lt;!-- 配置是否启用非堆内存跨分片结果集，1为开启，0为关闭，mycat1.6开始支持该属性--&gt; &lt;property name="useOffHeapForMerge"&gt;1&lt;/property&gt; &lt;!--单位为m--&gt; &lt;property name="memoryPageSize"&gt;64k&lt;/property&gt; &lt;!--单位为k--&gt; &lt;property name="spillsFileBufferSize"&gt;1k&lt;/property&gt; &lt;property name="useStreamOutput"&gt;0&lt;/property&gt; &lt;!--单位为m--&gt; &lt;property name="systemReserveMemorySize"&gt;384m&lt;/property&gt; &lt;!--是否采用zookeeper协调切换 --&gt; &lt;property name="useZKSwitch"&gt;false&lt;/property&gt; &lt;!-- 定义mycat使用的端口，默认值为8066 --&gt; &lt;property name="serverPort"&gt;3307&lt;/property&gt; &lt;!-- 定义mycat管理的端口，默认值为9066 --&gt; &lt;property name="managerPort"&gt;9066&lt;/property&gt; &lt;/system&gt; &lt;!-- 定义登录mycat对的用户权限 --&gt; &lt;user name="root" defaultAccount="true"&gt; &lt;property name="password"&gt;123456&lt;/property&gt; &lt;!-- 若要访问TESTDB 必须现在server.xml 中定义，否则无法访问TESTDB--&gt; &lt;property name="schemas"&gt;dbtest&lt;/property&gt; &lt;!-- 配置是否允许只读 --&gt; &lt;property name="readOnly"&gt;true&lt;/property&gt; &lt;!-- 定义限制前端整体的连接数，如果其值为0，或者不设置，则表示不限制连接数量 --&gt; &lt;property name="benchmark"&gt;11111&lt;/property&gt; &lt;!-- 设置是否开启密码加密功能，默认为0不开启加密，为1则表示开启加密 --&gt; &lt;property name="usingDecrypt"&gt;1&lt;/property&gt; &lt;/user&gt;&lt;/mycat:server&gt; 分库分表schema.xml配置 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061&lt;mycat:schema xmlns:mycat="http://io.mycat/"&gt; &lt;!-- schema 定义mycat中的逻辑库，可以有多个逻辑库, 1）dataNode属性：绑定逻辑库到具体的Database上面， 2）checkSQLschema：如果为true，则会替换掉schema，如果为false则不会； 3）sqlMaxLimit：如果带了该属性，则每次执行sql的时候如果sql没有limit则会带上这个limit，如果schema为非拆分库，则该属性不会生效。--&gt; &lt;schema name="dbtest" checkSQLschema="true" sqlMaxLimit="100"&gt; &lt;!-- table标签定义了MyCat中的逻辑表，所有拆分的表都需要在table标签中定义。 --&gt; &lt;!-- 1）name属性：定义逻辑表的名称--&gt; &lt;!-- 2）dataNode属性：定义逻辑表所属的dataNode，如果需要引用多个dataNode,则可以用dataNode="dn$0-99" 来代表dn0到dn99的数据库--&gt; &lt;!-- 3）rule属性：用来指定逻辑表使用的规则名字，规则名字在rule.xml中定义。--&gt; &lt;!-- 4）ruleRequired属性：该属性用于指定表是否绑定分片规则，如果配置为true,但是没有具体的分片规则，则会报错。--&gt; &lt;!-- 5）type属性：定义逻辑表的类型，分为"全局表（global）"和"普通表"两种类型,不设置该值的时候未global的所有表。--&gt; &lt;!-- 6）autoIncrement属性：使用该值的时候需要定义auto_increment，使用的时候最好配合数据库模式的全局序列。--&gt; &lt;!-- 7）subTables属性：dataNode在分表的条件下只能配置一个，不支持各种条件的Join关联查询。--&gt; &lt;!-- 8）primaryKey属性:逻辑表对应真实表的主键。--&gt; &lt;!-- 9）needAddLimit属性：指定表是否需要字段再每个语句的后面加上limit限制。--&gt; &lt;table name="travelrecord" dataNode="dn1,dn2" primaryKey="id" rule="rule1"&gt; &lt;!--childTable标签用于定义E-R分片的子表，通过标签上的属性与浮表进行关联--&gt; &lt;!-- 1)name属性：定义子表的名称--&gt; &lt;!-- 2）joinKey属性：插入子表时，回使用这个值查找浮表存贮的数据节点--&gt; &lt;!-- 3）parentKey属性：与父表建立关联关系的列名，程序首先获取joinKey的值，然后通过parentKey属性指定的列名产生查询语句，通过执行语句得知父表存储在哪个分片上，从而确定子表存贮的位置。--&gt; &lt;!-- 4）primaryKey：和table标签一样--&gt; &lt;!-- 5）needAddLimit：和table标签一样--&gt; &lt;/table&gt; &lt;/schema&gt; &lt;!-- dataNode标签定义了mycat中的数据节点，这也就是我们通常所说的数据分片，一个单独的dataNode就是一个独立的数据分片--&gt; &lt;!--1）name属性：定义数据节点的唯一名字--&gt; &lt;!--2）dataHost属性：定义该分片所属的数据库实例，属性引用自dataHost标签上定义的name属性--&gt; &lt;!--3）database属性：定义该分片所属的数据库实例上的具体数据库。--&gt; &lt;dataNode name="dn1" dataHost="localhost1" database="db01"/&gt; &lt;dataNode name="dn2" dataHost="localhost1" database="db02" /&gt; &lt;!-- 定义数据库实例，读写分离和心跳语句--&gt; &lt;!--1)那么属性：标识唯一的dataHost,--&gt; &lt;!-- 2)maxCon属性：指定每个读写实例连接池的最大连接数。内嵌writeHost、readHost标签会使用这个属性的值来实例化连接池的最大连接数--&gt; &lt;!--3)minCon属性：指定每个读写实例连接池的最小连接数。初始化连接池的大小的属性。--&gt; &lt;!--4）balance属性：负债均衡类型，有四种--&gt; &lt;!-- balance="0" : 不开启读写分离机制，所有的读操作都发送到当前可以用的writeHost上--&gt; &lt;!-- balance="1" : 全部的readHost与stand by writeHost（双主从模式下的master） 都参与select语句的负债均衡--&gt; &lt;!-- balance="2" : 所有的读操作都随机的往writeHost和readHost上分发--&gt; &lt;!-- balance="3" : 所有的读分发到readHost上，writeHost负责写--&gt; &lt;!--5）writeType属性：负载均衡目前的取值有两种：--&gt; &lt;!-- writeType="0"：所有的写操作都发送到第一个writeHost,writeHost1挂了，则切换到writeHost2上，重新恢复writeHost1后，还是以writeHost2为准--&gt; &lt;!-- writeType="1"：所有的写操作都随机的发送到配置的writeHost上，1.5版本以后不推荐使用该值。--&gt; &lt;!--6）dbType属性：制定后端后端数据的类型：mysql，oracle、mongoDB--&gt; &lt;!--7）dbDriver属性：制定后端数据库使用的Driver.目前可选的值为native和JDBC。--&gt; &lt;!--8）switchType属性：默认值为1，自动切换。--&gt; &lt;!-- -1表示不自动切换--&gt; &lt;!-- 2表示基于mysql主从同步的状态决定是否切换。--&gt; &lt;!-- 3表示基于mysql galaxy cluster 的切换机制--&gt; &lt;!--9）tempReadHostAvailable属性：如果配置了writeHost属性，下面的readHost依旧可以使用，默认为0--&gt; &lt;dataHost name="localhost1" maxCon="1000" minCon="10" balance="0" writeType="0" dbType="mysql" dbDriver="native" switchType="1" slaveThreshold="100"&gt; &lt;heartbeat&gt;select user()&lt;/heartbeat&gt; &lt;writeHost host="hostM1" url="127.0.0.1:3306" user="root" password="123456"&gt; &lt;!-- url、user、password 设置成你的数据库 --&gt; &lt;/writeHost&gt; &lt;/dataHost&gt;&lt;/mycat:schema&gt; 分库分表规则rule.xml配置 1234567891011121314151617181920212223&lt;mycat:rule xmlns:mycat="http://io.mycat/"&gt; &lt;!--name 属性指定唯一的名字，用于标识不同的表规则 1）内嵌的 rule 标签则指定对物理表中的哪一列进行拆分和使用什么路由算法。 2）columns 内指定要拆分的列名字。 3)algorithm 使用 function 标签中的 name 属性。连接表规则和具体路由算法。当然，多个表规则可以连接到同一个路由算法上。 table 标签内使用。让逻辑表使用这个规则进行分片。 --&gt; &lt;tableRule name="rule1"&gt; &lt;rule&gt; &lt;columns&gt;id&lt;/columns&gt; &lt;algorithm&gt;func1&lt;/algorithm&gt; &lt;/rule&gt; &lt;/tableRule&gt; &lt;!--name 指定算法的名字。 1)class 制定路由算法具体的类名字。 2)property 为具体算法需要用到的一些属性。 --&gt; &lt;function name="func1" class="io.mycat.route.function.PartitionByLong"&gt; &lt;property name="partitionCount"&gt;2&lt;/property&gt; &lt;property name="partitionLength"&gt;512&lt;/property&gt; &lt;/function&gt;&lt;/mycat:rule&gt; sharding-jdbc 使用教程 maven依赖包12345&lt;dependency&gt; &lt;groupId&gt;io.shardingsphere&lt;/groupId&gt; &lt;artifactId&gt;sharding-jdbc&lt;/artifactId&gt; &lt;version&gt;$&#123;sharding-sphere.version&#125;&lt;/version&gt;&lt;/dependency&gt; JPA 集成sharding-jdbc配置 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113@Configuration@EnablePlatformJpaRepositories( entityManagerFactoryRef = "shardingEntityManagerFactory", transactionManagerRef = "shardingTransactionManager", basePackages = &#123;"com.dxy.platform.push.sharding.dao"&#125;)public class ShardingAutoConfiguration extends PlatformModuleConfigurerAdapter implements EnvironmentAware &#123; private Environment environment; @Bean @ConfigurationProperties(prefix = "dxy.datasource.ds01") public PlatformDataSourceProperties sharding01PooledDataSourceProperties() &#123; return new PlatformDataSourceProperties(); &#125; @Bean(name = "sharding01DataSource") public DataSource sharding01DataSource() &#123; return buildPooledDataSource(sharding01PooledDataSourceProperties()); &#125; @Bean @ConfigurationProperties(prefix = "dxy.datasource.ds02") public PlatformDataSourceProperties sharding02PooledDataSourceProperties() &#123; return new PlatformDataSourceProperties(); &#125; @Bean(name = "sharding02DataSource") public DataSource sharding02DataSource() &#123; return buildPooledDataSource(sharding02PooledDataSourceProperties()); &#125; @Bean @ConfigurationProperties(prefix = "dxy.datasource.ds03") public PlatformDataSourceProperties sharding03PooledDataSourceProperties() &#123; return new PlatformDataSourceProperties(); &#125; @Bean(name = "sharding01DataSource") public DataSource sharding03DataSource() &#123; return buildPooledDataSource(sharding03PooledDataSourceProperties()); &#125; @Bean @ConfigurationProperties(prefix = "dxy.datasource.ds04") public PlatformDataSourceProperties sharding04PooledDataSourceProperties() &#123; return new PlatformDataSourceProperties(); &#125; @Bean(name = "sharding04DataSource") public DataSource sharding04DataSource() &#123; return buildPooledDataSource(sharding04PooledDataSourceProperties()); &#125; /** * sharding 主数据源 * @return * @throws SQLException */ @Bean(name = "shardingDataSource") public DataSource shardingDataSource() throws SQLException &#123; // 配置真实数据源 Map&lt;String, DataSource&gt; dataSourceMap = new HashMap&lt;&gt;(); dataSourceMap.put("ds0",sharding01DataSource()); dataSourceMap.put("ds1",sharding02DataSource()); dataSourceMap.put("ds2",sharding03DataSource()); dataSourceMap.put("ds3",sharding04DataSource()); // 配置Order表规则 TableRuleConfiguration orderTableRuleConfig = new TableRuleConfiguration(); orderTableRuleConfig.setLogicTable("push_message"); orderTableRuleConfig.setActualDataNodes("ds$&#123;0..3&#125;.push_message"); //分布式主键 orderTableRuleConfig.setKeyGeneratorColumnName("id"); // 配置分库 + 分表策略 orderTableRuleConfig.setDatabaseShardingStrategyConfig(new InlineShardingStrategyConfiguration("traceId", "ds$&#123;traceId % 4&#125;")); // 配置分片规则 ShardingRuleConfiguration shardingRuleConfig = new ShardingRuleConfiguration(); shardingRuleConfig.getTableRuleConfigs().add(orderTableRuleConfig); //配置项 Properties properties = new Properties(); properties.setProperty("sql.show","true"); DataSource dataSource = ShardingDataSourceFactory.createDataSource( dataSourceMap, shardingRuleConfig, new ConcurrentHashMap(), properties); return dataSource; &#125; @Bean(name = "shardingEntityManagerFactory") public LocalContainerEntityManagerFactoryBean shardingEntityManagerFactory() throws SQLException &#123; HibernateJpaVendorAdapter vendorAdapter = new HibernateJpaVendorAdapter(); vendorAdapter.setShowSql(false); vendorAdapter.setGenerateDdl(false); vendorAdapter.setDatabase(Database.MYSQL); LocalContainerEntityManagerFactoryBean factoryBean = new LocalContainerEntityManagerFactoryBean(); factoryBean.setDataSource(shardingDataSource()); factoryBean.setJpaVendorAdapter(vendorAdapter); factoryBean.setPackagesToScan("com.dxy.platform.push.sharding.domain"); return factoryBean; &#125; @Bean("shardingJdbcTemplate") public JdbcTemplate shardingJdbcTemplate() throws SQLException &#123; return new JdbcTemplate(shardingDataSource()); &#125; @Override public void setEnvironment(Environment environment) &#123; this.environment = environment; &#125;&#125; Mybatis 集成sharding-jdbc配置 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126@Slf4j@Configuration@EnableAutoConfiguration@MapperScan("com.fly.dao")public class ShardingDruidDataSourceAutoConfig&#123; @Primary @Bean(name = "mainDataSource",autowire = Autowire.BY_NAME) @ConfigurationProperties(prefix = "dxy.datasource.main-data-source") public DruidDataSource mainDataSource()&#123; return DruidDataSourceBuilder.create().build(); &#125; @Bean(name = "ds0DataSource",autowire = Autowire.BY_NAME) @ConfigurationProperties("dxy.datasource.ds0") public DruidDataSource ds0DataSource()&#123; return DruidDataSourceBuilder.create().build(); &#125; @Bean(name = "ds1DataSource",autowire = Autowire.BY_NAME) @ConfigurationProperties("dxy.datasource.ds1") public DruidDataSource ds1DataSource()&#123; return DruidDataSourceBuilder.create().build(); &#125; @Bean(name = "ds2DataSource",autowire = Autowire.BY_NAME) @ConfigurationProperties("dxy.datasource.ds2") public DruidDataSource ds2DataSource()&#123; return DruidDataSourceBuilder.create().build(); &#125; @Bean(name = "ds3DataSource",autowire = Autowire.BY_NAME) @ConfigurationProperties("dxy.datasource.ds3") public DruidDataSource ds3DataSource()&#123; return DruidDataSourceBuilder.create().build(); &#125; /** * 分库分表-模式 * @return * @throws SQLException */ @Bean(name = "dataSource",autowire = Autowire.BY_NAME) public DataSource dataSource() throws SQLException &#123; // 配置真实数据源 Map&lt;String, DataSource&gt; dataSourceMap = new HashMap&lt;&gt;(); dataSourceMap.put("main",mainDataSource()); dataSourceMap.put("ds0",ds0DataSource()); dataSourceMap.put("ds1",ds1DataSource()); dataSourceMap.put("ds2",ds2DataSource()); dataSourceMap.put("ds3",ds3DataSource()); // 配置Order表规则 TableRuleConfiguration orderTableRuleConfig = new TableRuleConfiguration(); orderTableRuleConfig.setLogicTable("push_message"); orderTableRuleConfig.setActualDataNodes("ds$&#123;0..3&#125;.push_message"); DefaultKeyGenerator defaultKeyGenerator = new DefaultKeyGenerator(); defaultKeyGenerator.setWorkerId(21L); orderTableRuleConfig.setKeyGenerator(defaultKeyGenerator); orderTableRuleConfig.setKeyGeneratorColumnName("id"); // 配置分库 + 分表策略 orderTableRuleConfig.setDatabaseShardingStrategyConfig(new InlineShardingStrategyConfiguration("traceId", "ds$&#123;traceId % 4&#125;")); //orderTableRuleConfig.setTableShardingStrategyConfig(new InlineShardingStrategyConfiguration("order_id", "t_order$&#123;order_id % 2&#125;")); // 配置分片规则 ShardingRuleConfiguration shardingRuleConfig = new ShardingRuleConfiguration(); shardingRuleConfig.getTableRuleConfigs().add(orderTableRuleConfig); //默认数据源 shardingRuleConfig.setDefaultDataSourceName("main"); // 获取数据源对象// DataSource dataSource = ShardingDataSourceFactory.createDataSource(dataSourceMap, shardingRuleConfig, new ConcurrentHashMap(), new Properties()); //数据治理功能 // 配置注册中心 RegistryCenterConfiguration regConfig = new RegistryCenterConfiguration(); regConfig.setServerLists("zk1.host.dxy:2181,zk2.host.dxy:2181,zk3.host.dxy:2181"); regConfig.setNamespace("sharding-sphere-orchestration"); // 配置数据治理 OrchestrationConfiguration orchConfig = new OrchestrationConfiguration("orchestration-sharding-data-source", regConfig, false); Properties properties = new Properties(); properties.setProperty("sql.show","true"); DataSource dataSource = OrchestrationShardingDataSourceFactory.createDataSource( dataSourceMap, shardingRuleConfig, new ConcurrentHashMap(), properties, orchConfig);// DataSource dataSource = OrchestrationShardingDataSourceFactory.createDataSource(dataSourceMap, shardingRuleConfig, new ConcurrentHashMap(), new Properties(), orchConfig); return dataSource; &#125; /** * 读写分离模式 * @return * @throws SQLException */ @Bean(name = "dataSource1",autowire = Autowire.BY_NAME) public DataSource dataSource1() throws SQLException &#123; // 配置真实数据源 Map&lt;String, DataSource&gt; dataSourceMap = new HashMap&lt;&gt;(); dataSourceMap.put("main",mainDataSource()); dataSourceMap.put("ds0",ds0DataSource()); dataSourceMap.put("ds1",ds1DataSource()); dataSourceMap.put("ds2",ds2DataSource()); dataSourceMap.put("ds3",ds3DataSource()); // 配置分库 + 分表策略 MasterSlaveRuleConfiguration masterSlaveRuleConfiguration = new MasterSlaveRuleConfiguration("test","main", Arrays.asList("ds0","ds1","ds2","ds3")); DataSource dataSource = MasterSlaveDataSourceFactory.createDataSource(dataSourceMap,masterSlaveRuleConfiguration, new HashMap&lt;&gt;(),new Properties()); return dataSource; &#125; @Bean @ConfigurationProperties(prefix = "mybatis") public SqlSessionFactoryBean sqlSessionFactoryBean() throws SQLException &#123; SqlSessionFactoryBean sqlSessionFactoryBean = new SqlSessionFactoryBean(); // 配置数据源，此处配置为关键配置，如果没有将 dynamicDataSource 作为数据源则不能实现切换 sqlSessionFactoryBean.setDataSource(dataSource()); return sqlSessionFactoryBean; &#125;&#125;]]></content>
      <categories>
        <category>mycat</category>
      </categories>
      <tags>
        <tag>mycat</tag>
        <tag>分库分表</tag>
        <tag>sharding-jdbc</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[otter]]></title>
    <url>%2F2018%2F04%2F24%2Fotter%E5%9F%BA%E7%A1%80%E4%BB%8B%E7%BB%8D%2F</url>
    <content type="text"><![CDATA[背景 ***公司系统间的数据同步通过http接口通信，这种方式会导致数据同步高峰期间nginx的负载流量增加，从而影响业务流量。其二就是http方式的不稳定性，会导致一些数据不一致的问题。针对这个现象，目前提出2中解决方式，第一种可以通过高可用消息队列来进行解耦，第二种通过数据库底层binlog来监听数据变化。 otter介绍 otter为阿里的一款增量数据同步工具，基于数据库增量日志解析，准实时同步到本机房或异地机房的mysql/oracle数据库.一个分布式数据库同步系统。 otter工作原理 原理描述： 基于Canal开源产品，获取数据库增量日志数据。 典型管理系统架构，manager(web管理)+node(工作节点).manager运行时推送同步配置到node节点.node节点将同步状态反馈到manager上. 基于zookeeper，解决分布式状态调度的，允许多node节点之间协同工作. Otter目前支持了什么 单向同步， mysql/oracle互相同步 双向同步，无冲突变更 文件同步，本地/aranda文件 双A同步，冲突检测&amp;冲突补救 数据迁移，中间表/行记录同步 典型的场景是账户信息表和账户交易明细表，更新账户余额后需要登记一条账户明细，并且保证在一个事务里，用户可以通过交易明细表查看交易记录，但是交易明细表的数据量是逐步递增的，用户量多的系统，几个月下来的数据超过千万了，表数据量一多就导致查询和插入变慢，而一开始就对账户明细做分表处理就难于保证强一致性事务，通过otter可以将记录同步导历史表，并且进行分表处理，用户往年的交易记录就可以查询历史表了，而原交易明细表就可以删除一个月甚至几天前的数据； 环境准备 otter manager依赖于mysql进行配置信息的存储，所以需要预先安装mysql，并初始化otter manager的系统表结构。 整个otter架构依赖了zookeeper进行多节点调度，所以需要预先安装zookeeper，不需要初始化节点，otter程序启动后会自检. 安装jdk1.6+ 官方文档：https://github.com/alibaba/otter/wiki/Manager_Quickstarthttps://github.com/alibaba/otter/wiki/Node_Quickstart 名词解释 Channel：同步通道，单向同步中一个Pipeline组成，在双向同步中有两个Pipeline组成；Pipeline：从源端到目标端的整个过程描述，主要由一些同步映射过程组成； DataMediaPair：根据业务表定义映射关系，比如源表和目标表，字段映射，字段组等； DataMedia:抽象的数据介质概念，可以理解为数据表/mq队列定义； DataMediaSource: 抽象的数据介质源信息，补充描述DateMedia； ColumnPair: 定义字段映射关系； ColumnGroup: 定义字段映射组； Node: 处理同步过程的工作节点，对应一个jvm； 采坑问题 mysql需要开启binlog,并且binlog的模式一定要Row。 mysql5.6版本需要binlog_checksum设置为none，默认开始crc校验。 mysql mater节点需要设置server-id，server-id需要和manager上配置的node的id一致。错误内容如下：12345pid:1 nid:1 exception:canal:源数据库cancal:java.io.IOException: Received error packet: errno = 1236, sqlstate = HY000 errmsg = Misconfigured master - server_id was not set at com.alibaba.otter.canal.parse.inbound.mysql.dbsync.DirectLogFetcher.fetch(DirectLogFetcher.java:105) at com.alibaba.otter.canal.parse.inbound.mysql.MysqlConnection.dump(MysqlConnection.java:146) at com.alibaba.otter.canal.parse.inbound.AbstractEventParser$3.run(AbstractEventParser.java:227) at java.lang.Thread.run(Thread.java:745) 参考资料 https://github.com/alibaba/otter/wiki https://github.com/alibaba/otter/wiki/Faq https://blog.csdn.net/wudufeng/article/details/78688240 https://yq.aliyun.com/articles/223077?utm_content=m_32233 https://my.oschina.net/u/860872/blog/1609715 https://www.cnblogs.com/findumars/p/6294542.html mysql binlog优化https://www.cnblogs.com/doseoer/p/6132454.html binlog采坑 https://www.cnblogs.com/276815076/p/7993712.html https://yq.aliyun.com/articles/223077?utm_content=m_32233 https://blog.csdn.net/wudufeng/article/details/78688240]]></content>
      <categories>
        <category>otter</category>
      </categories>
      <tags>
        <tag>otter</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker 基础命令]]></title>
    <url>%2F2018%2F04%2F23%2Fdocker%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[拉取镜像 docker pull daocloud.io/library/mysql:5.6 创建容器 docker run -p 3306:3306 –name mysql -v /Users/peijiepang/Documents/docker/mysql/conf:/etc/mysql -v /Users/peijiepang/Documents/docker/mysql/data:/var/lib/mysql -e MYSQL_ROOT_PASSWORD=123456 -d daocloud.io/library/mysql:5.6 获取所有的容器id docker ps -a 启动容器 docker start 578fcc293e25 查看当前启动的容器 docker ps 进去容器内部系统 sudo docker exec -it 578fcc293e25 /bin/bash 退出容器 exit/ctrl+c 容器重启 docker restart 容器id 查看容器启动日志 docker logs 容器id docker容器安装vim apt-get update，这个命令的作用是：同步 /etc/apt/sources.list 和 /etc/apt/sources.list.d 中列出的源的索引，这样才能获取到最新的软件包。等更新完毕以后再敲命令：apt-get install vim命令即可。 容器拷贝文件 12将主机/www/runoob目录拷贝到容器96f7f14e99ab的/www目录下:docker cp /www/runoob 96f7f14e99ab:/www/ 12docker cp /www/runoob 96f7f14e99ab:/www将容器96f7f14e99ab的/www目录拷贝到主机的/tmp目录中 容器设置时区12345678进入到/usr/share/zoneinfo/Asia目录，查看目录信息/usr/share/zoneinfo/Asia# ls -hllrwxrwxrwx 1 root root 6 Jul 6 02:15 Shanghai -&gt; ../PRClrwxrwxrwx 1 root root 12 Jul 6 02:15 Singapore -&gt; ../Singapore从查询结果可以知道，上海的时区文件实际上是个软连接文件。连接到了目录 /usr/share/zoneinfo/ 下的PRC文件。 直接进行拷贝：cp /usr/share/zoneinfo/PRC /etc/localtime然后这样就可以了。]]></content>
      <categories>
        <category>docker</category>
      </categories>
      <tags>
        <tag>命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java应用CPU百分百解决方案]]></title>
    <url>%2F2018%2F04%2F22%2Fjava%E5%BA%94%E7%94%A8CPU%E7%99%BE%E5%88%86%E7%99%BE%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88%2F</url>
    <content type="text"><![CDATA[利用top命令查找异常进程 top 输入top命令后，可以按P(shift+p)根据cpu占用排序、按M根据内存占用排序、按T根据运行时间排序。 这里先按P根据cpu排序查找异常的线程：]]></content>
      <categories>
        <category>问题及解决</category>
      </categories>
      <tags>
        <tag>服务器问题</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java应用OOM快速定位与解决方法]]></title>
    <url>%2F2018%2F04%2F21%2FOOM%E5%BF%AB%E9%80%9F%E5%AE%9A%E4%BD%8D%E4%B8%8E%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[背景最近项目老是出现OOM问题，常见有以下错误： java.lang.OutOfMemoryError: PermGen space java.lang.OutOfMemoryError: Java heap space OOM的常见原因 内存分配确实过小 频繁创建对象，没有及时释放 频繁申请系统资源，导致系统资源耗尽（例如：不断创建线程，不断发起网络连接） Java代码导致OutOfMemoryError错误的解决 检查代码中是否有死循环或递归调用。 检查是否有大循环重复产生新对象实体。 检查对数据库查询中，是否有一次获得全部数据的查询。一般来说，如果一次取十万条记录到内存，就可能引起内存溢出。这个问题比较隐蔽，在上线前，数据库中数据较少，不容易出问题，上线后，数据库中数据多了，一次查询就有可能引起内存溢出。因此对于数据库查询尽量采用分页的方式查询。 检查List、MAP等集合对象是否有使用完后，未清除的问题。List、MAP等集合对象会始终存有对对象的引用，使得这些对象不能被GC回收。 定位代码解决需要先找到出问题的进程，使用top命令定位： top 输入top命令后，可以按P(shift+p)根据cpu占用排序、按M根据内存占用排序、按T根据运行时间排序。（可以先按c显示具体的command） 这里先按M根据内存排序查找异常的进程：这里假设出现异常的进程pid为10410 注意定位问题前请先尝试输入jps命令，确定是否能够显示出现问题的pid.如果jps没有相应的显示，可能是你当前用户的权限不够，请使用启用相应进程的用户或者拥有更高权限的用户排查问题！不然以下的一些命令（例如jmap）将无法使用. 判断是否是由于“内存分配确实过小”输入以下命令： jmap -heap 10410 Attaching to process ID 10410, please wait... Debugger attached successfully. Server compiler detected. JVM version is 25.91-b14 using thread-local object allocation. Parallel GC with 4 thread(s) Heap Configuration: MinHeapFreeRatio = 0 MaxHeapFreeRatio = 100 MaxHeapSize = 2147483648 (2048.0MB) NewSize = 44564480 (42.5MB) MaxNewSize = 715653120 (682.5MB) OldSize = 89653248 (85.5MB) NewRatio = 2 SurvivorRatio = 8 MetaspaceSize = 21807104 (20.796875MB) CompressedClassSpaceSize = 1073741824 (1024.0MB) MaxMetaspaceSize = 17592186044415 MB G1HeapRegionSize = 0 (0.0MB) Heap Usage: PS Young Generation Eden Space: capacity = 343408640 (327.5MB) used = 63192336 (60.26490783691406MB) free = 280216304 (267.23509216308594MB) 18.401498576156964% used From Space: capacity = 18350080 (17.5MB) used = 12886976 (12.28997802734375MB) free = 5463104 (5.21002197265625MB) 70.22844587053571% used To Space: capacity = 18874368 (18.0MB) used = 0 (0.0MB) free = 18874368 (18.0MB) 0.0% used PS Old Generation capacity = 80216064 (76.5MB) used = 24040136 (22.92646026611328MB) free = 56175928 (53.57353973388672MB) 29.969229106030433% used 23018 interned Strings occupying 2885744 bytes. 判断是否是由于“频繁创建对象，没有及时回收”输入以下命令，找出最耗内存的对象： jmap -histo:live 10410 | more num #instances #bytes class name ---------------------------------------------- 1: 59259 8998824 [C 2: 21537 1895256 java.lang.reflect.Method 3: 57709 1385016 java.lang.String 4: 2683 1063512 [B 5: 9175 1021368 java.lang.Class 6: 18681 747240 java.util.LinkedHashMap$Entry 7: 21370 683840 java.util.concurrent.ConcurrentHashMap$Node 8: 8166 574544 [Ljava.util.HashMap$Node; 9: 9977 558712 java.util.LinkedHashMap 10: 9548 518480 [Ljava.lang.Object; 11: 21735 472376 [Ljava.lang.Class; 12: 13345 427040 java.util.HashMap$Node 13: 5570 401040 java.lang.reflect.Field 14: 259 258400 [Ljava.util.concurrent.ConcurrentHashMap$Node; 15: 14774 236384 java.lang.Object 16: 2692 215360 java.lang.reflect.Constructor 17: 3413 198216 [Ljava.lang.reflect.Method; 18: 4133 160288 [Ljava.lang.String; 19: 3695 147800 java.lang.ref.SoftReference 20: 1537 147552 org.springframework.beans.GenericTypeAwarePropertyDescriptor 21: 2378 133168 java.lang.Class$ReflectionData 22: 2861 132256 [I 23: 4050 129600 java.util.LinkedList 24: 3749 119968 java.lang.ref.WeakReference 25: 2435 116880 java.util.HashMap 26: 4509 108216 java.util.ArrayList 27: 4080 97920 java.beans.MethodRef 28: 2154 86160 java.util.TreeMap$Entry 29: 1188 85536 org.springframework.core.annotation.AnnotationAttributes 30: 1126 72064 org.springframework.core.MethodParameter 31: 2858 68592 java.util.LinkedList$Node 32: 3928 62848 java.util.LinkedHashSet 33: 370 62160 org.springframework.context.annotation.ConfigurationClassBeanDefinitionReader$ConfigurationClassBeanDefinition 34: 2185 52440 sun.reflect.generics.tree.SimpleClassTypeSignature 35: 2016 48384 sun.reflect.annotation.AnnotationInvocationHandler 36: 961 46128 org.springframework.core.ResolvableType 37: 901 43248 org.apache.tomcat.util.modeler.AttributeInfo 38: 2023 43200 [Ljava.lang.reflect.Type; 39: 2570 41120 java.util.LinkedHashMap$LinkedKeySet 40: 2185 41096 [Lsun.reflect.generics.tree.TypeArgument; 41: 1282 41024 java.util.concurrent.locks.ReentrantLock$NonfairSync 42: 2472 39552 java.util.LinkedHashMap$LinkedEntrySet 43: 2374 37984 org.springframework.core.annotation.AnnotationUtils$DefaultValueHolder 44: 1593 37008 [Ljava.lang.reflect.Constructor; 输入命令后，会以表格的形式显示存活对象的信息，并按照所占内存大小排序。 instances: 对象实例数量 bytes: 占用内存大小 class name: 类名 可以看到目前最耗内存的对象也才占用内存8m，所以属于正常范畴 如果发现某个对象的占用大量内存（例如：1G以上），就需要review代码，审查下该对象是否没有及时回收 PS：其中输出的奇怪的class name请查看最后的附录。 判断是否是由于“频繁申请系统资源”输入以下命令，查看进程的线程数 ll /proc/{PID}/task | wc -l 输入以下命令，查看进程的句柄数 ll /proc/{PID}/fd | wc -l jmap 附加说明 BaseType Character Type Interpretation B byte signed byte C char Unicode character D double double-precision floating-point value F float single-precision floating-point value I int integer J long long integer L reference an instance of class S short signed short Z boolean true or false [ reference one array dimension]]></content>
      <categories>
        <category>问题及解决</category>
      </categories>
      <tags>
        <tag>OutOfMemoryError</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[druid数据源无可用连接问题]]></title>
    <url>%2F2018%2F04%2F20%2Fdruid%E6%95%B0%E6%8D%AE%E6%BA%90%E6%97%A0%E5%8F%AF%E7%94%A8%E8%BF%9E%E6%8E%A5%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[背景在工程中使用了druid连接池，运行一段时间后系统出现异常,但是使用客户端能正常连接，连接数被未被占满,报错如下： Caused by: org.springframework.jdbc.CannotGetJdbcConnectionException: Could not get JDBC Connection; nested exception is com.alibaba.druid.pool.GetConnectionTimeoutException: wait millis 60009, active 50 at org.springframework.jdbc.datasource.DataSourceUtils.getConnection(DataSourceUtils.java:80) at org.springframework.jdbc.support.JdbcUtils.extractDatabaseMetaData(JdbcUtils.java:280) … 64 more 原因及解决方案应该是程序中有地方连接未关闭造成的。那如何来定呢？使用druid连接池的超时回收机制，在配置中增加以下内容： &lt;!– 超过时间限制是否回收 –&gt; &lt;property name=“removeAbandoned” value=“true” /&gt; &lt;!– 超时时间；单位为秒。180秒=3分钟 –&gt; &lt;property name=“removeAbandonedTimeout” value=“180” /&gt; &lt;!– 关闭abanded连接时输出错误日志 –&gt; &lt;property name=“logAbandoned” value=“true” /&gt; 但是加了logAbandoned配置之后，可能经常会强制释放连接报错，错误如下： [com.alibaba.druid.pool.DruidDataSource] – &lt;abandon connection, open stackTrace at java.lang.Thread.getStackTrace(Thread.java:1567) at com.alibaba.druid.pool.DruidDataSource.getConnectionDirect(DruidDataSource.java:995) at com.alibaba.druid.filter.FilterChainImpl.dataSource_connect(FilterChainImpl.java:4544) 备注：该堆栈是之前使用该连接是new出来的，故可以凭此确认此链接使用没有很好的回收。 但理论上使用了mybatis，mybatis会负责好连接池申请回放回]]></content>
      <categories>
        <category>问题及解决</category>
      </categories>
      <tags>
        <tag>连接池</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[解决OutOfMemoryError: unable to create new native thread问题]]></title>
    <url>%2F2018%2F04%2F19%2F%E8%A7%A3%E5%86%B3OutOfMemoryError-unable-to-create-new-native-thread%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[背景java.lang.OutOfMemoryError共有8种类型，其中java.lang.OutOfMemoryError: unable to create new native thread是很常见的一种，这类错误通常发生在应用试图创建新线程时。最近测试环境经常出现错误如下： Caused by: java.lang.OutOfMemoryError: unable to create new native thread at java.lang.Thread.start0(Native Method) at java.lang.Thread.start(Thread.java:714) at java.util.concurrent.ThreadPoolExecutor.addWorker(ThreadPoolExecutor.java:950) at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1368) at com.alibaba.dubbo.remoting.transport.dispatcher.all.AllChannelHandler.caught(AllChannelHandler.java:65) 可能原因 系统内存耗尽，无法为新线程分配内存 创建线程数超过了操作系统的限制 解决方案 排查应用是否创建了过多的线程 通过jstack确定应用创建了多少线程？超量创建的线程的堆栈信息是怎样的？谁创建了这些线程？一旦明确了这些问题，便很容易解决。步骤如下： 该进程内最耗费CPU的线程pid top -Hp pid 将pid装换成十六进制 printf “%x\n” 21742 最后用jstack查找线程堆栈信息 jstack 21711 | grep 54ee 调整操作系统线程数阈值 操作系统会限制进程允许创建的线程数，使用ulimit -u命令查看限制。某些服务器上此阈值设置的过小，比如1024。一旦应用创建超过1024个线程，就会遇到java.lang.OutOfMemoryError: unable to create new native thread问题。如果是这种情况，可以调大操作系统线程数阈值。 用当前用户登录，然后用ulimit -a查看配置项，将max user processes项调整大一点，可以参考top -H 信息中的 Threads: 853 total线程数 增加机器内存 如果上述两项未能排除问题，可能是正常增长的业务确实需要更多内存来创建更多线程。如果是这种情况，增加机器内存。 减小堆内存 一个老司机也经常忽略的非常重要的知识点：线程不在堆内存上创建，线程在堆内存之外的内存上创建。所以如果分配了堆内存之后只剩下很少的可用内存，依然可能遇到java.lang.OutOfMemoryError: unable to create new native thread。考虑如下场景：系统总内存6G，堆内存分配了5G，永久代512M。在这种情况下，JVM占用了5.5G内存，系统进程、其他用户进程和线程将共用剩下的0.5G内存，很有可能没有足够的可用内存创建新的线程。如果是这种情况，考虑减小堆内存。 减少进程数 这和减小堆内存原理相似。考虑如下场景：系统总内存32G，java进程数5个，每个进程的堆内存6G。在这种情况下，java进程总共占用30G内存，仅剩下2G内存用于系统进程、其他用户进程和线程，很有可能没有足够的可用内存创建新的线程。如果是这种情况，考虑减少每台机器上的进程数。 减小线程栈大小 线程会占用内存，如果每个线程都占用更多内存，整体上将消耗更多的内存。每个线程默认占用内存大小取决于JVM实现。可以利用-Xss参数限制线程内存大小，降低总内存消耗。例如，JVM默认每个线程占用1M内存，应用有500个线程，那么将消耗500M内存空间。如果实际上256K内存足够线程正常运行，配置-Xss256k，那么500个线程将只需要消耗125M内存。（注意，如果-Xss设置的过低，将会产生java.lang.StackOverflowError错误）]]></content>
      <categories>
        <category>问题及解决</category>
      </categories>
      <tags>
        <tag>OutOfMemoryError</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hello Hexo]]></title>
    <url>%2F2018%2F04%2F12%2Fhello-hexo%2F</url>
    <content type="text"><![CDATA[以前一直用wordpress维护博客，最近看到hexo博客的样例，觉得挺炫的，今天就准备将wordpress版本的博客迁移到hexo，然后重新梳理以前的博文。 Hexo Quick StartCreate a new post1$ hexo new "My New Post" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment]]></content>
      <categories>
        <category>感悟</category>
      </categories>
      <tags>
        <tag>感悟</tag>
      </tags>
  </entry>
</search>
